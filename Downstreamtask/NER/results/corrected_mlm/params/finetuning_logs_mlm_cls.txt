ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
results/corrected_mlm/params/dibert_NER_mlm_cls_30_best.json
selecting grid search sampler
[I 2021-01-28 00:26:27,367] A new study created in memory with name: no-name-8390b244-cd63-400c-a7d0-040c946fc734
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.23it/s]
train_weighted_f1 0.8358197608501744
train_acc 0.8357791286469219

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.37it/s]
valid_weighted_f1: 0.9383164449689996
valid_acc: 0.9385825432592152
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.59      0.34      0.43       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      0.99      2353
           7       0.97      0.97      0.97      3217
           8       1.00      1.00      1.00      9748
           9       0.92      1.00      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.86      0.88      0.87      9782
          13       0.84      0.85      0.84       306
          14       0.89      0.85      0.87       331
          15       1.00      0.98      0.99        66
          16       0.99      0.99      0.99       678
          17       0.87      0.91      0.89     15211
          18       0.93      0.91      0.92     19633
          19       0.88      0.58      0.70       266
          20       0.93      0.94      0.93      8344
          21       0.00      0.00      0.00        15
          22       0.98      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.94      0.87      0.90      2155
          26       0.87      0.50      0.64       115
          27       0.80      0.32      0.45        38
          28       0.82      0.92      0.87       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.92      0.94      2601
          33       0.93      0.94      0.94      4030
          34       0.85      0.84      0.85      2051
          35       0.93      0.91      0.92      3387
          36       0.96      0.94      0.95      1654
          37       0.98      0.93      0.95      2611
          38       0.96      0.94      0.95       370
          39       0.99      0.99      0.99       270
          40       1.00      0.90      0.95        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.94    117605
   macro avg       0.89      0.85      0.87    117605
weighted avg       0.94      0.94      0.94    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:20<00:00,  4.28it/s]
train_weighted_f1 0.9330210084743875
train_acc 0.9331893255849518

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.40it/s]
valid_weighted_f1: 0.9547565705376292
valid_acc: 0.9548658645465754
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.59      0.66       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.94      1.00      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.90      0.90      9782
          13       0.87      0.92      0.90       306
          14       0.96      0.90      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.91      0.93      0.92     15211
          18       0.94      0.93      0.93     19633
          19       0.87      0.65      0.74       266
          20       0.96      0.96      0.96      8344
          21       0.91      0.67      0.77        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.91      0.93      2155
          26       0.88      0.59      0.71       115
          27       0.86      0.82      0.84        38
          28       0.85      0.94      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.95      0.96      2601
          33       0.94      0.96      0.95      4030
          34       0.92      0.90      0.91      2051
          35       0.94      0.93      0.93      3387
          36       0.96      0.96      0.96      1654
          37       0.98      0.95      0.97      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.95      0.92      0.93    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:20<00:00,  4.28it/s]
train_weighted_f1 0.9518719216639979
train_acc 0.9519538750403561

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.38it/s]
valid_weighted_f1: 0.9614154549510503
valid_acc: 0.9615407508184176
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.61      0.69       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.91      0.91      9782
          13       0.87      0.95      0.90       306
          14       0.95      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.92      0.94      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.86      0.69      0.77       266
          20       0.97      0.97      0.97      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.93      0.94      2155
          26       0.94      0.57      0.71       115
          27       0.97      0.76      0.85        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.96      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.92      0.93      2051
          35       0.95      0.93      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.92      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.30it/s]
train_weighted_f1 0.9620092304385583
train_acc 0.9620673395524291

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.36it/s]
valid_weighted_f1: 0.9651874110323116
valid_acc: 0.9652905913864206
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.71      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.91      0.92      9782
          13       0.91      0.95      0.93       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.70      0.77       266
          20       0.97      0.98      0.97      8344
          21       0.85      0.73      0.79        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.92      0.70      0.79       115
          27       0.97      0.84      0.90        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.96      0.96      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.94      0.94      2051
          35       0.95      0.94      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.29it/s]
train_weighted_f1 0.9689730076004899
train_acc 0.969017094017094

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.30it/s]
valid_weighted_f1: 0.9672824577607149
valid_acc: 0.9673738361464224
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.68      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.93      9782
          13       0.89      0.96      0.92       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.84      0.77      0.80       266
          20       0.97      0.98      0.97      8344
          21       0.80      0.80      0.80        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.93      0.66      0.77       115
          27       0.94      0.84      0.89        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.29it/s]
train_weighted_f1 0.9737887983247306
train_acc 0.973821600312654

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.35it/s]
valid_weighted_f1: 0.9686627521956483
valid_acc: 0.968734322520301
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.70      0.76       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.91      0.96      0.93       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.84      0.76      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.92      0.72      0.81       115
          27       0.94      0.87      0.90        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.96      0.93      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:20<00:00,  4.28it/s]
train_weighted_f1 0.977921477976832
train_acc 0.977949610032115

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.9693374486600933
valid_acc: 0.9693975596275669
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.65      0.74       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.91      0.95      0.93       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.95      0.95     19633
          19       0.84      0.79      0.81       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.89      0.72      0.80       115
          27       0.89      0.87      0.88        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.97      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 00:45:14,593] Trial 0 finished with value: 0.9693975596275669 and parameters: {'lrmain': 3e-05, 'drop_out': 0.3}. Best is trial 0 with value: 0.9693975596275669.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:20<00:00,  4.27it/s]
train_weighted_f1 0.8823533194009547
train_acc 0.8824584544017944

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.27it/s]
valid_weighted_f1: 0.9509078741365057
valid_acc: 0.9510054844606947
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.50      0.59       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      0.99      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.87      0.91      0.89      9782
          13       0.83      0.92      0.88       306
          14       0.95      0.89      0.92       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.91      0.92      0.92     15211
          18       0.94      0.92      0.93     19633
          19       0.85      0.66      0.74       266
          20       0.95      0.96      0.95      8344
          21       0.91      0.67      0.77        15
          22       0.99      1.00      1.00      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      1.00       925
          25       0.94      0.90      0.92      2155
          26       0.93      0.46      0.62       115
          27       0.90      0.71      0.79        38
          28       0.83      0.94      0.88       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.95      0.95      2601
          33       0.92      0.96      0.94      4030
          34       0.88      0.90      0.89      2051
          35       0.96      0.91      0.93      3387
          36       0.97      0.95      0.96      1654
          37       0.98      0.94      0.96      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.93      0.90      0.91    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9525396234870404
train_acc 0.9526059455234406

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.31it/s]
valid_weighted_f1: 0.9630179924637425
valid_acc: 0.963139322307725
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.70      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.87      0.95      0.90       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.94      0.93     15211
          18       0.95      0.94      0.95     19633
          19       0.83      0.73      0.78       266
          20       0.96      0.97      0.97      8344
          21       0.87      0.87      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.93      0.94      0.94      2155
          26       0.93      0.49      0.64       115
          27       0.88      0.76      0.82        38
          28       0.87      0.93      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.96      0.96      2601
          33       0.94      0.98      0.96      4030
          34       0.94      0.93      0.93      2051
          35       0.95      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:20<00:00,  4.27it/s]
train_weighted_f1 0.9669025901507297
train_acc 0.9669419381149004

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.34it/s]
valid_weighted_f1: 0.9667471920838616
valid_acc: 0.9668381446367076
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.78      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.88      0.96      0.92       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.84      0.77      0.80       266
          20       0.97      0.98      0.97      8344
          21       0.87      0.87      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.92      0.59      0.72       115
          27       0.94      0.76      0.84        38
          28       0.86      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.93      0.94      2051
          35       0.97      0.93      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:22<00:00,  4.20it/s]
train_weighted_f1 0.9748494919693889
train_acc 0.974880418344633

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.29it/s]
valid_weighted_f1: 0.9685335813555025
valid_acc: 0.9685897708430764
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.83      0.80       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.91      0.95      0.93       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.83      0.79      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.88      0.93      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.95      0.95      2155
          26       0.93      0.69      0.79       115
          27       0.91      0.84      0.88        38
          28       0.88      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:20<00:00,  4.28it/s]
train_weighted_f1 0.9804364827979355
train_acc 0.980457001580262

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.45it/s]
valid_weighted_f1: 0.9700420592376505
valid_acc: 0.9700692997746695
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.80      0.78       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.92      0.95      0.94       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.82      0.81      0.82       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.93      0.72      0.81       115
          27       0.94      0.79      0.86        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.96      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.95      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.29it/s]
train_weighted_f1 0.9843838905444233
train_acc 0.9843970365839153

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.37it/s]
valid_weighted_f1: 0.96992393622368
valid_acc: 0.9699757663364653
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.77      0.79       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.95      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.85      0.80      0.82       266
          20       0.97      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.90      0.63      0.74       115
          27       0.94      0.76      0.84        38
          28       0.86      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.29it/s]
train_weighted_f1 0.9873111931015959
train_acc 0.9873186097092658

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.36it/s]
valid_weighted_f1: 0.9707743045019943
valid_acc: 0.9707835551209557
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.75      0.77       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       1.00      0.99      0.99     12278
          12       0.92      0.95      0.94      9782
          13       0.91      0.96      0.94       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.84      0.82      0.83       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.93      0.97        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.89      0.71      0.79       115
          27       0.94      0.82      0.87        38
          28       0.88      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.94      0.98      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 01:04:05,556] Trial 1 finished with value: 0.9707835551209557 and parameters: {'lrmain': 5e-05, 'drop_out': 0.1}. Best is trial 1 with value: 0.9707835551209557.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.32it/s]
train_weighted_f1 0.8714459663609655
train_acc 0.8714178603592122

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9479836009111982
valid_acc: 0.9481824752348965
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.71      0.50      0.58       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.87      0.90      0.89      9782
          13       0.83      0.91      0.87       306
          14       0.92      0.89      0.90       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.91      0.91      0.91     15211
          18       0.93      0.93      0.93     19633
          19       0.86      0.64      0.74       266
          20       0.94      0.95      0.95      8344
          21       1.00      0.47      0.64        15
          22       0.99      1.00      1.00      2100
          23       0.99      0.99      0.99      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.90      0.92      2155
          26       0.95      0.45      0.61       115
          27       1.00      0.39      0.57        38
          28       0.85      0.93      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.94      0.95      2601
          33       0.94      0.96      0.95      4030
          34       0.89      0.88      0.88      2051
          35       0.94      0.91      0.93      3387
          36       0.96      0.95      0.96      1654
          37       0.97      0.95      0.96      2611
          38       0.95      0.97      0.96       370
          39       0.99      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.93      0.88      0.90    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9474797798433648
train_acc 0.947558240301779

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.69it/s]
valid_weighted_f1: 0.9611047340081454
valid_acc: 0.9612346413842949
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.69      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.90      0.91      9782
          13       0.86      0.94      0.90       306
          14       0.94      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.92      0.94      0.93     15211
          18       0.95      0.94      0.94     19633
          19       0.87      0.71      0.78       266
          20       0.96      0.97      0.97      8344
          21       0.93      0.87      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.94      0.94      0.94      2155
          26       0.90      0.56      0.69       115
          27       1.00      0.66      0.79        38
          28       0.88      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.93      0.93      0.93      2051
          35       0.95      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.38it/s]
train_weighted_f1 0.9627170949418589
train_acc 0.962762952201322

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9658213777692782
valid_acc: 0.9659113132945027
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.73      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.93      9782
          13       0.87      0.95      0.91       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.87      0.76      0.81       266
          20       0.97      0.98      0.97      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.89      0.57      0.70       115
          27       0.93      0.74      0.82        38
          28       0.86      0.98      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.96      0.96      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.94      0.94      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.97      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.35it/s]
train_weighted_f1 0.9715106030117232
train_acc 0.9715457256461233

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9680027525608592
valid_acc: 0.9680880914927087
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.68      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.89      0.96      0.92       306
          14       0.94      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.84      0.80      0.82       266
          20       0.97      0.98      0.98      8344
          21       0.80      0.80      0.80        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.92      0.63      0.75       115
          27       0.93      0.68      0.79        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.96      0.96      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.94      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.96      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.38it/s]
train_weighted_f1 0.9771476858107593
train_acc 0.9771754090839578

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9688667553562939
valid_acc: 0.9689383954763828
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.74      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.89      0.96      0.92       306
          14       0.97      0.96      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.88      0.80      0.84       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.89      0.66      0.76       115
          27       0.94      0.89      0.92        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.9814726560266225
train_acc 0.9814913935192265

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9700733700935409
valid_acc: 0.9701458271332001
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.76      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.89      0.96      0.92       306
          14       0.95      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.84      0.79      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.86      0.80      0.83        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.90      0.64      0.75       115
          27       0.94      0.84      0.89        38
          28       0.91      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.38it/s]
train_weighted_f1 0.9848281555836768
train_acc 0.9848398922703098

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9706643583972969
valid_acc: 0.970707027762425
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.88      0.72      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.89      0.97      0.93       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.83      0.82      0.82       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.93      0.64      0.76       115
          27       0.94      0.79      0.86        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 01:21:44,521] Trial 2 finished with value: 0.970707027762425 and parameters: {'lrmain': 4e-05, 'drop_out': 0.1}. Best is trial 1 with value: 0.9707835551209557.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.8539151248175153
train_acc 0.8539903739953442

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9411959898909762
valid_acc: 0.9413715403256664
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.61      0.55      0.58       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.97      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.94      1.00      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.87      0.88      0.88      9782
          13       0.83      0.88      0.85       306
          14       0.96      0.86      0.91       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.89      0.90      0.90     15211
          18       0.92      0.92      0.92     19633
          19       0.86      0.65      0.74       266
          20       0.93      0.94      0.94      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       1.00      0.98      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.94      0.87      0.90      2155
          26       0.90      0.48      0.62       115
          27       0.88      0.76      0.82        38
          28       0.86      0.94      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.93      0.94      2601
          33       0.92      0.96      0.94      4030
          34       0.85      0.86      0.86      2051
          35       0.95      0.89      0.92      3387
          36       0.95      0.95      0.95      1654
          37       0.97      0.93      0.95      2611
          38       0.95      0.96      0.95       370
          39       0.99      0.99      0.99       270
          40       1.00      0.90      0.95        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.94    117605
   macro avg       0.90      0.88      0.88    117605
weighted avg       0.94      0.94      0.94    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9399799495084613
train_acc 0.9400944758797641

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9570663331943536
valid_acc: 0.9571446792228222
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.63      0.66       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.91      0.91      9782
          13       0.86      0.93      0.89       306
          14       0.96      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.92      0.93      0.92     15211
          18       0.94      0.94      0.94     19633
          19       0.86      0.71      0.78       266
          20       0.96      0.96      0.96      8344
          21       0.79      0.73      0.76        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.95      0.92      0.94      2155
          26       0.88      0.56      0.68       115
          27       0.91      0.82      0.86        38
          28       0.88      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.96      0.96      2601
          33       0.94      0.97      0.95      4030
          34       0.91      0.91      0.91      2051
          35       0.96      0.91      0.94      3387
          36       0.96      0.97      0.96      1654
          37       0.98      0.95      0.97      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.38it/s]
train_weighted_f1 0.9565678878176502
train_acc 0.9566298788465787

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.67it/s]
valid_weighted_f1: 0.9626706969204851
valid_acc: 0.9627651885549083
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.70      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.91      0.92      9782
          13       0.88      0.95      0.91       306
          14       0.96      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.93      0.93     15211
          18       0.94      0.95      0.94     19633
          19       0.86      0.74      0.80       266
          20       0.97      0.97      0.97      8344
          21       0.86      0.80      0.83        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.92      0.63      0.75       115
          27       0.89      0.82      0.85        38
          28       0.88      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.93      0.94      2051
          35       0.95      0.94      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.96      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9655879181805508
train_acc 0.9656282391123345

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9656973987823162
valid_acc: 0.9657922707367884
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.77      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.93      9782
          13       0.88      0.96      0.92       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      0.99       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.87      0.73      0.79       266
          20       0.97      0.98      0.97      8344
          21       0.86      0.80      0.83        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.94      0.63      0.75       115
          27       0.89      0.82      0.85        38
          28       0.88      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.93      0.94      2051
          35       0.96      0.93      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9720470427638349
train_acc 0.9720788516762672

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.67it/s]
valid_weighted_f1: 0.9677831424255362
valid_acc: 0.9678415033374431
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.80      0.81       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.90      0.95      0.93       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.84      0.78      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.80      0.80      0.80        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.93      0.68      0.78       115
          27       0.90      0.92      0.91        38
          28       0.89      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.94      0.94      2051
          35       0.96      0.93      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9768942610383952
train_acc 0.976920528113371

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9685365085989637
valid_acc: 0.9685897708430764
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.76      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.91      0.96      0.93       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.93      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.84      0.77      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.81      0.87      0.84        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.91      0.72      0.81       115
          27       0.94      0.82      0.87        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.95      0.97      0.96      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.97      0.96      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.9807054023530922
train_acc 0.9807235645953339

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9699024324368336
valid_acc: 0.9699417541771184
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.75      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.95      0.94      9782
          13       0.89      0.96      0.92       306
          14       0.96      0.97      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.86      0.78      0.82       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.93      0.65      0.77       115
          27       0.92      0.89      0.91        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 01:39:18,190] Trial 3 finished with value: 0.9699417541771184 and parameters: {'lrmain': 3e-05, 'drop_out': 0.1}. Best is trial 1 with value: 0.9707835551209557.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.887972545848785
train_acc 0.8880424716657321

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9519352798678965
valid_acc: 0.9520003401215935
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.61      0.56      0.58       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.91      0.90      9782
          13       0.87      0.91      0.88       306
          14       0.96      0.90      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.92      0.92      0.92     15211
          18       0.94      0.93      0.93     19633
          19       0.84      0.69      0.75       266
          20       0.94      0.96      0.95      8344
          21       0.83      0.67      0.74        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.94      0.91      0.92      2155
          26       0.88      0.57      0.69       115
          27       0.89      0.87      0.88        38
          28       0.84      0.94      0.88       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.94      0.95      2601
          33       0.94      0.95      0.95      4030
          34       0.90      0.90      0.90      2051
          35       0.95      0.92      0.93      3387
          36       0.96      0.96      0.96      1654
          37       0.97      0.95      0.96      2611
          38       0.96      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.92      0.91      0.91    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9553513376567226
train_acc 0.9554106982039388

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.70it/s]
valid_weighted_f1: 0.962915022545343
valid_acc: 0.962977764550827
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.72      0.70      0.71       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.91      0.92      9782
          13       0.88      0.94      0.91       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.94      0.93     15211
          18       0.95      0.95      0.95     19633
          19       0.84      0.75      0.79       266
          20       0.97      0.97      0.97      8344
          21       0.80      0.80      0.80        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.94      2155
          26       0.90      0.61      0.73       115
          27       0.91      0.79      0.85        38
          28       0.85      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.95      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.93      0.93      0.93      2051
          35       0.94      0.93      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9688598341277611
train_acc 0.9689045215884182

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.73it/s]
valid_weighted_f1: 0.9669629335880352
valid_acc: 0.9670252115131159
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.78      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.91      0.96      0.93       306
          14       0.95      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.94      0.96      0.95     19633
          19       0.84      0.80      0.82       266
          20       0.97      0.98      0.98      8344
          21       0.73      0.73      0.73        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.90      0.71      0.80       115
          27       0.93      0.74      0.82        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.93      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9768881819063521
train_acc 0.9769141560891064

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9685175495312546
valid_acc: 0.9685982738829132
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.76      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.90      0.97      0.93       306
          14       0.95      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.94     15211
          18       0.94      0.96      0.95     19633
          19       0.86      0.78      0.82       266
          20       0.97      0.98      0.98      8344
          21       0.73      0.73      0.73        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.89      0.68      0.77       115
          27       0.91      0.82      0.86        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9819629169491803
train_acc 0.9819799153795178

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9696741043047985
valid_acc: 0.9697291781811997
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.77      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.97      0.95       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.87      0.80      0.83       266
          20       0.97      0.98      0.98      8344
          21       0.83      0.67      0.74        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.94      0.96      2155
          26       0.88      0.74      0.80       115
          27       0.92      0.87      0.89        38
          28       0.90      0.93      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9856888247689457
train_acc 0.9856979915379518

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9704848083299893
valid_acc: 0.9705199608860168
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.74      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.90      0.98      0.94       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.86      0.80      0.83       266
          20       0.97      0.98      0.98      8344
          21       0.91      0.67      0.77        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.95      2155
          26       0.93      0.68      0.78       115
          27       0.94      0.84      0.89        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9885835379764901
train_acc 0.988588766546023

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.72it/s]
valid_weighted_f1: 0.9705617626285313
valid_acc: 0.9706049912843842
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.69      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.97      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.96      0.94       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.86      0.79      0.82       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.87      0.72      0.79       115
          27       0.91      0.84      0.88        38
          28       0.89      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.95      0.96      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.97      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 01:56:49,750] Trial 4 finished with value: 0.9706049912843842 and parameters: {'lrmain': 5e-05, 'drop_out': 0.0}. Best is trial 1 with value: 0.9707835551209557.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.8632489766660059
train_acc 0.8632722893408779

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.67it/s]
valid_weighted_f1: 0.9459453919555237
valid_acc: 0.9460992304748947
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.63      0.50      0.56       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.87      0.90      0.88      9782
          13       0.85      0.89      0.87       306
          14       0.94      0.85      0.90       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.91      0.91      0.91     15211
          18       0.93      0.92      0.92     19633
          19       0.88      0.62      0.73       266
          20       0.93      0.96      0.94      8344
          21       1.00      0.20      0.33        15
          22       0.99      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      1.00       925
          25       0.95      0.88      0.91      2155
          26       0.84      0.51      0.64       115
          27       0.79      0.68      0.73        38
          28       0.82      0.94      0.87       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.95      0.94      0.95      2601
          33       0.93      0.96      0.94      4030
          34       0.84      0.89      0.87      2051
          35       0.95      0.90      0.92      3387
          36       0.96      0.96      0.96      1654
          37       0.98      0.94      0.96      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      0.90      0.95        10
          41       1.00      0.99      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.92      0.88      0.89    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9450109990068256
train_acc 0.9451113829841464

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.70it/s]
valid_weighted_f1: 0.9602409836658214
valid_acc: 0.9603163130819268
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.69      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.92      0.91      9782
          13       0.87      0.94      0.90       306
          14       0.96      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.92      0.94      0.93     15211
          18       0.95      0.94      0.94     19633
          19       0.87      0.70      0.78       266
          20       0.97      0.97      0.97      8344
          21       0.93      0.87      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.92      0.94      2155
          26       0.90      0.55      0.68       115
          27       0.91      0.82      0.86        38
          28       0.87      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.96      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.91      0.93      2051
          35       0.95      0.93      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.960842930714258
train_acc 0.960904445124127

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.73it/s]
valid_weighted_f1: 0.9650266907272682
valid_acc: 0.9651290336295225
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.77      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.91      0.92      9782
          13       0.87      0.95      0.91       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.95      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.87      0.74      0.80       266
          20       0.97      0.98      0.97      8344
          21       0.81      0.87      0.84        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.90      0.57      0.70       115
          27       0.92      0.89      0.91        38
          28       0.86      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.96      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.93      0.94      2051
          35       0.96      0.93      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9696578683396466
train_acc 0.9696999626174576

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.69it/s]
valid_weighted_f1: 0.9674981747093003
valid_acc: 0.9675949151821777
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.77      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.90      0.96      0.93       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.75      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.83      0.67      0.74        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.91      0.63      0.75       115
          27       0.88      0.95      0.91        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.975672895971817
train_acc 0.9757024094747753

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.68it/s]
valid_weighted_f1: 0.9688601368752074
valid_acc: 0.968929892436546
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.77      0.82       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.92      0.96      0.94       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.83      0.79      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.92      0.70      0.80       115
          27       0.88      0.92      0.90        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.94      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9798611188868637
train_acc 0.9798813953883536

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.73it/s]
valid_weighted_f1: 0.9699716755745451
valid_acc: 0.9700437906551592
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.88      0.73      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.86      0.80      0.83       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.92      0.67      0.77       115
          27       0.88      0.95      0.91        38
          28       0.91      0.93      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9833973865395023
train_acc 0.9834146828431123

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.970336013214113
valid_acc: 0.9703669061689554
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.77      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.92      0.95      0.93      9782
          13       0.92      0.96      0.94       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.86      0.79      0.82       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.91      0.71      0.80       115
          27       0.88      0.95      0.91        38
          28       0.91      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.97      0.95      0.96      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 02:14:21,012] Trial 5 finished with value: 0.9703669061689554 and parameters: {'lrmain': 4e-05, 'drop_out': 0.2}. Best is trial 1 with value: 0.9707835551209557.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.41it/s]
train_weighted_f1 0.8571057455404998
train_acc 0.8571094798728993

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.74it/s]
valid_weighted_f1: 0.9456267605401038
valid_acc: 0.9458866544789762
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.36      0.48       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.97      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.93      1.00      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.87      0.89      0.88      9782
          13       0.83      0.90      0.86       306
          14       0.93      0.87      0.90       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.90      0.91      0.91     15211
          18       0.93      0.92      0.92     19633
          19       0.90      0.61      0.73       266
          20       0.93      0.95      0.94      8344
          21       0.50      0.07      0.12        15
          22       0.99      1.00      0.99      2100
          23       1.00      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.95      0.88      0.91      2155
          26       0.95      0.45      0.61       115
          27       0.91      0.53      0.67        38
          28       0.84      0.92      0.88       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.93      0.95      2601
          33       0.94      0.95      0.94      4030
          34       0.88      0.87      0.88      2051
          35       0.93      0.92      0.92      3387
          36       0.96      0.95      0.96      1654
          37       0.98      0.93      0.95      2611
          38       0.96      0.97      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.92      0.87      0.88    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9416967651953028
train_acc 0.9418053643948276

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.70it/s]
valid_weighted_f1: 0.958837233902633
valid_acc: 0.9589813358275584
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.61      0.66       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.90      0.91      9782
          13       0.86      0.93      0.89       306
          14       0.96      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.92      0.93      0.93     15211
          18       0.93      0.94      0.94     19633
          19       0.89      0.68      0.77       266
          20       0.96      0.96      0.96      8344
          21       1.00      0.53      0.70        15
          22       0.99      1.00      0.99      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.92      0.94      2155
          26       0.92      0.50      0.65       115
          27       0.88      0.76      0.82        38
          28       0.86      0.95      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.96      0.96      2601
          33       0.94      0.97      0.95      4030
          34       0.94      0.92      0.93      2051
          35       0.95      0.92      0.94      3387
          36       0.97      0.96      0.97      1654
          37       0.98      0.95      0.97      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.91      0.93    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.958687769420125
train_acc 0.9587443288984044

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9644275302709673
valid_acc: 0.964525317801114
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.74      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.92      9782
          13       0.88      0.93      0.91       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.72      0.78       266
          20       0.97      0.98      0.97      8344
          21       0.85      0.73      0.79        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.91      0.60      0.72       115
          27       0.87      0.71      0.78        38
          28       0.89      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.96      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.94      0.94      2051
          35       0.95      0.94      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9682330948343846
train_acc 0.9682747531902601

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9672164236111254
valid_acc: 0.9672973087878917
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.71      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.90      0.95      0.92       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.84      0.78      0.81       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.92      0.67      0.77       115
          27       0.87      0.89      0.88        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9743038042264811
train_acc 0.9743387962821363

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.69it/s]
valid_weighted_f1: 0.9687056545360956
valid_acc: 0.9687853407593214
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.74      0.77       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.90      0.95      0.93       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.86      0.77      0.82       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.92      0.70      0.79       115
          27       0.91      0.79      0.85        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:40<00:00,  3.74it/s]
train_weighted_f1 0.9789451034403626
train_acc 0.9789670099063738

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9700050744287819
valid_acc: 0.970052293694996
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.75      0.79       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.91      0.95      0.93       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.86      0.79      0.82       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.92      0.71      0.80       115
          27       0.94      0.82      0.87        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.41it/s]
train_weighted_f1 0.9824050015566891
train_acc 0.982420647057824

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.67it/s]
valid_weighted_f1: 0.9704674625138565
valid_acc: 0.9705199608860168
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.75      0.79       101
           5       0.95      1.00      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.95      0.94       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.84      0.79      0.82       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.91      0.71      0.80       115
          27       0.92      0.87      0.89        38
          28       0.90      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 02:32:16,685] Trial 6 finished with value: 0.9705199608860168 and parameters: {'lrmain': 4e-05, 'drop_out': 0.3}. Best is trial 1 with value: 0.9707835551209557.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.8132107739409371
train_acc 0.8130033899169088

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.50it/s]
valid_weighted_f1: 0.9281355683752018
valid_acc: 0.9285489562518601
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.60      0.21      0.31       101
           5       1.00      0.81      0.89        21
           6       0.99      0.99      0.99      2353
           7       0.97      0.96      0.96      3217
           8       0.99      1.00      1.00      9748
           9       0.93      1.00      0.96        65
          11       0.98      0.99      0.99     12278
          12       0.84      0.87      0.85      9782
          13       0.82      0.81      0.82       306
          14       0.88      0.80      0.84       331
          15       1.00      0.98      0.99        66
          16       0.99      0.99      0.99       678
          17       0.87      0.89      0.88     15211
          18       0.91      0.90      0.90     19633
          19       0.86      0.60      0.71       266
          20       0.90      0.92      0.91      8344
          21       0.00      0.00      0.00        15
          22       0.98      1.00      0.99      2100
          23       0.98      0.98      0.98      1397
          24       0.99      0.99      0.99       925
          25       0.93      0.83      0.88      2155
          26       0.79      0.46      0.58       115
          27       0.60      0.24      0.34        38
          28       0.80      0.90      0.85       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.94      0.93      0.93      2601
          33       0.91      0.93      0.92      4030
          34       0.83      0.80      0.82      2051
          35       0.91      0.89      0.90      3387
          36       0.96      0.93      0.95      1654
          37       0.97      0.91      0.94      2611
          38       0.92      0.95      0.93       370
          39       0.99      0.98      0.99       270
          40       1.00      0.10      0.18        10
          41       1.00      0.98      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.93    117605
   macro avg       0.88      0.82      0.83    117605
weighted avg       0.93      0.93      0.93    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9228829730856991
train_acc 0.9231077211942023

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.59it/s]
valid_weighted_f1: 0.9479562291398892
valid_acc: 0.9481484630755496
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.69      0.50      0.58       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.90      0.89      9782
          13       0.85      0.89      0.87       306
          14       0.94      0.87      0.90       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.90      0.92      0.91     15211
          18       0.93      0.92      0.93     19633
          19       0.92      0.63      0.75       266
          20       0.94      0.95      0.95      8344
          21       1.00      0.27      0.42        15
          22       0.99      1.00      1.00      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.94      0.89      0.92      2155
          26       0.87      0.50      0.64       115
          27       0.87      0.68      0.76        38
          28       0.87      0.92      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.95      0.95      0.95      2601
          33       0.93      0.95      0.94      4030
          34       0.90      0.87      0.89      2051
          35       0.93      0.92      0.92      3387
          36       0.96      0.96      0.96      1654
          37       0.98      0.94      0.96      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.93      0.88      0.90    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.942751176096287
train_acc 0.9428556863944538

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9563523546406387
valid_acc: 0.9564899451553931
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.69      0.56      0.62       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.90      0.91      9782
          13       0.88      0.92      0.90       306
          14       0.96      0.91      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.92      0.93      0.92     15211
          18       0.93      0.94      0.94     19633
          19       0.92      0.65      0.76       266
          20       0.96      0.96      0.96      8344
          21       0.83      0.67      0.74        15
          22       0.99      1.00      1.00      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      1.00       925
          25       0.95      0.92      0.93      2155
          26       0.87      0.62      0.72       115
          27       0.88      0.79      0.83        38
          28       0.88      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.96      0.96      2601
          33       0.95      0.96      0.95      4030
          34       0.93      0.90      0.92      2051
          35       0.94      0.92      0.93      3387
          36       0.96      0.97      0.96      1654
          37       0.98      0.95      0.97      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9541820185781135
train_acc 0.9542562998079896

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.68it/s]
valid_weighted_f1: 0.9615124274112462
valid_acc: 0.9616342842566218
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.59      0.67       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.89      0.93      0.91       306
          14       0.97      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.93      0.93     15211
          18       0.94      0.95      0.94     19633
          19       0.90      0.68      0.78       266
          20       0.96      0.97      0.97      8344
          21       0.79      0.73      0.76        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.94      2155
          26       0.87      0.65      0.75       115
          27       0.90      0.92      0.91        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.94      0.97      0.96      4030
          34       0.93      0.92      0.93      2051
          35       0.95      0.93      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9618448502264318
train_acc 0.9619027289255917

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9641508702438266
valid_acc: 0.9642362144466646
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.68      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.92      9782
          13       0.90      0.94      0.92       306
          14       0.94      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.93      0.94     15211
          18       0.94      0.95      0.95     19633
          19       0.89      0.72      0.79       266
          20       0.97      0.98      0.97      8344
          21       0.79      0.73      0.76        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.89      0.68      0.77       115
          27       0.89      0.84      0.86        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.96      0.96      4030
          34       0.95      0.93      0.94      2051
          35       0.94      0.94      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9673529082113175
train_acc 0.9673996618579124

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9662255664427785
valid_acc: 0.9663279622465031
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.66      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.93      9782
          13       0.90      0.95      0.93       306
          14       0.94      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.93      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.90      0.72      0.80       266
          20       0.96      0.98      0.97      8344
          21       0.83      0.67      0.74        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.92      0.67      0.77       115
          27       0.90      0.74      0.81        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.95      0.94      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.971714943205908
train_acc 0.9717538784387691

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9673101689882503
valid_acc: 0.9673738361464224
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.67      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.92      0.95      0.93       306
          14       0.97      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.88      0.76      0.81       266
          20       0.97      0.98      0.97      8344
          21       0.80      0.80      0.80        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.92      0.72      0.81       115
          27       0.90      0.92      0.91        38
          28       0.90      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.96      0.94      0.95      2051
          35       0.96      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 02:49:49,636] Trial 7 finished with value: 0.9673738361464224 and parameters: {'lrmain': 2e-05, 'drop_out': 0.2}. Best is trial 1 with value: 0.9707835551209557.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.8762550873053218
train_acc 0.8761108562301405

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9510292455427201
valid_acc: 0.9511500361379193
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.56      0.62       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.93      1.00      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.90      0.89      9782
          13       0.86      0.91      0.88       306
          14       0.95      0.90      0.93       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.91      0.92      0.92     15211
          18       0.93      0.93      0.93     19633
          19       0.85      0.65      0.74       266
          20       0.94      0.96      0.95      8344
          21       1.00      0.33      0.50        15
          22       0.99      1.00      0.99      2100
          23       1.00      0.99      0.99      1397
          24       0.99      1.00      1.00       925
          25       0.95      0.89      0.92      2155
          26       0.91      0.55      0.68       115
          27       0.82      0.74      0.78        38
          28       0.82      0.95      0.88       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.94      0.95      2601
          33       0.94      0.96      0.95      4030
          34       0.90      0.89      0.90      2051
          35       0.94      0.91      0.93      3387
          36       0.96      0.96      0.96      1654
          37       0.98      0.94      0.96      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.93      0.89      0.90    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9500199365840855
train_acc 0.9500943059591171

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9626241446553038
valid_acc: 0.9626971642362144
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.71      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.91      0.93      0.92       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.93      0.93     15211
          18       0.95      0.94      0.95     19633
          19       0.85      0.73      0.79       266
          20       0.96      0.98      0.97      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.90      0.70      0.78       115
          27       0.89      0.87      0.88        38
          28       0.84      0.96      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.95      0.96      2601
          33       0.94      0.98      0.96      4030
          34       0.92      0.94      0.93      2051
          35       0.96      0.93      0.94      3387
          36       0.96      0.97      0.96      1654
          37       0.98      0.97      0.97      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9653688476138119
train_acc 0.965413714295424

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.967114089870045
valid_acc: 0.967186769270014
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.79      0.82       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.92      0.94      0.93       306
          14       0.93      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.76      0.80       266
          20       0.97      0.98      0.97      8344
          21       1.00      0.73      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.89      0.74      0.81       115
          27       0.93      0.66      0.77        38
          28       0.87      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.96      0.96      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [03:03<00:00,  3.26it/s]
train_weighted_f1 0.9735801030511566
train_acc 0.9736166335321405

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.96855715089625
valid_acc: 0.9686407890820968
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.76      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.90      0.94      0.92       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.86      0.76      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.79      0.73      0.76        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.90      0.69      0.78       115
          27       0.93      0.71      0.81        38
          28       0.88      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.97      0.96      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9789968660909835
train_acc 0.9790222341166676

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.60it/s]
valid_weighted_f1: 0.9694555456634615
valid_acc: 0.9694995961056078
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.79      0.82       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.92      0.95      0.94       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.83      0.78      0.80       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.89      0.76      0.82       115
          27       0.97      0.76      0.85        38
          28       0.87      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.97      0.96      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.95      0.98      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.982858472711799
train_acc 0.9828730607806154

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9702788282263513
valid_acc: 0.9703328940096084
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.76      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.94      0.97      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.81      0.80      0.80       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.88      0.74      0.80       115
          27       0.96      0.63      0.76        38
          28       0.87      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.60      1.00      0.75         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9859206435067857
train_acc 0.9859284464155239

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9704179995562053
valid_acc: 0.9704009183283023
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.73      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.92      0.95      0.93      9782
          13       0.92      0.94      0.93       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.81      0.82      0.82       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.67      0.80        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.81      0.76      0.78       115
          27       0.92      0.89      0.91        38
          28       0.87      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 03:08:08,968] Trial 8 finished with value: 0.9704009183283023 and parameters: {'lrmain': 5e-05, 'drop_out': 0.2}. Best is trial 1 with value: 0.9707835551209557.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.8031046273767504
train_acc 0.8030694040882908

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.60it/s]
valid_weighted_f1: 0.9271066824285411
valid_acc: 0.9275115853917776
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.56      0.24      0.33       101
           5       1.00      0.67      0.80        21
           6       0.99      0.99      0.99      2353
           7       0.97      0.95      0.96      3217
           8       0.99      1.00      1.00      9748
           9       0.92      1.00      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.84      0.86      0.85      9782
          13       0.83      0.80      0.81       306
          14       0.89      0.80      0.84       331
          15       1.00      0.98      0.99        66
          16       0.98      0.99      0.99       678
          17       0.86      0.89      0.88     15211
          18       0.90      0.90      0.90     19633
          19       0.84      0.57      0.68       266
          20       0.90      0.92      0.91      8344
          21       0.00      0.00      0.00        15
          22       0.98      1.00      0.99      2100
          23       0.99      0.98      0.98      1397
          24       0.98      0.99      0.99       925
          25       0.93      0.83      0.87      2155
          26       0.77      0.51      0.61       115
          27       0.78      0.18      0.30        38
          28       0.78      0.91      0.84       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.93      0.93      0.93      2601
          33       0.92      0.93      0.92      4030
          34       0.85      0.79      0.82      2051
          35       0.92      0.89      0.90      3387
          36       0.96      0.93      0.94      1654
          37       0.97      0.91      0.94      2611
          38       0.94      0.93      0.93       370
          39       0.99      0.98      0.98       270
          40       1.00      0.30      0.46        10
          41       1.00      0.99      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.93    117605
   macro avg       0.88      0.82      0.84    117605
weighted avg       0.93      0.93      0.93    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9185833039463418
train_acc 0.9188352789247421

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.71it/s]
valid_weighted_f1: 0.9467360800281215
valid_acc: 0.9469495344585689
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.41      0.53       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.94      1.00      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.87      0.90      0.88      9782
          13       0.86      0.89      0.88       306
          14       0.95      0.87      0.91       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.90      0.92      0.91     15211
          18       0.93      0.92      0.92     19633
          19       0.87      0.59      0.71       266
          20       0.94      0.94      0.94      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.94      0.88      0.91      2155
          26       0.89      0.55      0.68       115
          27       0.91      0.76      0.83        38
          28       0.86      0.92      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.95      0.95      0.95      2601
          33       0.94      0.95      0.94      4030
          34       0.89      0.87      0.88      2051
          35       0.94      0.91      0.92      3387
          36       0.97      0.95      0.96      1654
          37       0.97      0.94      0.95      2611
          38       0.94      0.97      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.91      0.88      0.89    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9399081661825361
train_acc 0.9400434996856468

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.70it/s]
valid_weighted_f1: 0.9554072885991616
valid_acc: 0.9555631138131883
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.54      0.63       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.90      0.90      9782
          13       0.88      0.93      0.90       306
          14       0.97      0.89      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.91      0.93      0.92     15211
          18       0.93      0.94      0.94     19633
          19       0.93      0.62      0.74       266
          20       0.95      0.97      0.96      8344
          21       0.78      0.47      0.58        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.95      0.91      0.93      2155
          26       0.91      0.60      0.72       115
          27       0.91      0.84      0.88        38
          28       0.89      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.96      0.96      2601
          33       0.94      0.96      0.95      4030
          34       0.93      0.90      0.91      2051
          35       0.95      0.92      0.94      3387
          36       0.97      0.96      0.96      1654
          37       0.98      0.95      0.96      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.91      0.93    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9519548423139985
train_acc 0.9520494554043262

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9605246854870882
valid_acc: 0.9606394285957229
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.61      0.68       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.92      0.91      9782
          13       0.88      0.93      0.90       306
          14       0.97      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.93      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.90      0.67      0.76       266
          20       0.96      0.97      0.97      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.96      0.92      0.94      2155
          26       0.90      0.64      0.75       115
          27       0.91      0.84      0.88        38
          28       0.89      0.93      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.92      0.93      2051
          35       0.95      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.92      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9599526345204368
train_acc 0.9600166097432499

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.69it/s]
valid_weighted_f1: 0.9635035021713397
valid_acc: 0.9636069894987458
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.61      0.69       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.89      0.93      0.91       306
          14       0.97      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.93      0.93     15211
          18       0.94      0.95      0.95     19633
          19       0.87      0.72      0.79       266
          20       0.97      0.97      0.97      8344
          21       0.87      0.87      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.90      0.68      0.77       115
          27       0.87      0.87      0.87        38
          28       0.89      0.92      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.92      0.94      2051
          35       0.95      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9655058266860882
train_acc 0.9655613328575555

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.71it/s]
valid_weighted_f1: 0.9655853585317989
valid_acc: 0.9656902342587474
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.66      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.93      9782
          13       0.89      0.95      0.92       306
          14       0.97      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.93      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.88      0.71      0.79       266
          20       0.96      0.98      0.97      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.92      0.68      0.78       115
          27       0.92      0.87      0.89        38
          28       0.90      0.91      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.95      0.95      2051
          35       0.95      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9702145106132611
train_acc 0.9702607007527485

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9667096821926817
valid_acc: 0.9668041324773606
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.69      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.90      0.95      0.93       306
          14       0.97      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.87      0.73      0.80       266
          20       0.97      0.98      0.97      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.92      0.70      0.79       115
          27       0.89      0.89      0.89        38
          28       0.90      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.95      0.94      0.94      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.96      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 03:25:41,920] Trial 9 finished with value: 0.9668041324773606 and parameters: {'lrmain': 2e-05, 'drop_out': 0.3}. Best is trial 1 with value: 0.9707835551209557.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.8759340457982782
train_acc 0.8759101374658035

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.68it/s]
valid_weighted_f1: 0.9478008802742354
valid_acc: 0.9479784022788147
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.66      0.50      0.56       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.89      0.89      9782
          13       0.85      0.92      0.88       306
          14       0.90      0.91      0.91       331
          15       1.00      0.98      0.99        66
          16       1.00      0.99      1.00       678
          17       0.90      0.92      0.91     15211
          18       0.94      0.92      0.93     19633
          19       0.89      0.63      0.74       266
          20       0.93      0.96      0.95      8344
          21       1.00      0.33      0.50        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.94      0.90      0.92      2155
          26       0.90      0.50      0.64       115
          27       1.00      0.37      0.54        38
          28       0.86      0.91      0.88       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.95      0.95      2601
          33       0.93      0.95      0.94      4030
          34       0.86      0.90      0.88      2051
          35       0.94      0.91      0.92      3387
          36       0.96      0.95      0.96      1654
          37       0.98      0.94      0.96      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.93      0.88      0.89    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9502678267437058
train_acc 0.950350248933748

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.67it/s]
valid_weighted_f1: 0.961566876076903
valid_acc: 0.9616512903362953
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.65      0.73       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.91      0.92      9782
          13       0.90      0.92      0.91       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.92      0.94      0.93     15211
          18       0.95      0.94      0.94     19633
          19       0.86      0.71      0.78       266
          20       0.97      0.97      0.97      8344
          21       1.00      0.73      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.95      0.94      0.94      2155
          26       0.88      0.68      0.76       115
          27       0.96      0.68      0.80        38
          28       0.89      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.96      0.96      2601
          33       0.94      0.97      0.96      4030
          34       0.94      0.92      0.93      2051
          35       0.95      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.98      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.97      0.92      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9650464276790569
train_acc 0.965088741057926

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.68it/s]
valid_weighted_f1: 0.9660483228776618
valid_acc: 0.9661749075294418
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.71      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.92      0.93      9782
          13       0.88      0.96      0.92       306
          14       0.94      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.94      0.95      0.95     19633
          19       0.87      0.72      0.79       266
          20       0.97      0.98      0.97      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.93      0.62      0.74       115
          27       0.96      0.68      0.80        38
          28       0.89      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.96      0.97      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.41it/s]
train_weighted_f1 0.9733342870520145
train_acc 0.9733691865898625

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9686586197542569
valid_acc: 0.9687428255601378
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.76      0.80       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.89      0.96      0.93       306
          14       0.95      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.87      0.76      0.81       266
          20       0.97      0.98      0.97      8344
          21       1.00      0.73      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.94      0.64      0.76       115
          27       0.94      0.76      0.84        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.94      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.95      0.98      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9788016170452262
train_acc 0.9788257633685069

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.68it/s]
valid_weighted_f1: 0.9688527699812519
valid_acc: 0.9689383954763828
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.79      0.82       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.90      0.96      0.93       306
          14       0.93      0.97      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.87      0.75      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.80      0.80      0.80        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.89      0.70      0.78       115
          27       0.93      0.71      0.81        38
          28       0.89      0.93      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.95      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.41it/s]
train_weighted_f1 0.9828726438573505
train_acc 0.982887928837233

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.67it/s]
valid_weighted_f1: 0.970098619867786
valid_acc: 0.9701543301730369
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.75      0.79       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.92      0.96      0.94       306
          14       0.95      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.88      0.76      0.82       266
          20       0.97      0.98      0.98      8344
          21       0.86      0.80      0.83        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.91      0.73      0.81       115
          27       0.94      0.82      0.87        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.95      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.41it/s]
train_weighted_f1 0.9862217257331016
train_acc 0.9862300555640516

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9706297997684007
valid_acc: 0.9706645125632414
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.91      0.72      0.81       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       1.00      1.00      1.00     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.82      0.79      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.91      0.72      0.81       115
          27       0.97      0.82      0.89        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 03:43:12,341] Trial 10 finished with value: 0.9706645125632414 and parameters: {'lrmain': 4e-05, 'drop_out': 0.0}. Best is trial 1 with value: 0.9707835551209557.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.825468068240898
train_acc 0.8252727226385278

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.71it/s]
valid_weighted_f1: 0.9310773013145814
valid_acc: 0.9313889715573317
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.51      0.29      0.37       101
           5       1.00      0.86      0.92        21
           6       0.99      0.99      0.99      2353
           7       0.97      0.96      0.97      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.84      0.88      0.86      9782
          13       0.83      0.82      0.83       306
          14       0.91      0.81      0.86       331
          15       1.00      0.98      0.99        66
          16       0.99      0.99      0.99       678
          17       0.88      0.89      0.88     15211
          18       0.91      0.90      0.91     19633
          19       0.85      0.60      0.70       266
          20       0.91      0.92      0.92      8344
          21       0.00      0.00      0.00        15
          22       0.98      1.00      0.99      2100
          23       0.98      0.98      0.98      1397
          24       0.99      1.00      0.99       925
          25       0.92      0.85      0.88      2155
          26       0.80      0.46      0.59       115
          27       0.78      0.47      0.59        38
          28       0.79      0.92      0.85       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.93      0.93      0.93      2601
          33       0.91      0.94      0.93      4030
          34       0.85      0.80      0.83      2051
          35       0.91      0.90      0.90      3387
          36       0.95      0.93      0.94      1654
          37       0.97      0.92      0.94      2611
          38       0.93      0.94      0.94       370
          39       0.99      0.98      0.99       270
          40       1.00      0.40      0.57        10
          41       1.00      0.98      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.93    117605
   macro avg       0.88      0.83      0.85    117605
weighted avg       0.93      0.93      0.93    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.41it/s]
train_weighted_f1 0.9270620739786481
train_acc 0.9272314828974869

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.72it/s]
valid_weighted_f1: 0.9494901543969415
valid_acc: 0.9496194889673059
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.58      0.65       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.89      0.89      9782
          13       0.85      0.89      0.87       306
          14       0.95      0.89      0.92       331
          15       1.00      0.98      0.99        66
          16       0.99      1.00      0.99       678
          17       0.90      0.92      0.91     15211
          18       0.93      0.93      0.93     19633
          19       0.88      0.67      0.76       266
          20       0.95      0.94      0.95      8344
          21       1.00      0.33      0.50        15
          22       0.99      1.00      1.00      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.93      0.90      0.92      2155
          26       0.86      0.54      0.66       115
          27       0.88      0.76      0.82        38
          28       0.85      0.95      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.95      0.95      0.95      2601
          33       0.93      0.96      0.94      4030
          34       0.91      0.88      0.89      2051
          35       0.93      0.92      0.92      3387
          36       0.96      0.95      0.96      1654
          37       0.98      0.95      0.96      2611
          38       0.95      0.96      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.93      0.89      0.91    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9461671109097716
train_acc 0.9462509133234779

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.70it/s]
valid_weighted_f1: 0.9574633771622871
valid_acc: 0.9575528251349857
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.64      0.70       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.92      0.91      9782
          13       0.86      0.93      0.89       306
          14       0.98      0.90      0.94       331
          15       1.00      0.98      0.99        66
          16       1.00      1.00      1.00       678
          17       0.92      0.93      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.88      0.69      0.78       266
          20       0.96      0.97      0.96      8344
          21       0.83      0.67      0.74        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.95      0.92      0.93      2155
          26       0.86      0.55      0.67       115
          27       0.84      0.95      0.89        38
          28       0.89      0.92      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.95      0.96      0.96      2601
          33       0.95      0.96      0.95      4030
          34       0.93      0.90      0.92      2051
          35       0.95      0.92      0.93      3387
          36       0.97      0.96      0.96      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9569182469787896
train_acc 0.9569814021851796

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9621799088756791
valid_acc: 0.9622550061647038
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.73      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.92      0.92      9782
          13       0.87      0.95      0.91       306
          14       0.97      0.93      0.95       331
          15       1.00      0.98      0.99        66
          16       1.00      1.00      1.00       678
          17       0.94      0.93      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.87      0.74      0.80       266
          20       0.97      0.97      0.97      8344
          21       0.85      0.73      0.79        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.93      0.59      0.72       115
          27       0.85      0.87      0.86        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.96      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.93      0.93      0.93      2051
          35       0.95      0.93      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9641023509269587
train_acc 0.9641478054748432

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9647375285681185
valid_acc: 0.9648229241953998
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.75      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.89      0.96      0.92       306
          14       0.98      0.93      0.96       331
          15       1.00      0.98      0.99        66
          16       1.00      0.99      1.00       678
          17       0.94      0.93      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.87      0.74      0.80       266
          20       0.96      0.98      0.97      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.93      0.62      0.74       115
          27       0.85      0.92      0.89        38
          28       0.90      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.93      0.94      2051
          35       0.95      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9694751273561751
train_acc 0.9695088018895176

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.68it/s]
valid_weighted_f1: 0.9666292003412472
valid_acc: 0.9667020959993198
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.73      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.93      9782
          13       0.88      0.95      0.92       306
          14       0.97      0.94      0.96       331
          15       1.00      0.98      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.78      0.82       266
          20       0.97      0.98      0.97      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.93      0.58      0.72       115
          27       0.85      0.89      0.87        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.95      0.97      0.96      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.95      0.94      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9737580742879545
train_acc 0.9737865541791983

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.71it/s]
valid_weighted_f1: 0.9680528436726358
valid_acc: 0.9681050975723822
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.75      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.93      9782
          13       0.89      0.95      0.92       306
          14       0.97      0.95      0.96       331
          15       1.00      0.98      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.79      0.82       266
          20       0.97      0.98      0.98      8344
          21       0.80      0.80      0.80        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.93      0.64      0.76       115
          27       0.87      0.89      0.88        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 04:00:42,731] Trial 11 finished with value: 0.9681050975723822 and parameters: {'lrmain': 2e-05, 'drop_out': 0.1}. Best is trial 1 with value: 0.9707835551209557.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.8465958857103268
train_acc 0.846409789128477

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9395102193061414
valid_acc: 0.9397134475575019
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.57      0.38      0.45       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.97      0.97      3217
           8       1.00      1.00      1.00      9748
           9       0.92      1.00      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.85      0.89      0.87      9782
          13       0.84      0.88      0.86       306
          14       0.93      0.84      0.89       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.89      0.91      0.90     15211
          18       0.93      0.90      0.92     19633
          19       0.86      0.62      0.72       266
          20       0.93      0.94      0.93      8344
          21       0.00      0.00      0.00        15
          22       0.98      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.92      0.87      0.89      2155
          26       0.82      0.47      0.60       115
          27       0.76      0.58      0.66        38
          28       0.82      0.92      0.87       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.95      0.94      0.94      2601
          33       0.91      0.95      0.93      4030
          34       0.85      0.85      0.85      2051
          35       0.93      0.89      0.91      3387
          36       0.96      0.94      0.95      1654
          37       0.98      0.93      0.95      2611
          38       0.94      0.95      0.94       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.94    117605
   macro avg       0.89      0.87      0.87    117605
weighted avg       0.94      0.94      0.94    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9363364078606854
train_acc 0.9364624220489032

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.71it/s]
valid_weighted_f1: 0.955481243447655
valid_acc: 0.9555801198928617
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.72      0.60      0.66       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.91      0.90      9782
          13       0.86      0.93      0.90       306
          14       0.97      0.90      0.94       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.91      0.93      0.92     15211
          18       0.94      0.93      0.94     19633
          19       0.88      0.70      0.78       266
          20       0.95      0.96      0.96      8344
          21       0.83      0.67      0.74        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      0.99      1397
          24       0.99      1.00      1.00       925
          25       0.94      0.92      0.93      2155
          26       0.89      0.54      0.67       115
          27       0.83      0.89      0.86        38
          28       0.87      0.93      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.95      0.96      0.95      2601
          33       0.94      0.97      0.95      4030
          34       0.93      0.90      0.91      2051
          35       0.95      0.92      0.94      3387
          36       0.96      0.96      0.96      1654
          37       0.98      0.95      0.97      2611
          38       0.92      0.97      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9536605769089012
train_acc 0.9537359178263751

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9620206568572046
valid_acc: 0.9621274605671527
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.63      0.70       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.91      0.92      9782
          13       0.87      0.95      0.90       306
          14       0.97      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.93      0.93     15211
          18       0.94      0.95      0.94     19633
          19       0.87      0.72      0.79       266
          20       0.97      0.97      0.97      8344
          21       0.86      0.80      0.83        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.93      0.94      2155
          26       0.89      0.57      0.70       115
          27       0.89      0.84      0.86        38
          28       0.86      0.97      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.96      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.93      0.93      2051
          35       0.95      0.93      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9638213164606537
train_acc 0.9638706224193302

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.69it/s]
valid_weighted_f1: 0.9651625428277514
valid_acc: 0.9652565792270736
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.70      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.92      9782
          13       0.87      0.95      0.91       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.94      0.95      0.95     19633
          19       0.87      0.72      0.79       266
          20       0.97      0.98      0.97      8344
          21       0.82      0.93      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.90      0.63      0.74       115
          27       0.89      0.82      0.85        38
          28       0.87      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9705055595728337
train_acc 0.9705453178365703

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.67it/s]
valid_weighted_f1: 0.9676851465914765
valid_acc: 0.9677649759789124
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.72      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.88      0.96      0.92       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.86      0.78      0.81       266
          20       0.97      0.98      0.97      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.92      0.66      0.77       115
          27       0.89      0.84      0.86        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9755198727138085
train_acc 0.9755484188883792

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9688772640195952
valid_acc: 0.9689554015560563
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.74      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.89      0.96      0.92       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.86      0.76      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.86      0.80      0.83        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.95      2155
          26       0.90      0.64      0.75       115
          27       0.91      0.84      0.88        38
          28       0.90      0.93      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.95      0.95      0.95      2051
          35       0.94      0.95      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9790635902056992
train_acc 0.9790880783674024

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9694873189319011
valid_acc: 0.969525105225118
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.74      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.89      0.96      0.93       306
          14       0.95      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.83      0.77      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.91      0.69      0.78       115
          27       0.94      0.82      0.87        38
          28       0.88      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.97      0.96      0.96      4030
          34       0.95      0.96      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 04:18:14,504] Trial 12 finished with value: 0.969525105225118 and parameters: {'lrmain': 3e-05, 'drop_out': 0.2}. Best is trial 1 with value: 0.9707835551209557.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.8334585664990268
train_acc 0.8336328184737728

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9309341709494928
valid_acc: 0.931116874282556
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.48      0.28      0.35       101
           5       1.00      0.86      0.92        21
           6       0.99      0.99      0.99      2353
           7       0.97      0.96      0.97      3217
           8       0.99      1.00      1.00      9748
           9       0.93      1.00      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.83      0.88      0.85      9782
          13       0.84      0.82      0.83       306
          14       0.94      0.81      0.87       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.87      0.90      0.88     15211
          18       0.92      0.89      0.91     19633
          19       0.83      0.61      0.70       266
          20       0.91      0.93      0.92      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      0.98      0.98      1397
          24       0.99      1.00      0.99       925
          25       0.92      0.85      0.88      2155
          26       0.84      0.50      0.62       115
          27       0.79      0.61      0.69        38
          28       0.82      0.91      0.86       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.94      0.93      0.93      2601
          33       0.91      0.94      0.93      4030
          34       0.84      0.82      0.83      2051
          35       0.93      0.89      0.91      3387
          36       0.95      0.94      0.95      1654
          37       0.97      0.92      0.94      2611
          38       0.92      0.95      0.94       370
          39       0.99      0.99      0.99       270
          40       1.00      0.70      0.82        10
          41       1.00      0.99      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.93    117605
   macro avg       0.88      0.85      0.86    117605
weighted avg       0.93      0.93      0.93    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9314551367749153
train_acc 0.9316324276562845

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.75it/s]
valid_weighted_f1: 0.9507130344588233
valid_acc: 0.9508439267037966
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.67      0.51      0.58       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.90      0.89      9782
          13       0.87      0.92      0.89       306
          14       0.96      0.90      0.93       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.91      0.92      0.91     15211
          18       0.94      0.93      0.93     19633
          19       0.88      0.65      0.74       266
          20       0.95      0.95      0.95      8344
          21       0.75      0.40      0.52        15
          22       0.99      1.00      1.00      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      1.00       925
          25       0.93      0.91      0.92      2155
          26       0.90      0.57      0.70       115
          27       0.89      0.84      0.86        38
          28       0.85      0.94      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.94      0.95      0.95      2601
          33       0.94      0.95      0.95      4030
          34       0.90      0.89      0.89      2051
          35       0.94      0.92      0.93      3387
          36       0.97      0.96      0.96      1654
          37       0.97      0.95      0.96      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.92      0.90      0.91    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9492935298889315
train_acc 0.9493721432091213

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.69it/s]
valid_weighted_f1: 0.958544824522079
valid_acc: 0.9586667233535989
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.58      0.67       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.91      0.91      9782
          13       0.89      0.93      0.91       306
          14       0.96      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.93      0.93      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.87      0.70      0.78       266
          20       0.96      0.97      0.96      8344
          21       0.90      0.60      0.72        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.94      0.92      0.93      2155
          26       0.90      0.60      0.72       115
          27       0.89      0.84      0.86        38
          28       0.87      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.96      0.96      2601
          33       0.95      0.96      0.95      4030
          34       0.92      0.91      0.92      2051
          35       0.95      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.92      0.93    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.41it/s]
train_weighted_f1 0.9594323378472225
train_acc 0.9594887937333265

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9629168867890746
valid_acc: 0.9630287827898474
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.70      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.92      9782
          13       0.90      0.95      0.92       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      0.99       678
          17       0.94      0.93      0.93     15211
          18       0.94      0.95      0.95     19633
          19       0.87      0.71      0.78       266
          20       0.96      0.98      0.97      8344
          21       0.91      0.67      0.77        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.90      0.64      0.75       115
          27       0.91      0.82      0.86        38
          28       0.88      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.93      0.93      0.93      2051
          35       0.95      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9665353669047659
train_acc 0.966576608723726

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.73it/s]
valid_weighted_f1: 0.965401140541404
valid_acc: 0.9654861613026657
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.69      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.93      9782
          13       0.90      0.94      0.92       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.93      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.87      0.74      0.80       266
          20       0.97      0.98      0.97      8344
          21       0.91      0.67      0.77        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.92      0.67      0.77       115
          27       0.89      0.87      0.88        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.94      0.94      2051
          35       0.96      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.971499107890165
train_acc 0.9715372296137703

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.67it/s]
valid_weighted_f1: 0.9668323407444411
valid_acc: 0.9668976659155648
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.69      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.91      0.95      0.93       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.74      0.79       266
          20       0.97      0.98      0.97      8344
          21       0.91      0.67      0.77        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.91      0.70      0.79       115
          27       0.92      0.87      0.89        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.96      0.96      0.96      4030
          34       0.94      0.94      0.94      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.41it/s]
train_weighted_f1 0.9755877855981192
train_acc 0.9756163871472022

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9679258450732399
valid_acc: 0.9679945580545045
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.66      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.91      0.94      0.93       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.76      0.80       266
          20       0.97      0.98      0.97      8344
          21       1.00      0.73      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.88      0.72      0.79       115
          27       0.94      0.84      0.89        38
          28       0.89      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 04:35:45,523] Trial 13 finished with value: 0.9679945580545045 and parameters: {'lrmain': 2e-05, 'drop_out': 0.0}. Best is trial 1 with value: 0.9707835551209557.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.860491719908491
train_acc 0.8604760326927325

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9426272232674102
valid_acc: 0.9427915479784023
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.65      0.41      0.50       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.97      0.97      3217
           8       1.00      1.00      1.00      9748
           9       0.94      1.00      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.86      0.89      0.88      9782
          13       0.83      0.85      0.84       306
          14       0.94      0.87      0.90       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.90      0.90      0.90     15211
          18       0.92      0.92      0.92     19633
          19       0.86      0.62      0.72       266
          20       0.93      0.95      0.94      8344
          21       1.00      0.33      0.50        15
          22       0.99      1.00      0.99      2100
          23       1.00      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.94      0.89      0.91      2155
          26       0.83      0.51      0.63       115
          27       0.89      0.66      0.76        38
          28       0.85      0.94      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.95      0.94      0.94      2601
          33       0.92      0.96      0.94      4030
          34       0.87      0.86      0.87      2051
          35       0.94      0.90      0.92      3387
          36       0.96      0.94      0.95      1654
          37       0.97      0.93      0.95      2611
          38       0.95      0.95      0.95       370
          39       0.99      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.94    117605
   macro avg       0.92      0.88      0.89    117605
weighted avg       0.94      0.94      0.94    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.943217199090268
train_acc 0.9433208441657746

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9572975692986108
valid_acc: 0.9573742612984142
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.59      0.67       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.91      0.91      9782
          13       0.87      0.92      0.89       306
          14       0.96      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.91      0.94      0.92     15211
          18       0.94      0.94      0.94     19633
          19       0.84      0.71      0.77       266
          20       0.96      0.96      0.96      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.94      0.93      0.93      2155
          26       0.87      0.59      0.70       115
          27       0.91      0.82      0.86        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.95      0.96      2601
          33       0.94      0.97      0.95      4030
          34       0.91      0.92      0.91      2051
          35       0.95      0.92      0.93      3387
          36       0.97      0.96      0.96      1654
          37       0.98      0.96      0.97      2611
          38       0.94      0.97      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.92      0.93    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9592870190516178
train_acc 0.959340113167151

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.67it/s]
valid_weighted_f1: 0.9636239267065845
valid_acc: 0.9636835168572765
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.72      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.91      0.93      0.92       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.94      0.93     15211
          18       0.95      0.94      0.95     19633
          19       0.86      0.76      0.81       266
          20       0.97      0.97      0.97      8344
          21       0.80      0.80      0.80        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.94      2155
          26       0.88      0.70      0.78       115
          27       0.94      0.82      0.87        38
          28       0.91      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.93      0.94      2051
          35       0.95      0.93      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9682023222724904
train_acc 0.9682439550729809

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9668689326420263
valid_acc: 0.9669401811147486
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.71      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.92      0.94      0.93       306
          14       0.95      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.75      0.80       266
          20       0.97      0.98      0.97      8344
          21       1.00      0.73      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.91      0.72      0.81       115
          27       0.94      0.82      0.87        38
          28       0.91      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.96      0.94      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.97      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.974119358341197
train_acc 0.9741476355541961

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.75it/s]
valid_weighted_f1: 0.968365028283977
valid_acc: 0.9684282130861783
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.74      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.92      0.95      0.93       306
          14       0.95      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.84      0.78      0.81       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.91      0.73      0.81       115
          27       0.91      0.84      0.88        38
          28       0.90      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.41it/s]
train_weighted_f1 0.9785939751067645
train_acc 0.9786154865677729

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.71it/s]
valid_weighted_f1: 0.9691192629807416
valid_acc: 0.9691934866714851
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.73      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.92      0.95      0.94       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.93      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.89      0.77      0.82       266
          20       0.97      0.98      0.98      8344
          21       0.85      0.73      0.79        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.91      0.75      0.82       115
          27       0.91      0.84      0.88        38
          28       0.91      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.98      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.97      0.96      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9822038939696333
train_acc 0.9822231143056193

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.71it/s]
valid_weighted_f1: 0.9698128051883704
valid_acc: 0.9698482207389142
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.89      0.76      0.82       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.92      0.95      0.94       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.84      0.80      0.82       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.93      0.74      0.83       115
          27       0.94      0.82      0.87        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 04:53:16,358] Trial 14 finished with value: 0.9698482207389142 and parameters: {'lrmain': 3e-05, 'drop_out': 0.0}. Best is trial 1 with value: 0.9707835551209557.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.8692418521402981
train_acc 0.869213139963637

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9499348760329286
valid_acc: 0.950138174397347
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.47      0.57       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.87      0.91      0.89      9782
          13       0.84      0.92      0.88       306
          14       0.95      0.89      0.92       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.91      0.92      0.91     15211
          18       0.94      0.92      0.93     19633
          19       0.88      0.62      0.73       266
          20       0.94      0.96      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.95      0.90      0.93      2155
          26       0.89      0.50      0.64       115
          27       0.87      0.68      0.76        38
          28       0.85      0.93      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.95      0.95      0.95      2601
          33       0.93      0.96      0.94      4030
          34       0.88      0.90      0.89      2051
          35       0.95      0.90      0.93      3387
          36       0.96      0.95      0.96      1654
          37       0.98      0.94      0.96      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.91      0.88      0.89    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9479098811886839
train_acc 0.9480117160286147

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.71it/s]
valid_weighted_f1: 0.9619732547518239
valid_acc: 0.9620764423281323
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.62      0.72       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.92      0.92      9782
          13       0.88      0.93      0.90       306
          14       0.97      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.94      0.93     15211
          18       0.95      0.94      0.94     19633
          19       0.85      0.70      0.77       266
          20       0.96      0.97      0.97      8344
          21       0.91      0.67      0.77        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      0.99      1397
          24       0.99      1.00      1.00       925
          25       0.96      0.92      0.94      2155
          26       0.89      0.63      0.73       115
          27       0.89      0.87      0.88        38
          28       0.86      0.95      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.96      0.96      2601
          33       0.94      0.97      0.96      4030
          34       0.94      0.93      0.94      2051
          35       0.95      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.92      0.94    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:40<00:00,  3.73it/s]
train_weighted_f1 0.9634212886822782
train_acc 0.9634766189189649

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9665981764830028
valid_acc: 0.9666850899196463
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.70      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.93      9782
          13       0.91      0.94      0.92       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.95      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.71      0.78       266
          20       0.97      0.98      0.97      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.88      0.69      0.77       115
          27       0.87      0.89      0.88        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.94      0.94      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9721615543034604
train_acc 0.9721999201372958

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9680910494784255
valid_acc: 0.9681986310105862
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.66      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.90      0.96      0.93       306
          14       0.94      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.84      0.76      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.80      0.80      0.80        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.95      2155
          26       0.91      0.65      0.76       115
          27       0.93      0.74      0.82        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9776883700499612
train_acc 0.9777170311464546

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.68it/s]
valid_weighted_f1: 0.9690846340868615
valid_acc: 0.9691764805918116
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.71      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.92      0.92      0.92       306
          14       0.94      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.94      0.96      0.95     19633
          19       0.85      0.77      0.81       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.95      2155
          26       0.86      0.75      0.80       115
          27       0.94      0.76      0.84        38
          28       0.90      0.93      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.41it/s]
train_weighted_f1 0.9819497479458309
train_acc 0.9819661093269443

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.70it/s]
valid_weighted_f1: 0.970066574259031
valid_acc: 0.9701118149738531
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.72      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.90      0.96      0.93       306
          14       0.96      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.85      0.80      0.82       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.93      0.69      0.79       115
          27       0.94      0.79      0.86        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9849641801933748
train_acc 0.984975828787956

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.72it/s]
valid_weighted_f1: 0.9703291875255419
valid_acc: 0.9703669061689554
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.68      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.93      0.95      0.94       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.85      0.80      0.82       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.88      0.77      0.82       115
          27       0.91      0.84      0.88        38
          28       0.90      0.93      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.96      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.98      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 05:11:12,538] Trial 15 finished with value: 0.9703669061689554 and parameters: {'lrmain': 5e-05, 'drop_out': 0.3}. Best is trial 1 with value: 0.9707835551209557.

Process finished with exit code 0
