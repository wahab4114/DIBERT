ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
results/corrected_mlm/params/dibert_NER_mlm_cls_pprediction_30_best.json
selecting grid search sampler
[I 2021-01-28 09:58:29,825] A new study created in memory with name: no-name-1aac59a2-104a-4fc5-bdd1-2c76a4b34a21
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.8744624698328288
train_acc 0.8743596115614009

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9551786343713141
valid_acc: 0.9553845499766166
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.72      0.50      0.59       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.91      0.90      9782
          13       0.86      0.89      0.87       306
          14       0.95      0.88      0.91       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.92      0.92      0.92     15211
          18       0.94      0.93      0.94     19633
          19       0.84      0.61      0.71       266
          20       0.94      0.97      0.96      8344
          21       0.50      0.07      0.12        15
          22       0.99      1.00      0.99      2100
          23       0.99      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.93      0.57      0.70       115
          27       0.85      0.76      0.81        38
          28       0.83      0.95      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.96      2601
          33       0.96      0.95      0.95      4030
          34       0.91      0.93      0.92      2051
          35       0.93      0.94      0.93      3387
          36       0.95      0.98      0.96      1654
          37       0.99      0.95      0.97      2611
          38       0.92      0.96      0.94       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.92      0.89      0.90    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9524875955588665
train_acc 0.9525889534587347

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.9653326107449843
valid_acc: 0.9654521491433188
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.66      0.70       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.92      9782
          13       0.89      0.92      0.90       306
          14       0.95      0.92      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.90      0.70      0.79       266
          20       0.97      0.98      0.97      8344
          21       0.89      0.53      0.67        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.88      0.63      0.73       115
          27       0.88      0.79      0.83        38
          28       0.86      0.94      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.91      0.92    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.31it/s]
train_weighted_f1 0.9657576213467258
train_acc 0.96581302781601

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9686849113719735
valid_acc: 0.968768334679648
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.71      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.90      0.94      0.92       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.85      0.76      0.80       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.88      0.69      0.77       115
          27       0.91      0.76      0.83        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.9731754365275137
train_acc 0.9732098859832459

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.59it/s]
valid_weighted_f1: 0.970641027619496
valid_acc: 0.970707027762425
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.68      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.93      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.80      0.79      0.79       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.88      0.67      0.76       115
          27       0.93      0.68      0.79        38
          28       0.90      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.33it/s]
train_weighted_f1 0.9787610042201449
train_acc 0.978787531222919

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9711257774066584
valid_acc: 0.9711661919136091
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.73      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.81      0.79      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.88      0.73      0.80       115
          27       0.94      0.76      0.84        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.60      1.00      0.75         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.96      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.982492301572467
train_acc 0.982506669385397

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9713059001406639
valid_acc: 0.9713872709493644
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.64      0.70       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.95      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.87      0.76      0.81       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.85      0.76      0.80       115
          27       0.94      0.82      0.87        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9857077027102742
train_acc 0.9857181696147899

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9720861060624287
valid_acc: 0.9721100293354874
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.76      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.95      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.80      0.79      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.90      0.70      0.79       115
          27       0.94      0.82      0.87        38
          28       0.92      0.94      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.97      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.95      0.96      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 10:16:14,868] Trial 0 finished with value: 0.9721100293354874 and parameters: {'lrmain': 5e-05, 'drop_out': 0.2}. Best is trial 0 with value: 0.9721100293354874.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.8602408383717682
train_acc 0.8602933679971453

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.9523842227548944
valid_acc: 0.9526550741890226
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.60      0.35      0.44       101
           5       1.00      0.86      0.92        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.90      0.90      9782
          13       0.87      0.86      0.87       306
          14       0.94      0.89      0.91       331
          15       0.99      1.00      0.99        66
          16       1.00      0.99      0.99       678
          17       0.92      0.91      0.92     15211
          18       0.93      0.93      0.93     19633
          19       0.83      0.62      0.71       266
          20       0.95      0.97      0.96      8344
          21       1.00      0.13      0.24        15
          22       0.98      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.92      0.93      2155
          26       0.89      0.58      0.71       115
          27       0.93      0.74      0.82        38
          28       0.85      0.91      0.88       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.96      2601
          33       0.94      0.96      0.95      4030
          34       0.89      0.93      0.91      2051
          35       0.94      0.92      0.93      3387
          36       0.96      0.97      0.96      1654
          37       0.98      0.95      0.96      2611
          38       0.95      0.94      0.94       370
          39       0.99      0.99      0.99       270
          40       0.91      1.00      0.95        10
          41       1.00      0.99      0.99       229
          42       0.99      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.93      0.88      0.89    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9476950746664263
train_acc 0.9478131212723658

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.96314539860165
valid_acc: 0.9632243527060924
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.68      0.59      0.63       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.91      0.91      0.91       306
          14       0.96      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.93      0.93     15211
          18       0.94      0.95      0.94     19633
          19       0.80      0.72      0.76       266
          20       0.98      0.97      0.97      8344
          21       1.00      0.87      0.93        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.89      0.66      0.76       115
          27       0.87      0.89      0.88        38
          28       0.88      0.93      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.97      0.92      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.94      0.96      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9618720618368157
train_acc 0.9619388370630916

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9676311232991008
valid_acc: 0.9677054547000553
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.68      0.69       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.90      0.95      0.93       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.76      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.91      0.68      0.78       115
          27       0.94      0.84      0.89        38
          28       0.89      0.95      0.92       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.96      0.95      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.95      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:20<00:00,  4.27it/s]
train_weighted_f1 0.9699951304352131
train_acc 0.9700344938913528

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.9696019203088803
valid_acc: 0.9696781599421793
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.61      0.69       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.90      0.95      0.93       306
          14       0.98      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.81      0.77      0.79       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.91      0.65      0.76       115
          27       0.92      0.95      0.94        38
          28       0.90      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9754282565566613
train_acc 0.9754570865405855

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9711671029035174
valid_acc: 0.9711917010331194
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.75      0.73       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.97      0.97      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.80      0.77      0.79       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.88      0.70      0.78       115
          27       0.94      0.87      0.90        38
          28       0.89      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9795075184026407
train_acc 0.9795277480416645

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9718529840288598
valid_acc: 0.9718804472598954
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.73      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.95      0.93       306
          14       0.98      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.84      0.79      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.71      0.79       115
          27       0.88      0.92      0.90        38
          28       0.90      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.97      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.99      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9830296781588455
train_acc 0.9830429814276733

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9726611234400756
valid_acc: 0.9726967390842226
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.74      0.74       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.94      0.93       306
          14       0.97      0.96      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.85      0.77      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.93      0.97        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.97      0.96      2155
          26       0.87      0.70      0.78       115
          27       0.94      0.89      0.92        38
          28       0.94      0.94      0.94       248
          29       0.99      1.00      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.98      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.97      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 10:33:58,019] Trial 1 finished with value: 0.9726967390842226 and parameters: {'lrmain': 4e-05, 'drop_out': 0.2}. Best is trial 1 with value: 0.9726967390842226.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.8678549988938106
train_acc 0.8678612088154831

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9531234359081904
valid_acc: 0.9533353173759619
              precision    recall  f1-score   support

           1       1.00      0.96      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.66      0.45      0.53       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.90      0.90      9782
          13       0.86      0.89      0.87       306
          14       0.92      0.88      0.90       331
          15       0.99      1.00      0.99        66
          16       0.99      0.99      0.99       678
          17       0.91      0.93      0.92     15211
          18       0.94      0.92      0.93     19633
          19       0.83      0.65      0.73       266
          20       0.94      0.97      0.96      8344
          21       0.50      0.07      0.12        15
          22       0.99      1.00      0.99      2100
          23       0.99      1.00      0.99      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.92      0.93      2155
          26       0.86      0.57      0.68       115
          27       0.90      0.71      0.79        38
          28       0.85      0.94      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.95      0.96      2601
          33       0.96      0.95      0.95      4030
          34       0.91      0.92      0.91      2051
          35       0.93      0.94      0.93      3387
          36       0.96      0.97      0.96      1654
          37       0.98      0.95      0.97      2611
          38       0.95      0.93      0.94       370
          39       0.99      1.00      0.99       270
          40       1.00      0.90      0.95        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.92      0.88      0.89    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9509180196370419
train_acc 0.9510458615826409

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9643815780773153
valid_acc: 0.9644913056417669
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.65      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.88      0.94      0.91       306
          14       0.94      0.93      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.71      0.77       266
          20       0.97      0.97      0.97      8344
          21       0.73      0.53      0.62        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.87      0.59      0.70       115
          27       0.90      0.71      0.79        38
          28       0.86      0.94      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.95      0.94      0.94      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.95      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.92      0.93    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9637702144468048
train_acc 0.9638334522777863

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.967722175266663
valid_acc: 0.967815994217933
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.69      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.89      0.94      0.91       306
          14       0.94      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.83      0.74      0.78       266
          20       0.97      0.98      0.97      8344
          21       0.85      0.73      0.79        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.87      0.63      0.73       115
          27       0.93      0.68      0.79        38
          28       0.87      0.98      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:47<00:00,  3.58it/s]
train_weighted_f1 0.9717129582745594
train_acc 0.9717581264549455

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.969919018063906
valid_acc: 0.9699927724161388
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.68      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.90      0.95      0.92       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.81      0.74      0.78       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.85      0.68      0.75       115
          27       0.94      0.82      0.87        38
          28       0.88      0.99      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9767833896003356
train_acc 0.9768111416968276

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9709739700058199
valid_acc: 0.9710471493558948
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.69      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.90      0.95      0.93       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.75      0.79       266
          20       0.97      0.99      0.98      8344
          21       0.85      0.73      0.79        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.84      0.70      0.77       115
          27       0.94      0.87      0.90        38
          28       0.88      0.98      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9809334968045031
train_acc 0.980952957468862

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9718499060086788
valid_acc: 0.9718889502997321
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.74      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.95      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.80      0.78      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.88      0.69      0.77       115
          27       0.97      0.84      0.90        38
          28       0.91      0.96      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9844747576742036
train_acc 0.9844851829195765

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9715651594168685
valid_acc: 0.9716083499851197
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.68      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.96      0.93       306
          14       0.96      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.81      0.78      0.80       266
          20       0.97      0.99      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.88      0.70      0.78       115
          27       0.94      0.82      0.87        38
          28       0.88      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.97      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 10:52:09,732] Trial 2 finished with value: 0.9716083499851197 and parameters: {'lrmain': 4e-05, 'drop_out': 0.1}. Best is trial 1 with value: 0.9726967390842226.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.25it/s]
train_weighted_f1 0.8394994088771883
train_acc 0.8395545530237379

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9461984553140775
valid_acc: 0.9465583946260788
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.51      0.36      0.42       101
           5       1.00      0.86      0.92        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.93      1.00      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.88      0.88      9782
          13       0.82      0.81      0.82       306
          14       0.95      0.86      0.90       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.90      0.91      0.91     15211
          18       0.93      0.92      0.92     19633
          19       0.82      0.58      0.68       266
          20       0.94      0.96      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.95      0.91      0.93      2155
          26       0.85      0.50      0.63       115
          27       0.82      0.71      0.76        38
          28       0.82      0.93      0.87       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.94      0.96      2601
          33       0.93      0.97      0.95      4030
          34       0.91      0.90      0.91      2051
          35       0.94      0.91      0.93      3387
          36       0.94      0.97      0.96      1654
          37       0.98      0.95      0.96      2611
          38       0.92      0.94      0.93       370
          39       0.98      0.97      0.98       270
          40       0.00      0.00      0.00        10
          41       0.99      0.98      0.98       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.87      0.84      0.85    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9403764884112151
train_acc 0.9405553856349085

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.50it/s]
valid_weighted_f1: 0.9596524291559613
valid_acc: 0.9598401428510692
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.56      0.62       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.90      0.91      9782
          13       0.87      0.90      0.88       306
          14       0.96      0.90      0.93       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.93      0.93      0.93     15211
          18       0.93      0.95      0.94     19633
          19       0.88      0.65      0.74       266
          20       0.97      0.97      0.97      8344
          21       1.00      0.33      0.50        15
          22       0.99      1.00      0.99      2100
          23       0.99      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.88      0.58      0.70       115
          27       0.87      0.87      0.87        38
          28       0.84      0.96      0.90       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.97      0.96      4030
          34       0.93      0.94      0.94      2051
          35       0.96      0.92      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      0.90      0.95        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.90      0.91    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.32it/s]
train_weighted_f1 0.9560724907523657
train_acc 0.956166845083346

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.49it/s]
valid_weighted_f1: 0.9654233076081576
valid_acc: 0.9655371795416862
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.65      0.69       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.92      9782
          13       0.89      0.93      0.91       306
          14       0.96      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.72      0.78       266
          20       0.97      0.98      0.97      8344
          21       0.83      0.67      0.74        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.91      0.64      0.76       115
          27       0.89      0.84      0.86        38
          28       0.87      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.97      0.95      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9644417649226757
train_acc 0.9645003908174883

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.968141878797655
valid_acc: 0.9682326431699333
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.65      0.73       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.89      0.96      0.93       306
          14       0.96      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.84      0.77      0.80       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.92      0.67      0.77       115
          27       0.87      0.87      0.87        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.95      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9708236092186748
train_acc 0.9708692290700243

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9694084432351117
valid_acc: 0.9695080991454444
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.66      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.91      0.94      0.92       306
          14       0.97      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.83      0.74      0.78       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.87      0.71      0.78       115
          27       0.87      0.89      0.88        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:44<00:00,  3.65it/s]
train_weighted_f1 0.9747474314735469
train_acc 0.9747784659563984

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9712316435337783
valid_acc: 0.9712852344713235
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.77      0.77       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.89      0.96      0.93       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.83      0.77      0.80       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.94      0.65      0.77       115
          27       0.94      0.84      0.89        38
          28       0.90      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.33it/s]
train_weighted_f1 0.9787473618962607
train_acc 0.9787705391582131

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.9718831019936228
valid_acc: 0.9719484715785893
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.69      0.77       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.89      0.95      0.92       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.85      0.77      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.92      0.66      0.77       115
          27       0.94      0.87      0.90        38
          28       0.91      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 11:11:08,548] Trial 3 finished with value: 0.9719484715785893 and parameters: {'lrmain': 3e-05, 'drop_out': 0.2}. Best is trial 1 with value: 0.9726967390842226.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.33it/s]
train_weighted_f1 0.8276924297088643
train_acc 0.827524171212044

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9466522598524667
valid_acc: 0.9469580374984057
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.55      0.31      0.39       101
           5       1.00      0.71      0.83        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.90      1.00      0.95        65
          11       0.99      0.99      0.99     12278
          12       0.87      0.90      0.89      9782
          13       0.87      0.81      0.84       306
          14       0.92      0.85      0.89       331
          15       1.00      0.98      0.99        66
          16       0.99      0.99      0.99       678
          17       0.90      0.91      0.91     15211
          18       0.93      0.92      0.92     19633
          19       0.81      0.59      0.68       266
          20       0.94      0.95      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.99      0.99      0.99       925
          25       0.95      0.91      0.93      2155
          26       0.83      0.59      0.69       115
          27       0.89      0.63      0.74        38
          28       0.82      0.91      0.86       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.96      0.96      2601
          33       0.92      0.97      0.94      4030
          34       0.90      0.90      0.90      2051
          35       0.95      0.91      0.93      3387
          36       0.95      0.97      0.96      1654
          37       0.98      0.94      0.96      2611
          38       0.94      0.95      0.94       370
          39       0.98      0.98      0.98       270
          40       0.00      0.00      0.00        10
          41       1.00      0.97      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.87      0.84      0.85    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.34it/s]
train_weighted_f1 0.9369660768023257
train_acc 0.9371484766613991

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9594041627347655
valid_acc: 0.9595765486161303
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.71      0.59      0.65       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.94      1.00      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.92      0.91      9782
          13       0.89      0.88      0.89       306
          14       0.96      0.90      0.93       331
          15       1.00      0.98      0.99        66
          16       0.99      0.99      0.99       678
          17       0.93      0.93      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.87      0.63      0.73       266
          20       0.96      0.97      0.97      8344
          21       0.50      0.07      0.12        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.85      0.64      0.73       115
          27       0.92      0.87      0.89        38
          28       0.86      0.94      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.97      2601
          33       0.94      0.97      0.96      4030
          34       0.95      0.93      0.94      2051
          35       0.95      0.93      0.94      3387
          36       0.96      0.97      0.96      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.95      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.92      0.90      0.90    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.35it/s]
train_weighted_f1 0.9534933436021436
train_acc 0.9536031673208611

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.51it/s]
valid_weighted_f1: 0.9642453081175171
valid_acc: 0.9643212448450321
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.59      0.69      0.64       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.92      9782
          13       0.89      0.92      0.91       306
          14       0.97      0.91      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.93      0.94     15211
          18       0.94      0.95      0.95     19633
          19       0.86      0.74      0.79       266
          20       0.97      0.98      0.97      8344
          21       0.83      0.33      0.48        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.86      0.65      0.74       115
          27       0.88      0.97      0.93        38
          28       0.86      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.96      0.94      0.95      2051
          35       0.96      0.93      0.94      3387
          36       0.95      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.95      0.95      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.95      0.92      0.93    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.9628166344792315
train_acc 0.9628840206623507

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.967956574943375
valid_acc: 0.9680370732536882
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.72      0.69      0.71       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.89      0.94      0.92       306
          14       0.96      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.88      0.73      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.85      0.73      0.79        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.87      0.64      0.74       115
          27       0.92      0.89      0.91        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.95      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.95      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.9687353656570876
train_acc 0.9687866391395218

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9695342958353644
valid_acc: 0.9696016325836486
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.69      0.74       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.90      0.94      0.92       306
          14       0.97      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.88      0.74      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.85      0.66      0.75       115
          27       0.92      0.95      0.94        38
          28       0.88      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.94      0.96      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9734557258099038
train_acc 0.9734891930468471

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9705884303327712
valid_acc: 0.9706560095234046
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.71      0.76       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.91      0.94      0.92       306
          14       0.97      0.94      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.87      0.74      0.80       266
          20       0.97      0.99      0.98      8344
          21       0.93      0.87      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.85      0.71      0.77       115
          27       0.95      0.95      0.95        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.96      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.977247007965395
train_acc 0.9772773614721925

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9716642123968419
valid_acc: 0.971727392542834
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.75      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.85      0.74      0.79       266
          20       0.97      0.99      0.98      8344
          21       0.81      0.87      0.84        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.96      2155
          26       0.87      0.68      0.76       115
          27       0.95      0.95      0.95        38
          28       0.90      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 11:28:50,266] Trial 4 finished with value: 0.971727392542834 and parameters: {'lrmain': 3e-05, 'drop_out': 0.3}. Best is trial 1 with value: 0.9726967390842226.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.8551509784528306
train_acc 0.8552817709129836

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.9479506519842802
valid_acc: 0.9482590025934271
              precision    recall  f1-score   support

           1       1.00      0.95      0.97       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.53      0.35      0.42       101
           5       1.00      0.81      0.89        21
           6       1.00      0.99      0.99      2353
           7       0.97      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.94      1.00      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.90      0.89      9782
          13       0.87      0.84      0.86       306
          14       0.94      0.87      0.90       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.91      0.91      0.91     15211
          18       0.94      0.92      0.93     19633
          19       0.83      0.61      0.70       266
          20       0.93      0.96      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.94      0.92      0.93      2155
          26       0.87      0.60      0.71       115
          27       0.87      0.68      0.76        38
          28       0.83      0.89      0.86       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.96      0.96      2601
          33       0.93      0.96      0.94      4030
          34       0.91      0.91      0.91      2051
          35       0.93      0.92      0.93      3387
          36       0.96      0.96      0.96      1654
          37       0.98      0.94      0.96      2611
          38       0.94      0.94      0.94       370
          39       0.98      0.99      0.98       270
          40       1.00      0.10      0.18        10
          41       1.00      0.98      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.90      0.85      0.86    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.38it/s]
train_weighted_f1 0.9472861905109073
train_acc 0.9474297378124416

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.60it/s]
valid_weighted_f1: 0.9607848308077098
valid_acc: 0.960903022830662
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.66      0.58      0.62       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.90      0.91      9782
          13       0.88      0.90      0.89       306
          14       0.96      0.91      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.94      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.86      0.73      0.79       266
          20       0.97      0.97      0.97      8344
          21       0.90      0.60      0.72        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.87      0.62      0.72       115
          27       0.89      0.82      0.85        38
          28       0.85      0.94      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.97      0.96      4030
          34       0.94      0.94      0.94      2051
          35       0.95      0.93      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.95      0.95      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.9609659208713205
train_acc 0.9610435676539056

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9657423334669242
valid_acc: 0.9658347859359722
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.67      0.63      0.65       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.92      9782
          13       0.89      0.92      0.91       306
          14       0.96      0.93      0.94       331
          15       0.99      1.00      0.99        66
          16       1.00      1.00      1.00       678
          17       0.94      0.93      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.73      0.78       266
          20       0.97      0.98      0.97      8344
          21       0.93      0.87      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.87      0.63      0.73       115
          27       0.91      0.82      0.86        38
          28       0.88      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.96      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9691647083900747
train_acc 0.969216750777387

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9682215515339921
valid_acc: 0.9683346796479742
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.65      0.71       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.91      0.93      0.92       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.93      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.86      0.76      0.80       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.89      0.66      0.76       115
          27       0.94      0.79      0.86        38
          28       0.91      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9746009314259837
train_acc 0.9746372194185315

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.67it/s]
valid_weighted_f1: 0.9698683746758576
valid_acc: 0.9699332511372816
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.67      0.72       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.90      0.94      0.92       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.84      0.78      0.81       266
          20       0.97      0.99      0.98      8344
          21       1.00      0.87      0.93        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.90      0.67      0.77       115
          27       0.91      0.84      0.88        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.50      1.00      0.67         3
          32       0.98      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9789425520787864
train_acc 0.9789648858982855

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.970816425387472
valid_acc: 0.9708515794396497
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.70      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.84      0.77      0.80       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.84      0.70      0.76       115
          27       0.91      0.84      0.88        38
          28       0.91      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.43      1.00      0.60         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.96      0.95      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.96      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9823473190434191
train_acc 0.9823622368353979

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.9715274454089596
valid_acc: 0.9715743378257727
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.72      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.86      0.78      0.82       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.84      0.70      0.77       115
          27       0.92      0.89      0.91        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.50      1.00      0.67         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.96      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 11:46:24,783] Trial 5 finished with value: 0.9715743378257727 and parameters: {'lrmain': 3e-05, 'drop_out': 0.0}. Best is trial 1 with value: 0.9726967390842226.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.823944130356625
train_acc 0.8240885881293436

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.939012517062586
valid_acc: 0.9395008715615832
              precision    recall  f1-score   support

           1       0.98      0.96      0.97       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.45      0.19      0.27       101
           5       1.00      0.43      0.60        21
           6       1.00      0.99      0.99      2353
           7       0.97      0.97      0.97      3217
           8       0.99      1.00      0.99      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.86      0.87      0.87      9782
          13       0.84      0.80      0.82       306
          14       0.89      0.81      0.85       331
          15       1.00      0.94      0.97        66
          16       0.99      0.99      0.99       678
          17       0.89      0.90      0.89     15211
          18       0.91      0.92      0.92     19633
          19       0.84      0.57      0.68       266
          20       0.93      0.94      0.94      8344
          21       0.00      0.00      0.00        15
          22       0.98      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.98      0.99      0.99       925
          25       0.93      0.90      0.92      2155
          26       0.85      0.48      0.61       115
          27       0.81      0.34      0.48        38
          28       0.81      0.91      0.86       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.95      0.95      2601
          33       0.92      0.95      0.94      4030
          34       0.89      0.89      0.89      2051
          35       0.93      0.90      0.91      3387
          36       0.95      0.96      0.95      1654
          37       0.97      0.93      0.95      2611
          38       0.90      0.95      0.92       370
          39       0.98      0.98      0.98       270
          40       0.00      0.00      0.00        10
          41       1.00      0.98      0.99       229
          42       0.99      0.98      0.98       405

    accuracy                           0.94    117605
   macro avg       0.86      0.81      0.83    117605
weighted avg       0.94      0.94      0.94    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9375308407752422
train_acc 0.9377601909908073

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.67it/s]
valid_weighted_f1: 0.9549129328700521
valid_acc: 0.9550869435823307
              precision    recall  f1-score   support

           1       0.99      0.96      0.97       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.64      0.47      0.54       101
           5       1.00      0.90      0.95        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.91      0.90      9782
          13       0.87      0.87      0.87       306
          14       0.96      0.88      0.92       331
          15       1.00      0.97      0.98        66
          16       0.99      0.99      0.99       678
          17       0.92      0.92      0.92     15211
          18       0.93      0.94      0.93     19633
          19       0.86      0.66      0.74       266
          20       0.96      0.96      0.96      8344
          21       0.67      0.27      0.38        15
          22       0.99      1.00      0.99      2100
          23       0.99      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.92      0.93      2155
          26       0.85      0.58      0.69       115
          27       0.82      0.87      0.85        38
          28       0.86      0.93      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.96      0.96      2601
          33       0.94      0.97      0.95      4030
          34       0.93      0.92      0.93      2051
          35       0.94      0.92      0.93      3387
          36       0.95      0.97      0.96      1654
          37       0.98      0.95      0.97      2611
          38       0.94      0.96      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.92      0.89      0.90    117605
weighted avg       0.95      0.96      0.95    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9529174637670009
train_acc 0.9530360571613057

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9617145712244233
valid_acc: 0.9618383572127035
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.71      0.54      0.61       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.92      0.92      9782
          13       0.87      0.91      0.89       306
          14       0.97      0.90      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.93      0.93     15211
          18       0.94      0.95      0.94     19633
          19       0.85      0.71      0.77       266
          20       0.97      0.97      0.97      8344
          21       0.83      0.67      0.74        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.87      0.58      0.70       115
          27       0.85      0.92      0.89        38
          28       0.86      0.95      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.94      0.94      2051
          35       0.96      0.93      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.93      0.96      0.94       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9615703581290261
train_acc 0.961647847955005

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9652877944700332
valid_acc: 0.9653926278644616
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.60      0.67       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.93      0.92      9782
          13       0.89      0.92      0.91       306
          14       0.97      0.91      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.93      0.94     15211
          18       0.95      0.94      0.95     19633
          19       0.85      0.74      0.79       266
          20       0.97      0.98      0.97      8344
          21       0.77      0.67      0.71        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.90      0.61      0.73       115
          27       0.86      0.95      0.90        38
          28       0.87      0.93      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.93      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.95      0.96      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.92      0.92    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9678485919825505
train_acc 0.9679030517748212

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.9678860469437629
valid_acc: 0.9679605458951576
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.61      0.69       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.89      0.94      0.92       306
          14       0.97      0.94      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.83      0.78      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.91      0.63      0.75       115
          27       0.88      0.97      0.93        38
          28       0.88      0.93      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.96      0.96      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.94      0.96      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.9724342412587269
train_acc 0.9724749791847207

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9692906272039764
valid_acc: 0.9693465413885464
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.69      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.89      0.95      0.92       306
          14       0.97      0.94      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.82      0.77      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.90      0.63      0.74       115
          27       0.88      0.95      0.91        38
          28       0.87      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.96      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9758990975974358
train_acc 0.9759296783402152

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9705215073684178
valid_acc: 0.9705539730453637
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.70      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.90      0.94      0.92       306
          14       0.97      0.94      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.82      0.79      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.89      0.69      0.77       115
          27       0.88      0.95      0.91        38
          28       0.89      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 12:03:58,728] Trial 6 finished with value: 0.9705539730453637 and parameters: {'lrmain': 2e-05, 'drop_out': 0.0}. Best is trial 1 with value: 0.9726967390842226.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.880747094552979
train_acc 0.880547909126438

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.60it/s]
valid_weighted_f1: 0.9564641111777625
valid_acc: 0.9566855150716381
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.66      0.49      0.56       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.92      0.90      9782
          13       0.85      0.92      0.88       306
          14       0.92      0.90      0.91       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.93      0.92      0.92     15211
          18       0.94      0.93      0.94     19633
          19       0.83      0.64      0.72       266
          20       0.95      0.97      0.96      8344
          21       0.67      0.13      0.22        15
          22       0.99      1.00      1.00      2100
          23       0.99      1.00      0.99      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.92      0.94      2155
          26       0.88      0.50      0.64       115
          27       0.91      0.55      0.69        38
          28       0.83      0.94      0.88       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.97      2601
          33       0.94      0.96      0.95      4030
          34       0.92      0.94      0.93      2051
          35       0.96      0.92      0.94      3387
          36       0.95      0.98      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.94      0.95       370
          39       0.99      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.92      0.88      0.89    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9552516708010708
train_acc 0.9553395439329833

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9657905681733987
valid_acc: 0.9658943072148293
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.68      0.64      0.66       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.92      9782
          13       0.89      0.96      0.92       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.93      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.83      0.75      0.79       266
          20       0.97      0.98      0.97      8344
          21       0.86      0.80      0.83        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.89      0.66      0.76       115
          27       0.91      0.82      0.86        38
          28       0.89      0.92      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.95      0.95      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9676765659246217
train_acc 0.9677193250751899

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.68it/s]
valid_weighted_f1: 0.9691557791522334
valid_acc: 0.9692104927511586
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.70      0.73       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.90      0.95      0.92       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.79      0.79      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.88      0.93      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.88      0.68      0.76       115
          27       0.91      0.84      0.88        38
          28       0.88      0.94      0.90       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.95      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.97      0.95      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9751188321347467
train_acc 0.9751427333435285

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9708933573810961
valid_acc: 0.9709451128778538
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.73      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.83      0.76      0.80       266
          20       0.97      0.99      0.98      8344
          21       0.82      0.93      0.87        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.88      0.74      0.80       115
          27       0.92      0.87      0.89        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.98      0.97      0.98      2601
          33       0.96      0.97      0.97      4030
          34       0.97      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9803302947676409
train_acc 0.9803497391718068

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9722505046940882
valid_acc: 0.9722800901322223
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.70      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.79      0.80      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.84      0.73      0.78       115
          27       0.92      0.89      0.91        38
          28       0.91      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9843453933101108
train_acc 0.984355618426195

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9719677298664707
valid_acc: 0.9719824837379363
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.73      0.77       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.98      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.82      0.79      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.88      0.73      0.80       115
          27       0.86      0.95      0.90        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9870413404721782
train_acc 0.9870477986780174

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.60it/s]
valid_weighted_f1: 0.9720085744784618
valid_acc: 0.97202499893712
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.75      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.93      0.96      0.94       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.81      0.78      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.85      0.76      0.80       115
          27       0.85      0.87      0.86        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.60      1.00      0.75         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 12:21:33,306] Trial 7 finished with value: 0.97202499893712 and parameters: {'lrmain': 5e-05, 'drop_out': 0.1}. Best is trial 1 with value: 0.9726967390842226.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.8666859706263367
train_acc 0.8666165400757846

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9544835465274065
valid_acc: 0.9546873007100038
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.68      0.50      0.57       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.92      0.90      9782
          13       0.85      0.87      0.86       306
          14       0.95      0.89      0.92       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.93      0.91      0.92     15211
          18       0.94      0.93      0.93     19633
          19       0.83      0.64      0.72       266
          20       0.95      0.97      0.96      8344
          21       1.00      0.07      0.12        15
          22       0.99      1.00      0.99      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.92      0.94      2155
          26       0.90      0.50      0.64       115
          27       0.88      0.74      0.80        38
          28       0.85      0.92      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.96      2601
          33       0.94      0.97      0.95      4030
          34       0.90      0.94      0.92      2051
          35       0.95      0.92      0.94      3387
          36       0.95      0.97      0.96      1654
          37       0.98      0.96      0.97      2611
          38       0.92      0.95      0.94       370
          39       0.99      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.93      0.88      0.89    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9503035166632804
train_acc 0.9504245892168357

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9650463829108611
valid_acc: 0.9651545427490328
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.63      0.69       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.90      0.92      0.91       306
          14       0.96      0.90      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.71      0.77       266
          20       0.97      0.98      0.97      8344
          21       1.00      0.60      0.75        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.89      0.65      0.75       115
          27       0.89      0.84      0.86        38
          28       0.87      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.93      0.96      0.94       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9640690808251555
train_acc 0.9641393094424904

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9683133127452933
valid_acc: 0.9683856978869946
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.65      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.93      9782
          13       0.91      0.94      0.92       306
          14       0.97      0.92      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.82      0.77      0.79       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.87      0.67      0.75       115
          27       0.90      0.92      0.91        38
          28       0.89      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.95      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.95      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9718621171834796
train_acc 0.9719089310292094

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9704633232991039
valid_acc: 0.9705284639258535
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.76      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.91      0.95      0.93       306
          14       0.97      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.81      0.80      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.94      1.00      0.97        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.69      0.77       115
          27       0.90      0.92      0.91        38
          28       0.91      0.94      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.97      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.96      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9772887390412288
train_acc 0.9773166556218246

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9715097030673793
valid_acc: 0.9715488287062625
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.78      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.93      0.94      0.94       306
          14       0.97      0.94      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.80      0.77      0.79       266
          20       0.98      0.98      0.98      8344
          21       1.00      1.00      1.00        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.87      0.73      0.79       115
          27       0.90      0.95      0.92        38
          28       0.91      0.94      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9814142362503815
train_acc 0.9814308592887122

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9720903421881929
valid_acc: 0.9721355384549977
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.78      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.95      0.94       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.84      0.78      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.94      1.00      0.97        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.70      0.78       115
          27       0.90      0.92      0.91        38
          28       0.93      0.95      0.94       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9845142933705269
train_acc 0.9845255390732528

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9723957967207801
valid_acc: 0.9724246418094469
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.77      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.90      0.95      0.93       306
          14       0.98      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.81      0.80      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.93      0.97        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.87      0.71      0.78       115
          27       0.90      0.95      0.92        38
          28       0.93      0.96      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 12:39:07,518] Trial 8 finished with value: 0.9724246418094469 and parameters: {'lrmain': 5e-05, 'drop_out': 0.3}. Best is trial 1 with value: 0.9726967390842226.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.38it/s]
train_weighted_f1 0.8872831427445355
train_acc 0.8870675519532378

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.9572617813310479
valid_acc: 0.9574677947366184
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.66      0.56      0.61       101
           5       0.95      0.95      0.95        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.99      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.91      0.91      9782
          13       0.87      0.87      0.87       306
          14       0.92      0.90      0.91       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.92      0.93      0.92     15211
          18       0.94      0.93      0.94     19633
          19       0.86      0.64      0.74       266
          20       0.95      0.97      0.96      8344
          21       0.75      0.20      0.32        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.94      2155
          26       0.86      0.57      0.68       115
          27       0.88      0.61      0.72        38
          28       0.88      0.91      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.97      2601
          33       0.95      0.96      0.95      4030
          34       0.92      0.93      0.93      2051
          35       0.94      0.94      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.94      0.94       370
          39       0.99      0.99      0.99       270
          40       1.00      0.90      0.95        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.92      0.89      0.90    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.9580034571717334
train_acc 0.9580911964112759

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9657257754717022
valid_acc: 0.9658177798562986
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.65      0.74      0.69       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.91      0.92      9782
          13       0.88      0.94      0.91       306
          14       0.94      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.94      0.96      0.95     19633
          19       0.84      0.76      0.80       266
          20       0.97      0.98      0.97      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.92      0.57      0.71       115
          27       0.93      0.74      0.82        38
          28       0.86      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.95      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9696504714650662
train_acc 0.9696967766053253

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9696337237347582
valid_acc: 0.9697291781811997
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.71      0.67      0.69       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.90      0.94      0.92       306
          14       0.94      0.97      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.84      0.75      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.87      0.67      0.75       115
          27       0.96      0.71      0.82        38
          28       0.87      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.97      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9770949275330754
train_acc 0.9771233708857964

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.68it/s]
valid_weighted_f1: 0.9705062645147415
valid_acc: 0.9705624760852004
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.69      0.68      0.69       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.90      0.95      0.93       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.83      0.80      0.82       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.89      0.68      0.77       115
          27       0.97      0.82      0.89        38
          28       0.88      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.94      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9821841770816436
train_acc 0.9822008122206929

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.67it/s]
valid_weighted_f1: 0.972040125262728
valid_acc: 0.9720760171761405
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.72      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.95      0.93       306
          14       0.94      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.81      0.79      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.86      0.80      0.83        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.83      0.74      0.78       115
          27       1.00      0.68      0.81        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.99      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.38it/s]
train_weighted_f1 0.9856187488851987
train_acc 0.9856289612750845

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9723706949327872
valid_acc: 0.9723906296500999
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.71      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.91      0.96      0.94       306
          14       0.95      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.81      0.79      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.87      0.73      0.79       115
          27       1.00      0.74      0.85        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.99      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9884668458991526
train_acc 0.9884730081052149

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.97264699056748
valid_acc: 0.9726372178053654
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.68      0.76      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.96      0.97      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.84      0.79      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.87      0.73      0.79       115
          27       0.97      0.84      0.90        38
          28       0.89      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.96      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.98      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 12:56:42,789] Trial 9 finished with value: 0.9726372178053654 and parameters: {'lrmain': 5e-05, 'drop_out': 0.0}. Best is trial 1 with value: 0.9726967390842226.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.38it/s]
train_weighted_f1 0.8752039264776028
train_acc 0.8751816026915431

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9530685155532007
valid_acc: 0.9533268143361252
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.64      0.43      0.51       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.91      0.90      9782
          13       0.84      0.90      0.87       306
          14       0.94      0.88      0.91       331
          15       1.00      0.98      0.99        66
          16       1.00      0.99      0.99       678
          17       0.92      0.91      0.92     15211
          18       0.94      0.93      0.93     19633
          19       0.88      0.62      0.73       266
          20       0.94      0.97      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       1.00      1.00      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.96      0.92      0.94      2155
          26       0.88      0.51      0.65       115
          27       0.90      0.68      0.78        38
          28       0.84      0.92      0.88       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.95      0.96      2601
          33       0.95      0.95      0.95      4030
          34       0.92      0.93      0.92      2051
          35       0.93      0.93      0.93      3387
          36       0.95      0.97      0.96      1654
          37       0.98      0.95      0.96      2611
          38       0.95      0.95      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      0.40      0.57        10
          41       1.00      0.98      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.90      0.86      0.88    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9535862609727691
train_acc 0.9536913136565224

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.9637940889063391
valid_acc: 0.9639556141320522
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.61      0.67       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.91      0.92      9782
          13       0.89      0.95      0.92       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.93      0.94     15211
          18       0.94      0.95      0.95     19633
          19       0.86      0.69      0.77       266
          20       0.97      0.98      0.97      8344
          21       0.80      0.53      0.64        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.89      0.59      0.71       115
          27       0.88      0.79      0.83        38
          28       0.90      0.91      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.92      0.97      0.94       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.38it/s]
train_weighted_f1 0.9662689131290428
train_acc 0.9663270377733598

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9676209985935279
valid_acc: 0.9677309638195655
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.72      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.93      9782
          13       0.90      0.94      0.92       306
          14       0.97      0.92      0.94       331
          15       0.99      1.00      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.86      0.73      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.84      0.64      0.73       115
          27       0.92      0.87      0.89        38
          28       0.90      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.96      0.95      0.96      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.95      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.9736236069943645
train_acc 0.9736591136939049

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9700959269683541
valid_acc: 0.970179839292547
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.65      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.91      0.95      0.93       306
          14       0.96      0.95      0.96       331
          15       0.99      1.00      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.83      0.77      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.71      0.67      0.69        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.87      0.67      0.75       115
          27       0.92      0.87      0.89        38
          28       0.91      0.97      0.94       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9789032730305112
train_acc 0.9789266537526975

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9712192674408011
valid_acc: 0.9712767314314867
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.70      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.97      0.95      0.96       331
          15       0.99      1.00      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.84      0.77      0.80       266
          20       0.97      0.99      0.98      8344
          21       0.86      0.80      0.83        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.86      0.70      0.78       115
          27       0.90      0.92      0.91        38
          28       0.93      0.96      0.94       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.60      1.00      0.75         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.96      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9829281590900046
train_acc 0.9829431530475268

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9716987071936395
valid_acc: 0.9717358955826708
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.68      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.95      0.93       306
          14       0.95      0.95      0.95       331
          15       0.99      1.00      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.82      0.79      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.84      0.70      0.76       115
          27       0.89      0.87      0.88        38
          28       0.92      0.94      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.60      1.00      0.75         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9860213729984049
train_acc 0.9860293367997145

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9718098656091864
valid_acc: 0.9718549381403851
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.66      0.71       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.97      0.95      0.96       331
          15       0.99      1.00      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.85      0.79      0.82       266
          20       0.97      0.99      0.98      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.84      0.70      0.76       115
          27       0.90      0.92      0.91        38
          28       0.91      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.97      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 13:14:19,132] Trial 10 finished with value: 0.9718549381403851 and parameters: {'lrmain': 4e-05, 'drop_out': 0.0}. Best is trial 1 with value: 0.9726967390842226.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.8153297212285149
train_acc 0.8150318176411616

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9382256221503074
valid_acc: 0.9385825432592152
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.45      0.33      0.38       101
           5       1.00      0.38      0.55        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.97      0.97      3217
           8       0.99      1.00      0.99      9748
           9       0.93      1.00      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.86      0.88      0.87      9782
          13       0.82      0.80      0.81       306
          14       0.89      0.79      0.84       331
          15       0.99      1.00      0.99        66
          16       0.99      0.99      0.99       678
          17       0.88      0.90      0.89     15211
          18       0.92      0.91      0.91     19633
          19       0.82      0.58      0.68       266
          20       0.93      0.94      0.93      8344
          21       0.00      0.00      0.00        15
          22       0.98      1.00      0.99      2100
          23       1.00      0.99      0.99      1397
          24       0.99      0.99      0.99       925
          25       0.93      0.91      0.92      2155
          26       0.88      0.43      0.58       115
          27       0.80      0.42      0.55        38
          28       0.82      0.92      0.87       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.94      0.96      0.95      2601
          33       0.92      0.96      0.94      4030
          34       0.91      0.87      0.89      2051
          35       0.94      0.90      0.92      3387
          36       0.94      0.95      0.95      1654
          37       0.98      0.92      0.95      2611
          38       0.92      0.92      0.92       370
          39       0.97      0.98      0.98       270
          40       0.00      0.00      0.00        10
          41       1.00      0.98      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.94    117605
   macro avg       0.86      0.82      0.83    117605
weighted avg       0.94      0.94      0.94    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9331614850501134
train_acc 0.9333826103209801

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9548728438068161
valid_acc: 0.9550954466221674
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.71      0.50      0.58       101
           5       1.00      0.90      0.95        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.91      0.90      9782
          13       0.86      0.86      0.86       306
          14       0.93      0.90      0.92       331
          15       0.96      1.00      0.98        66
          16       0.99      0.99      0.99       678
          17       0.92      0.91      0.92     15211
          18       0.93      0.94      0.93     19633
          19       0.88      0.62      0.72       266
          20       0.95      0.96      0.96      8344
          21       1.00      0.20      0.33        15
          22       0.99      1.00      0.99      2100
          23       0.99      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.87      0.54      0.67       115
          27       0.87      0.71      0.78        38
          28       0.85      0.94      0.89       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.96      0.96      2601
          33       0.94      0.96      0.95      4030
          34       0.93      0.92      0.92      2051
          35       0.95      0.93      0.94      3387
          36       0.95      0.97      0.96      1654
          37       0.98      0.95      0.97      2611
          38       0.95      0.94      0.94       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.89      0.90    117605
weighted avg       0.96      0.96      0.95    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9499536382227796
train_acc 0.9500635078418379

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9614237100205234
valid_acc: 0.9615407508184176
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.67      0.69       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.93      0.92      9782
          13       0.91      0.92      0.91       306
          14       0.95      0.91      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.93      0.93     15211
          18       0.95      0.94      0.94     19633
          19       0.88      0.64      0.74       266
          20       0.96      0.98      0.97      8344
          21       0.91      0.67      0.77        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.93      0.94      2155
          26       0.88      0.66      0.76       115
          27       0.88      0.79      0.83        38
          28       0.86      0.97      0.91       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.97      0.97      2601
          33       0.94      0.97      0.96      4030
          34       0.95      0.93      0.94      2051
          35       0.96      0.92      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.96      0.97      2611
          38       0.94      0.95      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.9588800797810424
train_acc 0.9589577917112708

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9650786642929063
valid_acc: 0.965180051868543
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.67      0.71       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.94      0.92      9782
          13       0.89      0.94      0.92       306
          14       0.95      0.92      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.93      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.67      0.76       266
          20       0.97      0.98      0.97      8344
          21       0.91      0.67      0.77        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.92      0.67      0.77       115
          27       0.91      0.76      0.83        38
          28       0.89      0.94      0.91       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.97      0.96      4030
          34       0.96      0.95      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.96      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9652734077374654
train_acc 0.9653276919678511

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.967867581111623
valid_acc: 0.9679520428553208
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.69      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.90      0.94      0.92       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.96      0.95      0.95     19633
          19       0.87      0.71      0.78       266
          20       0.97      0.98      0.98      8344
          21       0.91      0.67      0.77        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.90      0.67      0.77       115
          27       0.91      0.84      0.88        38
          28       0.90      0.93      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9699810076747923
train_acc 0.9700281218670881

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.70it/s]
valid_weighted_f1: 0.9689680922515741
valid_acc: 0.9690404319544237
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.71      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.91      0.94      0.93       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.95      0.95     19633
          19       0.87      0.72      0.79       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.67      0.80        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.88      0.70      0.78       115
          27       0.94      0.84      0.89        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9736515769223499
train_acc 0.9736846017909636

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9699524290211707
valid_acc: 0.9700012754559755
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.67      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.95      0.93      9782
          13       0.91      0.96      0.93       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.82      0.76      0.79       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.67      0.80        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.89      0.70      0.79       115
          27       0.94      0.84      0.89        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 13:31:53,772] Trial 11 finished with value: 0.9700012754559755 and parameters: {'lrmain': 2e-05, 'drop_out': 0.1}. Best is trial 1 with value: 0.9726967390842226.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.38it/s]
train_weighted_f1 0.8009832562046026
train_acc 0.8008168935107305

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.59it/s]
valid_weighted_f1: 0.9369778439737606
valid_acc: 0.9374941541601123
              precision    recall  f1-score   support

           1       0.98      0.97      0.97       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.44      0.15      0.22       101
           5       1.00      0.43      0.60        21
           6       1.00      0.99      0.99      2353
           7       0.97      0.98      0.97      3217
           8       0.99      1.00      0.99      9748
           9       0.94      1.00      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.85      0.87      0.86      9782
          13       0.84      0.76      0.80       306
          14       0.91      0.79      0.85       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.89      0.89      0.89     15211
          18       0.91      0.91      0.91     19633
          19       0.82      0.56      0.67       266
          20       0.93      0.93      0.93      8344
          21       0.00      0.00      0.00        15
          22       0.98      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.93      0.89      0.91      2155
          26       0.85      0.46      0.60       115
          27       0.79      0.50      0.61        38
          28       0.82      0.88      0.85       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.95      0.95      2601
          33       0.92      0.96      0.94      4030
          34       0.88      0.88      0.88      2051
          35       0.93      0.89      0.91      3387
          36       0.95      0.95      0.95      1654
          37       0.98      0.93      0.95      2611
          38       0.89      0.94      0.92       370
          39       0.98      0.97      0.98       270
          40       0.00      0.00      0.00        10
          41       1.00      0.97      0.98       229
          42       0.99      0.98      0.99       405

    accuracy                           0.94    117605
   macro avg       0.86      0.81      0.83    117605
weighted avg       0.94      0.94      0.94    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.9280906331505082
train_acc 0.9283349050993186

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9536335396459964
valid_acc: 0.9538284936864929
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.59      0.48      0.52       101
           5       1.00      0.90      0.95        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.91      0.90      9782
          13       0.87      0.89      0.88       306
          14       0.96      0.88      0.92       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.91      0.92      0.92     15211
          18       0.94      0.93      0.93     19633
          19       0.86      0.64      0.73       266
          20       0.96      0.96      0.96      8344
          21       0.50      0.07      0.12        15
          22       0.99      1.00      0.99      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.93      0.94      2155
          26       0.89      0.56      0.68       115
          27       0.86      0.82      0.84        38
          28       0.87      0.93      0.90       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.97      0.95      4030
          34       0.93      0.91      0.92      2051
          35       0.94      0.92      0.93      3387
          36       0.96      0.97      0.96      1654
          37       0.98      0.95      0.97      2611
          38       0.93      0.95      0.94       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.92      0.89      0.89    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9458034126207707
train_acc 0.9459450561587739

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9599090659672416
valid_acc: 0.9600357127673144
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.65      0.54      0.59       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.92      0.91      9782
          13       0.91      0.91      0.91       306
          14       0.95      0.89      0.92       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.93      0.92      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.86      0.67      0.75       266
          20       0.96      0.97      0.97      8344
          21       0.75      0.40      0.52        15
          22       0.99      1.00      0.99      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.94      2155
          26       0.88      0.67      0.76       115
          27       0.89      0.84      0.86        38
          28       0.87      0.96      0.91       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.97      0.97      2601
          33       0.94      0.97      0.95      4030
          34       0.95      0.92      0.93      2051
          35       0.95      0.93      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.93      0.95      0.94       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.90      0.91    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.38it/s]
train_weighted_f1 0.955726832287427
train_acc 0.9558195697609216

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.963927389969819
valid_acc: 0.9640576506100931
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.58      0.65       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.93      0.92      9782
          13       0.89      0.92      0.91       306
          14       0.96      0.91      0.94       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      0.99       678
          17       0.94      0.93      0.93     15211
          18       0.95      0.95      0.95     19633
          19       0.87      0.68      0.76       266
          20       0.96      0.98      0.97      8344
          21       0.80      0.53      0.64        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.89      0.63      0.73       115
          27       0.89      0.87      0.88        38
          28       0.88      0.96      0.92       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.95      0.94      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.95      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9622204432013816
train_acc 0.962295670421913

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.60it/s]
valid_weighted_f1: 0.9665835947018345
valid_acc: 0.9666850899196463
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.61      0.70       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.91      0.94      0.93      9782
          13       0.89      0.94      0.92       306
          14       0.97      0.91      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.93      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.87      0.70      0.78       266
          20       0.97      0.98      0.97      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.87      0.66      0.75       115
          27       0.89      0.87      0.88        38
          28       0.88      0.96      0.92       248
          29       1.00      0.98      0.99        66
          30       1.00      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.95      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.9673734355827717
train_acc 0.9674315219792357

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9684935692807728
valid_acc: 0.9685642617235661
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.68      0.74       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.90      0.94      0.92       306
          14       0.97      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.96      0.95      0.95     19633
          19       0.87      0.74      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.90      0.60      0.72        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.89      0.69      0.77       115
          27       0.88      0.92      0.90        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9714801605676626
train_acc 0.9715244855652411

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.60it/s]
valid_weighted_f1: 0.9698530741543916
valid_acc: 0.9699162450576081
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.70      0.75       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.90      0.96      0.93       306
          14       0.96      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.87      0.75      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.85      0.73      0.79        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.92      0.66      0.77       115
          27       0.89      0.87      0.88        38
          28       0.88      0.97      0.93       248
          29       1.00      0.98      0.99        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.97      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 13:49:29,771] Trial 12 finished with value: 0.9699162450576081 and parameters: {'lrmain': 2e-05, 'drop_out': 0.2}. Best is trial 1 with value: 0.9726967390842226.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.851483093921275
train_acc 0.8512918217192571

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9520168248202944
valid_acc: 0.9522554313166958
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.59      0.42      0.49       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.91      0.90      9782
          13       0.88      0.87      0.87       306
          14       0.95      0.87      0.91       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.91      0.92      0.92     15211
          18       0.94      0.93      0.93     19633
          19       0.84      0.61      0.70       266
          20       0.94      0.97      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.89      0.57      0.69       115
          27       0.82      0.74      0.78        38
          28       0.84      0.92      0.88       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.96      2601
          33       0.93      0.96      0.95      4030
          34       0.92      0.92      0.92      2051
          35       0.94      0.92      0.93      3387
          36       0.96      0.97      0.96      1654
          37       0.99      0.94      0.96      2611
          38       0.94      0.94      0.94       370
          39       0.99      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.90      0.88      0.89    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9456241107204517
train_acc 0.9457698254914955

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9628226280509046
valid_acc: 0.9629352493516432
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.71      0.58      0.64       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.92      0.92      9782
          13       0.90      0.90      0.90       306
          14       0.96      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.93      0.93      0.93     15211
          18       0.95      0.94      0.95     19633
          19       0.85      0.68      0.76       266
          20       0.96      0.98      0.97      8344
          21       1.00      0.40      0.57        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.87      0.66      0.75       115
          27       0.89      0.82      0.85        38
          28       0.86      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.96      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.94      0.94      2051
          35       0.96      0.93      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.96      0.97      2611
          38       0.95      0.95      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.92      0.93    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:30<00:00,  4.00it/s]
train_weighted_f1 0.960392354298866
train_acc 0.9604722094781737

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9672130082995809
valid_acc: 0.9673228179074019
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.72      0.75      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.90      0.95      0.92       306
          14       0.98      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.72      0.78       266
          20       0.97      0.98      0.97      8344
          21       0.88      0.47      0.61        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.89      0.64      0.75       115
          27       0.90      0.95      0.92        38
          28       0.88      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.95      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.95      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9683951022132457
train_acc 0.9684489218534944

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9693865658347168
valid_acc: 0.9694485778665873
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.76      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.92      0.94      0.93       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.84      0.74      0.78       266
          20       0.97      0.98      0.98      8344
          21       0.91      0.67      0.77        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.81      0.72      0.76       115
          27       0.89      0.82      0.85        38
          28       0.89      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.98      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.95      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.41it/s]
train_weighted_f1 0.9741312726684496
train_acc 0.9741688756350784

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9712424060546111
valid_acc: 0.971302240550997
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.75      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.94      0.93       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.82      0.76      0.79       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.88      0.70      0.78       115
          27       0.87      0.87      0.87        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9783490698451122
train_acc 0.978378659665936

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.9717942721066773
valid_acc: 0.971829429020875
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.82      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.96      0.97      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.81      0.77      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.86      0.68      0.76       115
          27       0.94      0.87      0.90        38
          28       0.90      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.50      1.00      0.67         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.97      0.95      0.96      3387
          36       0.96      0.99      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.96      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9817427730673834
train_acc 0.9817611425464308

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.73it/s]
valid_weighted_f1: 0.9720971985129697
valid_acc: 0.9721355384549977
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.79      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.95      0.93       306
          14       0.97      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.81      0.78      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.88      0.70      0.78       115
          27       0.90      0.92      0.91        38
          28       0.89      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.97      0.95      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 14:07:16,055] Trial 13 finished with value: 0.9721355384549977 and parameters: {'lrmain': 4e-05, 'drop_out': 0.3}. Best is trial 1 with value: 0.9726967390842226.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.7886175493086155
train_acc 0.788227897571834

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.60it/s]
valid_weighted_f1: 0.9366009593384699
valid_acc: 0.9371030143276221
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.44      0.27      0.33       101
           5       1.00      0.14      0.25        21
           6       1.00      0.99      0.99      2353
           7       0.97      0.97      0.97      3217
           8       0.99      1.00      1.00      9748
           9       0.92      1.00      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.86      0.87      0.86      9782
          13       0.82      0.75      0.78       306
          14       0.89      0.80      0.84       331
          15       0.98      0.98      0.98        66
          16       0.99      0.99      0.99       678
          17       0.89      0.89      0.89     15211
          18       0.90      0.92      0.91     19633
          19       0.85      0.53      0.65       266
          20       0.93      0.93      0.93      8344
          21       0.00      0.00      0.00        15
          22       0.98      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.98      0.99      0.99       925
          25       0.94      0.89      0.91      2155
          26       0.84      0.47      0.60       115
          27       0.94      0.39      0.56        38
          28       0.80      0.84      0.82       248
          29       1.00      0.94      0.97        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.95      0.95      0.95      2601
          33       0.92      0.96      0.94      4030
          34       0.90      0.86      0.88      2051
          35       0.93      0.90      0.92      3387
          36       0.95      0.96      0.95      1654
          37       0.98      0.92      0.95      2611
          38       0.90      0.93      0.91       370
          39       0.98      0.97      0.98       270
          40       0.00      0.00      0.00        10
          41       1.00      0.97      0.98       229
          42       0.99      0.98      0.99       405

    accuracy                           0.94    117605
   macro avg       0.86      0.80      0.82    117605
weighted avg       0.94      0.94      0.94    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9235216505165496
train_acc 0.9238086438633158

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.953407860122827
valid_acc: 0.9537009480889418
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.39      0.51       101
           5       1.00      0.90      0.95        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.91      0.90      9782
          13       0.86      0.83      0.84       306
          14       0.96      0.87      0.91       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.92      0.91      0.92     15211
          18       0.93      0.94      0.93     19633
          19       0.87      0.61      0.71       266
          20       0.96      0.96      0.96      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      1.00       925
          25       0.95      0.92      0.94      2155
          26       0.83      0.51      0.63       115
          27       0.92      0.87      0.89        38
          28       0.86      0.93      0.89       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.96      0.96      2601
          33       0.94      0.97      0.95      4030
          34       0.93      0.91      0.92      2051
          35       0.95      0.91      0.93      3387
          36       0.95      0.97      0.96      1654
          37       0.98      0.95      0.97      2611
          38       0.94      0.95      0.94       370
          39       0.99      0.98      0.98       270
          40       1.00      0.70      0.82        10
          41       1.00      0.99      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.91      0.87      0.89    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9430310471904042
train_acc 0.9431870316562165

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9606058373254796
valid_acc: 0.9607839802729475
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.54      0.64       101
           5       1.00      0.90      0.95        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.92      0.91      9782
          13       0.88      0.87      0.87       306
          14       0.95      0.89      0.92       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.93      0.93      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.89      0.65      0.75       266
          20       0.96      0.97      0.97      8344
          21       0.86      0.40      0.55        15
          22       0.99      1.00      1.00      2100
          23       0.99      1.00      0.99      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.94      2155
          26       0.84      0.58      0.69       115
          27       0.92      0.87      0.89        38
          28       0.88      0.93      0.90       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.97      0.97      2601
          33       0.94      0.97      0.96      4030
          34       0.94      0.94      0.94      2051
          35       0.96      0.92      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.95      0.95      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.90      0.91    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9535372197041718
train_acc 0.9536541435149785

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9642573037864977
valid_acc: 0.964389269163726
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.64      0.70       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.92      9782
          13       0.88      0.89      0.89       306
          14       0.95      0.91      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.87      0.69      0.77       266
          20       0.97      0.98      0.97      8344
          21       0.88      0.47      0.61        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.83      0.59      0.69       115
          27       0.92      0.87      0.89        38
          28       0.88      0.95      0.92       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.96      0.94      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.94      0.96      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.94      0.91      0.92    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9603708083350925
train_acc 0.9604520314013356

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9668847976442413
valid_acc: 0.9670167084732793
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.66      0.74       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.88      0.91      0.90       306
          14       0.97      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.90      0.68      0.78       266
          20       0.97      0.98      0.97      8344
          21       0.75      0.40      0.52        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.83      0.60      0.70       115
          27       0.92      0.95      0.94        38
          28       0.90      0.95      0.92       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.96      0.95      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.95      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.91      0.92    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.9657731268061918
train_acc 0.9658395779171127

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.66it/s]
valid_weighted_f1: 0.968776745325445
valid_acc: 0.9688958802771991
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.66      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.89      0.93      0.91       306
          14       0.97      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.87      0.72      0.79       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.47      0.64        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.88      0.61      0.72       115
          27       0.95      0.95      0.95        38
          28       0.91      0.93      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9698418027382883
train_acc 0.9698964333656183

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9702466614190015
valid_acc: 0.970315887929935
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.66      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.95      0.93      9782
          13       0.89      0.94      0.92       306
          14       0.97      0.94      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.86      0.71      0.78       266
          20       0.98      0.98      0.98      8344
          21       0.85      0.73      0.79        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.87      0.63      0.73       115
          27       0.95      0.95      0.95        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 14:24:51,054] Trial 14 finished with value: 0.970315887929935 and parameters: {'lrmain': 2e-05, 'drop_out': 0.3}. Best is trial 1 with value: 0.9726967390842226.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.8499905246880358
train_acc 0.8499250225144858

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9484730385803665
valid_acc: 0.9487181667446112
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.49      0.43      0.46       101
           5       1.00      0.81      0.89        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.89      0.89      9782
          13       0.86      0.84      0.85       306
          14       0.92      0.88      0.90       331
          15       0.97      1.00      0.99        66
          16       0.99      0.99      0.99       678
          17       0.91      0.91      0.91     15211
          18       0.93      0.92      0.93     19633
          19       0.83      0.62      0.71       266
          20       0.94      0.96      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      1.00      0.99      1397
          24       1.00      0.99      0.99       925
          25       0.95      0.92      0.93      2155
          26       0.84      0.54      0.66       115
          27       0.85      0.58      0.69        38
          28       0.82      0.93      0.87       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.96      0.96      2601
          33       0.92      0.97      0.94      4030
          34       0.90      0.91      0.91      2051
          35       0.96      0.90      0.93      3387
          36       0.95      0.97      0.96      1654
          37       0.98      0.95      0.96      2611
          38       0.92      0.95      0.93       370
          39       0.99      0.99      0.99       270
          40       1.00      0.70      0.82        10
          41       1.00      0.99      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.89      0.86      0.88    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.38it/s]
train_weighted_f1 0.9443170549728628
train_acc 0.9444667465293708

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9604519661525913
valid_acc: 0.960605416436376
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.64      0.56      0.60       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.92      0.91      9782
          13       0.89      0.91      0.90       306
          14       0.96      0.90      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.93      0.93     15211
          18       0.94      0.95      0.94     19633
          19       0.86      0.67      0.76       266
          20       0.97      0.97      0.97      8344
          21       0.75      0.20      0.32        15
          22       0.99      1.00      1.00      2100
          23       0.99      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.94      0.94      2155
          26       0.95      0.60      0.73       115
          27       0.87      0.87      0.87        38
          28       0.87      0.94      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.93      0.97      0.95      4030
          34       0.95      0.93      0.94      2051
          35       0.96      0.92      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.95      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.90      0.91    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9587526852884706
train_acc 0.958825041205757

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.67it/s]
valid_weighted_f1: 0.9656110272054049
valid_acc: 0.9656902342587474
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.67      0.68      0.68       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.92      9782
          13       0.90      0.93      0.91       306
          14       0.96      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.93      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.71      0.78       266
          20       0.97      0.98      0.97      8344
          21       0.89      0.53      0.67        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.88      0.66      0.76       115
          27       0.94      0.79      0.86        38
          28       0.88      0.93      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.93      0.97      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.92      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9669494200356157
train_acc 0.9669971623251942

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.968357687646221
valid_acc: 0.9684282130861783
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.72      0.67      0.70       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.91      0.93      0.92       306
          14       0.98      0.92      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.93      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.75      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.88      0.68      0.76       115
          27       0.90      0.95      0.92        38
          28       0.90      0.93      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:49<00:00,  3.54it/s]
train_weighted_f1 0.9726090909127268
train_acc 0.9726502098519991

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9696526688522948
valid_acc: 0.9697036690616896
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.71      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.90      0.95      0.93       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      0.99       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.77      0.81       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.88      0.68      0.76       115
          27       0.92      0.92      0.92        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.9772126259254024
train_acc 0.9772359433144722

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9707916339584928
valid_acc: 0.9708345733599761
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.74      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.92      0.95      0.94      9782
          13       0.89      0.96      0.92       306
          14       0.97      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.86      0.77      0.81       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.87      0.63      0.73       115
          27       0.92      0.87      0.89        38
          28       0.88      0.98      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9803081929740921
train_acc 0.9803263750828363

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.51it/s]
valid_weighted_f1: 0.9714569714674088
valid_acc: 0.9715063135070788
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.65      0.71       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.89      0.96      0.93       306
          14       0.98      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.83      0.79      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.89      0.67      0.76       115
          27       0.86      0.95      0.90        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-28 14:42:59,729] Trial 15 finished with value: 0.9715063135070788 and parameters: {'lrmain': 3e-05, 'drop_out': 0.1}. Best is trial 1 with value: 0.9726967390842226.

Process finished with exit code 0
