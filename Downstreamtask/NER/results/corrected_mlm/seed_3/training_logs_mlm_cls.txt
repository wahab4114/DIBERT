ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 5e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.34it/s]
train_weighted_f1 0.881203252025261
train_acc 0.8812212196904046

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.60it/s]
valid_weighted_f1: 0.9519500306628479
valid_acc: 0.9520683644402874
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.60      0.66       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.91      0.90      9782
          13       0.84      0.92      0.88       306
          14       0.95      0.89      0.92       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.92      0.91      0.92     15211
          18       0.93      0.93      0.93     19633
          19       0.88      0.66      0.76       266
          20       0.94      0.96      0.95      8344
          21       1.00      0.53      0.70        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.96      0.90      0.93      2155
          26       0.94      0.51      0.66       115
          27       0.88      0.74      0.80        38
          28       0.83      0.98      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.94      0.95      2601
          33       0.94      0.95      0.95      4030
          34       0.89      0.90      0.89      2051
          35       0.94      0.92      0.93      3387
          36       0.97      0.96      0.96      1654
          37       0.98      0.94      0.96      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.93      0.90      0.91    117605
weighted avg       0.95      0.95      0.95    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.20it/s]
train_weighted_f1 0.952685573718376
train_acc 0.9527599361098367

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.9629957004891492
valid_acc: 0.9630883040687046
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.70      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.91      0.92      9782
          13       0.87      0.95      0.91       306
          14       0.96      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.94      0.93     15211
          18       0.94      0.95      0.95     19633
          19       0.84      0.76      0.80       266
          20       0.97      0.97      0.97      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.94      2155
          26       0.95      0.60      0.73       115
          27       0.89      0.84      0.86        38
          28       0.86      0.97      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.96      0.96      2601
          33       0.94      0.97      0.96      4030
          34       0.94      0.94      0.94      2051
          35       0.95      0.93      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.19it/s]
train_weighted_f1 0.9668244208366743
train_acc 0.9668675978318125

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9671449435177187
valid_acc: 0.967220781429361
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.69      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.91      0.95      0.93       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.79      0.82       266
          20       0.97      0.98      0.97      8344
          21       0.93      0.87      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.92      0.70      0.80       115
          27       0.91      0.76      0.83        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.95      0.98      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.21it/s]
train_weighted_f1 0.9748542591834541
train_acc 0.9748846663608095

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.51it/s]
valid_weighted_f1: 0.9687037838367186
valid_acc: 0.9687768377194848
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.77      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.90      0.95      0.92       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.93      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.83      0.81      0.82       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.89      0.64      0.75       115
          27       0.91      0.84      0.88        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.20it/s]
train_weighted_f1 0.9804322896704503
train_acc 0.9804516915600414

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.51it/s]
valid_weighted_f1: 0.9693620672449852
valid_acc: 0.9694315717869139
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.72      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.91      0.94      0.92       306
          14       0.93      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.85      0.82      0.84       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.87      0.72      0.79       115
          27       0.93      0.68      0.79        38
          28       0.91      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.96      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.20it/s]
train_weighted_f1 0.984282527750467
train_acc 0.9842950841956806

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.51it/s]
valid_weighted_f1: 0.9704379146814944
valid_acc: 0.9704689426469963
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.74      0.78       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.95      0.93       306
          14       0.94      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.84      0.80      0.82       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.88      0.73      0.80       115
          27       0.90      0.74      0.81        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.20it/s]
train_weighted_f1 0.9872856087666395
train_acc 0.987292059608163

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9703591798114405
valid_acc: 0.9704009183283023
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.66      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.95      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.94      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.87      0.80      0.83       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.89      0.70      0.79       115
          27       0.91      0.82      0.86        38
          28       0.91      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.95      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.20it/s]
train_weighted_f1 0.9896287031385367
train_acc 0.9896337785254287

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.9703989648572531
valid_acc: 0.9704264274478126
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.71      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.91      0.94      0.93       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.85      0.82      0.84       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.90      0.70      0.79       115
          27       0.89      0.82      0.85        38
          28       0.88      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.97      0.95      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.20it/s]
train_weighted_f1 0.9912165402498249
train_acc 0.9912193505632869

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.51it/s]
valid_weighted_f1: 0.9710534808784227
valid_acc: 0.9710896645550784
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.72      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.97      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.85      0.79      0.82       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.89      0.69      0.77       115
          27       0.92      0.87      0.89        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.20it/s]
train_weighted_f1 0.9925973049240138
train_acc 0.9925988938165876

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9709660709031002
valid_acc: 0.9709961311168743
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.72      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.95      0.94       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.85      0.79      0.82       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.67      0.80        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.95      2155
          26       0.89      0.72      0.80       115
          27       0.91      0.84      0.88        38
          28       0.90      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.21it/s]
train_weighted_f1 0.993605656393177
train_acc 0.9936067356544493

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9713692621261477
valid_acc: 0.9714042770290379
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.89      0.71      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.93      0.96      0.94       306
          14       0.96      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.87      0.78      0.83       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.87      0.75      0.80       115
          27       0.91      0.84      0.88        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.98      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.95      0.96      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.97      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.21it/s]
train_weighted_f1 0.9944507392735894
train_acc 0.994451028869518

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9717591643936564
valid_acc: 0.9717869138216912
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.75      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.84      0.82      0.83       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.96      2155
          26       0.89      0.73      0.80       115
          27       0.92      0.87      0.89        38
          28       0.92      0.94      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.97      0.95      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 12
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.20it/s]
train_weighted_f1 0.9951187562180837
train_acc 0.995119029413264

Valid_Epoch: 12
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.9710877833491735
valid_acc: 0.9711321797542621
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.75      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.89      0.97      0.93       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.82      0.81      0.82       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.89      0.66      0.76       115
          27       0.91      0.82      0.86        38
          28       0.92      0.93      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.98      0.97      2601
          33       0.96      0.96      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 13
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.21it/s]
train_weighted_f1 0.9954305932494987
train_acc 0.9954312586022328

Valid_Epoch: 13
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.50it/s]
valid_weighted_f1: 0.9714289544140676
valid_acc: 0.9714467922282216
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.71      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.95      0.94      0.94       306
          14       0.97      0.97      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.79      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.96      0.95      2155
          26       0.86      0.79      0.82       115
          27       0.91      0.82      0.86        38
          28       0.91      0.93      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.95      0.95      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.98      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 14
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.20it/s]
train_weighted_f1 0.9960225885656625
train_acc 0.9960227948548028

Valid_Epoch: 14
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.9717273670256574
valid_acc: 0.971761404702181
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.91      0.71      0.80       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.95      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.93      0.96      0.94       306
          14       0.96      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.80      0.82      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.87      0.76      0.81       115
          27       0.92      0.89      0.91        38
          28       0.91      0.96      0.94       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.94      0.97      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
