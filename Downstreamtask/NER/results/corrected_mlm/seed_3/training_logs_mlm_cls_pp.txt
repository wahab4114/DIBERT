ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 4e-05, 'drop_out': 0.2}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.8633912708154423
train_acc 0.8633540636522744

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9525215934208254
valid_acc: 0.9527486076272267
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.58      0.40      0.47       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.91      0.90      9782
          13       0.86      0.87      0.87       306
          14       0.94      0.89      0.91       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.92      0.92      0.92     15211
          18       0.94      0.92      0.93     19633
          19       0.85      0.62      0.72       266
          20       0.94      0.96      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      1.00      0.99      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.92      0.93      2155
          26       0.89      0.56      0.68       115
          27       0.88      0.61      0.72        38
          28       0.84      0.94      0.88       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.96      2601
          33       0.94      0.96      0.95      4030
          34       0.91      0.92      0.92      2051
          35       0.94      0.93      0.94      3387
          36       0.94      0.97      0.96      1654
          37       0.98      0.95      0.96      2611
          38       0.93      0.95      0.94       370
          39       0.99      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      0.98      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.90      0.88      0.89    117605
weighted avg       0.95      0.95      0.95    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.23it/s]
train_weighted_f1 0.9480783978196686
train_acc 0.9481996907444223

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.963463697226718
valid_acc: 0.9635814803792355
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.69      0.56      0.62       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.89      0.92      0.90       306
          14       0.95      0.92      0.93       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.93      0.94      0.93     15211
          18       0.95      0.94      0.95     19633
          19       0.86      0.70      0.77       266
          20       0.97      0.97      0.97      8344
          21       0.91      0.67      0.77        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.88      0.61      0.72       115
          27       0.94      0.76      0.84        38
          28       0.89      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.97      0.96      4030
          34       0.94      0.95      0.95      2051
          35       0.96      0.93      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.92      0.98      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9620513062431182
train_acc 0.9621183157465464

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9675044625481097
valid_acc: 0.9676034182220143
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.65      0.69       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.91      0.93      0.92       306
          14       0.96      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.88      0.71      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.86      0.70      0.77       115
          27       0.94      0.84      0.89        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.95      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.95      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9699362486270598
train_acc 0.9699824556931913

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9690671740382445
valid_acc: 0.9691509714723013
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.72      0.67      0.70       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.92      0.93      0.93       306
          14       0.97      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      0.99       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.84      0.74      0.79       266
          20       0.97      0.99      0.98      8344
          21       1.00      0.80      0.89        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.87      0.70      0.78       115
          27       0.92      0.92      0.92        38
          28       0.90      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.95      0.99      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9752802913674273
train_acc 0.9753137159946305

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9707418574456322
valid_acc: 0.9708260703201395
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.64      0.72       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.98      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.85      0.76      0.80       266
          20       0.97      0.99      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.85      0.70      0.77       115
          27       0.95      0.95      0.95        38
          28       0.92      0.94      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.96      0.99      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9796408963298745
train_acc 0.9796626225552667

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9717715803672949
valid_acc: 0.9718124229412015
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.68      0.72       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.95      0.94       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.84      0.78      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.93      0.97        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.84      0.76      0.80       115
          27       0.94      0.87      0.90        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.97      0.94      0.96      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9830277496092668
train_acc 0.9830387334114968

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.9720622714752816
valid_acc: 0.9721185323753242
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.68      0.74       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.93      0.95      0.94       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.84      0.77      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.93      0.97        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.74      0.81       115
          27       0.91      0.82      0.86        38
          28       0.91      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9858052534224486
train_acc 0.9858137499787599

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.50it/s]
valid_weighted_f1: 0.9722567940425308
valid_acc: 0.972288593172059
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.71      0.75       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.94      0.95      0.94       306
          14       0.97      0.94      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.84      0.78      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.84      0.78      0.81       115
          27       0.92      0.95      0.94        38
          28       0.92      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9879706717651858
train_acc 0.9879759902125708

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9725845135172828
valid_acc: 0.9726032056460184
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.67      0.72       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.94      0.96      0.95       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.82      0.80      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.93      0.97        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.84      0.78      0.81       115
          27       0.94      0.82      0.87        38
          28       0.90      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.94      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9899184321098875
train_acc 0.9899226436254269

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.51it/s]
valid_weighted_f1: 0.9725752519722447
valid_acc: 0.9725776965265083
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.67      0.72       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.93      0.96      0.95       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.79      0.78      0.78       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.87      0.77      0.81       115
          27       0.94      0.89      0.92        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9910826741961429
train_acc 0.9910855380537289

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9727878700483451
valid_acc: 0.9727902725224268
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.70      0.73       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      1.00      1.00     12278
          12       0.93      0.95      0.94      9782
          13       0.93      0.95      0.94       306
          14       0.97      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.78      0.81      0.79       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.85      0.77      0.80       115
          27       0.97      0.89      0.93        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9925193364601296
train_acc 0.9925213675213675

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.972771738779864
valid_acc: 0.97278176948259
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.74      0.75       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.94      0.96      0.95       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.81      0.79      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.84      0.80      0.82       115
          27       0.94      0.89      0.92        38
          28       0.91      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.96      0.96      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 12
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.23it/s]
train_weighted_f1 0.9933896471546068
train_acc 0.9933911488334948

Valid_Epoch: 12
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.9730292522285316
valid_acc: 0.9730538667573657
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.72      0.75       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.93      0.96      0.94       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.82      0.77      0.79       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.83      0.78      0.80       115
          27       0.92      0.89      0.91        38
          28       0.89      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 13
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.23it/s]
train_weighted_f1 0.9942647666720555
train_acc 0.9942651781617985

Valid_Epoch: 13
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.9730595854540302
valid_acc: 0.9730623697972025
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.74      0.77       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      1.00     12278
          12       0.93      0.95      0.94      9782
          13       0.93      0.96      0.94       306
          14       0.97      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.79      0.79      0.79       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.93      0.97        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.87      0.79      0.83       115
          27       0.94      0.89      0.92        38
          28       0.91      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.97    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 14
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9946743751868525
train_acc 0.9946751117228254

Valid_Epoch: 14
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9730720375232212
valid_acc: 0.9730878789167128
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.70      0.76       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      1.00      1.00     12278
          12       0.93      0.95      0.94      9782
          13       0.93      0.97      0.95       306
          14       0.97      0.97      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.79      0.79      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.85      0.78      0.81       115
          27       0.94      0.89      0.92        38
          28       0.92      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
