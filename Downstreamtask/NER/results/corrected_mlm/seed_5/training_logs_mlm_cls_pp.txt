ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 4e-05, 'drop_out': 0.2}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [03:02<00:00,  3.28it/s]
train_weighted_f1 0.8623269374503567
train_acc 0.8623695859033831

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.952489163803645
valid_acc: 0.9527571106670635
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.66      0.43      0.52       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.90      0.90      9782
          13       0.86      0.89      0.87       306
          14       0.91      0.89      0.90       331
          15       1.00      0.98      0.99        66
          16       0.99      0.99      0.99       678
          17       0.91      0.92      0.92     15211
          18       0.94      0.92      0.93     19633
          19       0.84      0.61      0.70       266
          20       0.95      0.96      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       1.00      0.99      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.91      0.93      2155
          26       0.90      0.56      0.69       115
          27       0.95      0.50      0.66        38
          28       0.83      0.93      0.88       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.96      2601
          33       0.94      0.96      0.95      4030
          34       0.92      0.91      0.92      2051
          35       0.95      0.92      0.94      3387
          36       0.95      0.97      0.96      1654
          37       0.98      0.95      0.96      2611
          38       0.94      0.94      0.94       370
          39       0.99      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.91      0.87      0.89    117605
weighted avg       0.95      0.95      0.95    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9481581661291193
train_acc 0.9482846510679512

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.9636394476030619
valid_acc: 0.9637770502954807
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.71      0.60      0.65       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.88      0.92      0.90       306
          14       0.95      0.93      0.94       331
          15       1.00      0.98      0.99        66
          16       1.00      0.99      0.99       678
          17       0.93      0.94      0.94     15211
          18       0.95      0.94      0.95     19633
          19       0.88      0.68      0.77       266
          20       0.97      0.97      0.97      8344
          21       0.90      0.60      0.72        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.89      0.59      0.71       115
          27       0.97      0.74      0.84        38
          28       0.88      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.95      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.92      0.93    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9618019056081576
train_acc 0.9618719308083126

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9677535703203229
valid_acc: 0.9678840185366269
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.61      0.69       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.92      0.93      9782
          13       0.90      0.95      0.92       306
          14       0.97      0.93      0.95       331
          15       1.00      0.98      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.87      0.71      0.78       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.91      0.67      0.77       115
          27       0.97      0.89      0.93        38
          28       0.91      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9698881750596394
train_acc 0.9699346655112062

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9697867129314814
valid_acc: 0.9698907359380978
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.66      0.71       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.90      0.96      0.93       306
          14       0.97      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.86      0.73      0.79       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.92      0.66      0.77       115
          27       0.97      0.89      0.93        38
          28       0.91      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9754633136453543
train_acc 0.9754953186861736

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9712126230594226
valid_acc: 0.9712767314314867
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.76      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.97      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.86      0.76      0.81       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.70      0.78       115
          27       0.97      0.89      0.93        38
          28       0.89      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.20it/s]
train_weighted_f1 0.9797735764747604
train_acc 0.9797932490526924

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.50it/s]
valid_weighted_f1: 0.9715191735263733
valid_acc: 0.971565834785936
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.69      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.82      0.79      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.89      0.68      0.77       115
          27       0.97      0.87      0.92        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.99      0.98      1654
          37       0.98      0.97      0.98      2611
          38       0.97      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9828170433144426
train_acc 0.9828337666309833

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9720964048532323
valid_acc: 0.9721270354151609
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.72      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.98      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.79      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.86      0.71      0.78       115
          27       0.97      0.95      0.96        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.99      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9857684801221098
train_acc 0.985776579837216

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9722844690299438
valid_acc: 0.9723141022915692
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.68      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.96      0.94       306
          14       0.97      0.96      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.85      0.78      0.82       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.88      0.75      0.81       115
          27       0.95      0.95      0.95        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.21it/s]
train_weighted_f1 0.9879346787126073
train_acc 0.987939882075071

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.972305930394397
valid_acc: 0.9723141022915692
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.75      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.97      0.94       306
          14       0.97      0.96      0.97       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.94      0.96      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.81      0.77      0.79       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.93      0.97        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.86      0.77      0.82       115
          27       0.97      0.92      0.95        38
          28       0.90      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9896547032507832
train_acc 0.9896592666224873

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9725960555132427
valid_acc: 0.9725947026061817
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.71      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      1.00     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.96      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.80      0.81      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.87      0.73      0.79       115
          27       0.95      0.92      0.93        38
          28       0.91      0.94      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.97      0.95      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9911028603434703
train_acc 0.991105716130567

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9729799113885714
valid_acc: 0.9730113515581821
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.71      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.97      0.94       306
          14       0.97      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.96      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.81      0.78      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.88      0.77      0.82       115
          27       0.97      0.89      0.93        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.98      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.20it/s]
train_weighted_f1 0.9923467387113675
train_acc 0.9923482608621773

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.9726997262646706
valid_acc: 0.9727137451638961
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.73      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.98      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.82      0.79      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.87      0.77      0.81       115
          27       0.95      0.92      0.93        38
          28       0.91      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 12
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9934598158476767
train_acc 0.9934612411004061

Valid_Epoch: 12
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9729122615677979
valid_acc: 0.9729178181199779
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.69      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      1.00     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.96      0.93       306
          14       0.98      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.79      0.81      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.87      0.74      0.80       115
          27       0.95      0.92      0.93        38
          28       0.90      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.60      1.00      0.75         3
          32       0.98      0.97      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 13
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.994162867529627
train_acc 0.9941632257735638

Valid_Epoch: 13
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.972785182373
valid_acc: 0.9727902725224268
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.65      0.71       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.97      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.96      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.78      0.80      0.79       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.93      0.97        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.94      0.96      2155
          26       0.84      0.76      0.80       115
          27       0.95      0.92      0.93        38
          28       0.90      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.97      0.97      4030
          34       0.97      0.95      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 14
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9946864680100833
train_acc 0.9946867937673106

Valid_Epoch: 14
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.9731798438343352
valid_acc: 0.9731984184345903
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.69      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.96      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.85      0.79      0.82       266
          20       0.98      0.99      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.89      0.75      0.81       115
          27       0.97      0.92      0.95        38
          28       0.92      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.97    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
