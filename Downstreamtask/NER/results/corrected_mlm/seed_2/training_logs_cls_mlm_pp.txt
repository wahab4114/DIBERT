ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 4e-05, 'drop_out': 0.2}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.39it/s]
train_weighted_f1 0.8608205131810022
train_acc 0.8607532157482456

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9524204283100032
valid_acc: 0.9526720802686961
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.56      0.33      0.41       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.91      0.89      9782
          13       0.85      0.85      0.85       306
          14       0.95      0.88      0.91       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.91      0.92      0.92     15211
          18       0.95      0.92      0.93     19633
          19       0.86      0.61      0.71       266
          20       0.94      0.97      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.95      0.91      0.93      2155
          26       0.74      0.52      0.61       115
          27       0.86      0.82      0.84        38
          28       0.82      0.95      0.88       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.97      2601
          33       0.95      0.95      0.95      4030
          34       0.92      0.92      0.92      2051
          35       0.93      0.93      0.93      3387
          36       0.95      0.97      0.96      1654
          37       0.99      0.95      0.97      2611
          38       0.94      0.94      0.94       370
          39       0.99      0.99      0.99       270
          40       1.00      0.40      0.57        10
          41       1.00      0.98      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.90      0.86      0.88    117605
weighted avg       0.95      0.95      0.95    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [03:01<00:00,  3.30it/s]
train_weighted_f1 0.9475800673847223
train_acc 0.9477111688841311

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9633337928996789
valid_acc: 0.9634539347816845
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.61      0.66       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.89      0.90      0.90       306
          14       0.96      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.94      0.93      0.93     15211
          18       0.94      0.95      0.95     19633
          19       0.86      0.71      0.78       266
          20       0.97      0.98      0.97      8344
          21       1.00      0.47      0.64        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.81      0.60      0.69       115
          27       0.88      0.76      0.82        38
          28       0.86      0.96      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.94      0.95      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.96      0.98      2611
          38       0.95      0.95      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.92      0.93    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.24it/s]
train_weighted_f1 0.9617801895985704
train_acc 0.9618506907274302

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9679210799458615
valid_acc: 0.9680200671740147
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.62      0.70       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.89      0.95      0.92       306
          14       0.95      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.76      0.81       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.67      0.80        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.85      0.60      0.70       115
          27       0.88      0.79      0.83        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.98      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.97      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.97      0.98      2611
          38       0.97      0.95      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.25it/s]
train_weighted_f1 0.9697091935715862
train_acc 0.9697583728398838

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9700874497131811
valid_acc: 0.9701543301730369
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.67      0.74       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.90      0.95      0.93       306
          14       0.97      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.87      0.76      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.86      0.80      0.83        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.84      0.64      0.73       115
          27       0.89      0.89      0.89        38
          28       0.87      0.98      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.60      1.00      0.75         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.26it/s]
train_weighted_f1 0.9753469599685742
train_acc 0.9753763742332331

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.971214589911649
valid_acc: 0.9712767314314867
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.74      0.76       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.95      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.83      0.78      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.85      0.64      0.73       115
          27       0.94      0.79      0.86        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.97      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.24it/s]
train_weighted_f1 0.9795185504369106
train_acc 0.9795383680821057

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.971128512741379
valid_acc: 0.9712087071127928
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.72      0.76       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.91      0.96      0.93       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.83      0.79      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.96      2155
          26       0.86      0.66      0.75       115
          27       0.94      0.82      0.87        38
          28       0.91      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.25it/s]
train_weighted_f1 0.9826876631615141
train_acc 0.9827010161254695

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9725888248883008
valid_acc: 0.9726287147655287
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.73      0.78       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.83      0.77      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.81      0.69      0.74       115
          27       0.92      0.87      0.89        38
          28       0.91      0.96      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.25it/s]
train_weighted_f1 0.9855933935075292
train_acc 0.9856013491699377

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9720381100952178
valid_acc: 0.9720760171761405
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.71      0.76       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.84      0.77      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.85      0.70      0.77       115
          27       0.89      0.89      0.89        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.24it/s]
train_weighted_f1 0.9876868998220508
train_acc 0.9876934971368371

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9725854253697999
valid_acc: 0.9726372178053654
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.65      0.72       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.90      0.95      0.93       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.84      0.77      0.81       266
          20       0.97      0.99      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.84      0.71      0.77       115
          27       0.92      0.89      0.91        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.97      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.98      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.24it/s]
train_weighted_f1 0.9895737886800976
train_acc 0.9895785543151349

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9730169145421632
valid_acc: 0.9730368606776922
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.67      0.75       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      1.00     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.95      0.94       306
          14       0.97      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.77      0.79      0.78       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.83      0.74      0.78       115
          27       0.89      0.89      0.89        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.24it/s]
train_weighted_f1 0.9911038622115357
train_acc 0.9911067781346111

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9726645897619313
valid_acc: 0.9726967390842226
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.73      0.79       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      1.00     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.94      0.93       306
          14       0.97      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.77      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.81      0.73      0.77       115
          27       0.89      0.89      0.89        38
          28       0.91      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.97      0.96      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.97      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.24it/s]
train_weighted_f1 0.992293126255608
train_acc 0.9922951606599718

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.972681115317526
valid_acc: 0.9727052421240594
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.70      0.77       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.84      0.78      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.88      0.73      0.80       115
          27       0.94      0.87      0.90        38
          28       0.91      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.97      0.96      0.97      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 12
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.24it/s]
train_weighted_f1 0.993436882162002
train_acc 0.9934378770114357

Valid_Epoch: 12
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9728745873969594
valid_acc: 0.9728667998809575
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.80      0.79       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.95      0.94       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.96      0.96     19633
          19       0.79      0.79      0.79       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.80      0.75      0.77       115
          27       0.87      0.89      0.88        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.95      0.96      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 13
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.25it/s]
train_weighted_f1 0.9941602814148375
train_acc 0.9941611017654756

Valid_Epoch: 13
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.65it/s]
valid_weighted_f1: 0.9730254688491686
valid_acc: 0.9730538667573657
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.75      0.81       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.80      0.79      0.79       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.82      0.73      0.77       115
          27       0.89      0.87      0.88        38
          28       0.90      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.97      0.97      4030
          34       0.97      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 14
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.25it/s]
train_weighted_f1 0.9946913371128977
train_acc 0.9946921037875313

Valid_Epoch: 14
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.64it/s]
valid_weighted_f1: 0.9726768207317801
valid_acc: 0.9727307512435696
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.67      0.76       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      1.00     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.96      0.93       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.85      0.77      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.86      0.65      0.74       115
          27       0.89      0.87      0.88        38
          28       0.91      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.97      0.97      4030
          34       0.97      0.96      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.97      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
