ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 5e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.8823857995445078
train_acc 0.8823989821753241

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9514768811648537
valid_acc: 0.9515836911695932
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.54      0.65       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.94      1.00      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.91      0.89      9782
          13       0.85      0.92      0.89       306
          14       0.96      0.91      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.91      0.92      0.92     15211
          18       0.94      0.92      0.93     19633
          19       0.86      0.67      0.76       266
          20       0.95      0.96      0.95      8344
          21       0.89      0.53      0.67        15
          22       0.99      1.00      1.00      2100
          23       0.99      1.00      0.99      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.89      0.92      2155
          26       0.88      0.52      0.66       115
          27       0.91      0.79      0.85        38
          28       0.86      0.95      0.90       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.95      0.95      2601
          33       0.93      0.96      0.95      4030
          34       0.89      0.90      0.89      2051
          35       0.95      0.91      0.93      3387
          36       0.97      0.95      0.96      1654
          37       0.97      0.95      0.96      2611
          38       0.95      0.96      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.93      0.90      0.91    117605
weighted avg       0.95      0.95      0.95    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9525629503079415
train_acc 0.9526324956245433

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9628351358758259
valid_acc: 0.9629012371922963
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.71      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.91      0.92      9782
          13       0.89      0.93      0.91       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.94      0.93     15211
          18       0.95      0.94      0.94     19633
          19       0.83      0.75      0.79       266
          20       0.97      0.97      0.97      8344
          21       0.82      0.93      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.93      0.95      2155
          26       0.89      0.64      0.75       115
          27       0.91      0.79      0.85        38
          28       0.87      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.96      0.96      2601
          33       0.94      0.98      0.96      4030
          34       0.94      0.93      0.93      2051
          35       0.95      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.94      0.98      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9669380472419835
train_acc 0.9669780462524001

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9667594819341364
valid_acc: 0.9668296415968709
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.76      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.90      0.96      0.93       306
          14       0.94      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.83      0.77      0.80       266
          20       0.97      0.98      0.97      8344
          21       1.00      0.87      0.93        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.92      0.68      0.78       115
          27       0.93      0.71      0.81        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.96      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.96      0.93      0.94      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9750041131164101
train_acc 0.9750344089310292

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9693168517312746
valid_acc: 0.9693805535478933
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.73      0.79       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.92      0.95      0.94       306
          14       0.95      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.77      0.81       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.91      0.75      0.82       115
          27       1.00      0.79      0.88        38
          28       0.90      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.96      0.94      0.95      2051
          35       0.97      0.92      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9804000527345492
train_acc 0.980418769434674

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.60it/s]
valid_weighted_f1: 0.969559014768771
valid_acc: 0.9696016325836486
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.78      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.97      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.90      0.95      0.93       306
          14       0.96      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.85      0.79      0.82       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.95      2155
          26       0.91      0.70      0.79       115
          27       0.97      0.89      0.93        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.98      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.23it/s]
train_weighted_f1 0.9845927435280479
train_acc 0.9846051893765612

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9705458777725284
valid_acc: 0.9705624760852004
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.78      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.97      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.95      0.93       306
          14       0.97      0.97      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.83      0.79      0.81       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.90      0.76      0.82       115
          27       0.97      0.89      0.93        38
          28       0.89      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.23it/s]
train_weighted_f1 0.9875303938842832
train_acc 0.9875373825423527

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.59it/s]
valid_weighted_f1: 0.9704417238487467
valid_acc: 0.9704689426469963
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.74      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.91      0.95      0.93       306
          14       0.95      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.80      0.80      0.80       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.87      0.75      0.80       115
          27       0.97      0.82      0.89        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.24it/s]
train_weighted_f1 0.989415925438864
train_acc 0.9894213777166063

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9707141388892998
valid_acc: 0.9707325368819353
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.89      0.71      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.95      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.97      0.95      0.96       331
          15       1.00      0.98      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.81      0.79      0.80       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.88      0.76      0.81       115
          27       0.94      0.89      0.92        38
          28       0.89      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.24it/s]
train_weighted_f1 0.9914477388462188
train_acc 0.9914508674449032

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.971054782650468
valid_acc: 0.9710641554355682
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.78      0.82       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.93      0.95      0.94       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.83      0.82      0.83       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.95      2155
          26       0.88      0.77      0.82       115
          27       0.92      0.89      0.91        38
          28       0.91      0.93      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.98      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.24it/s]
train_weighted_f1 0.992609929106512
train_acc 0.992611637865117

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.971558529800645
valid_acc: 0.9715743378257727
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.80      0.79       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.97      0.94       306
          14       0.97      0.97      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.80      0.81      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.89      0.71      0.79       115
          27       1.00      0.87      0.93        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.98      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.23it/s]
train_weighted_f1 0.9936111628995871
train_acc 0.9936120456746699

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9711000931183524
valid_acc: 0.9711321797542621
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.73      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.93      0.95      0.94       306
          14       0.97      0.96      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.81      0.79      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.85      0.77      0.81       115
          27       0.97      0.89      0.93        38
          28       0.91      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.96      0.95      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.25it/s]
train_weighted_f1 0.9945015433227906
train_acc 0.9945020050636353

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9707830665449738
valid_acc: 0.9708005612006292
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.75      0.80       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.77      0.80      0.79       266
          20       0.98      0.97      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.89      0.70      0.79       115
          27       0.87      0.89      0.88        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.60      1.00      0.75         3
          32       0.96      0.98      0.97      2601
          33       0.96      0.96      0.96      4030
          34       0.96      0.94      0.95      2051
          35       0.94      0.95      0.95      3387
          36       0.98      0.97      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.98      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 12
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.25it/s]
train_weighted_f1 0.9949907979553767
train_acc 0.9949915889279707

Valid_Epoch: 12
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9713550082104141
valid_acc: 0.9713617618298541
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.78      0.82       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.79      0.80      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.83      0.69      0.75       115
          27       0.85      0.89      0.87        38
          28       0.92      0.94      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.96      0.98      0.97      2601
          33       0.96      0.96      0.96      4030
          34       0.96      0.95      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.98      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 13
100%|█████████████████████████████████████████| 600/600 [03:04<00:00,  3.25it/s]
train_weighted_f1 0.9955340397599493
train_acc 0.9955342729945116

Valid_Epoch: 13
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.9717165150956935
valid_acc: 0.971727392542834
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.88      0.77      0.82       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.93      0.96      0.94       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.82      0.80      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.76      0.82       115
          27       0.89      0.89      0.89        38
          28       0.91      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.97      0.97      2601
          33       0.97      0.96      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 14
100%|█████████████████████████████████████████| 600/600 [02:16<00:00,  4.40it/s]
train_weighted_f1 0.995962206476309
train_acc 0.9959622606242885

Valid_Epoch: 14
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.67it/s]
valid_weighted_f1: 0.9717904196413734
valid_acc: 0.9718379320607117
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.91      0.74      0.82       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.97      0.96      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.86      0.79      0.83       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.87      0.69      0.77       115
          27       1.00      0.89      0.94        38
          28       0.92      0.94      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
