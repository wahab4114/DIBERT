ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 4e-05, 'drop_out': 0.2}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.8613067940310132
train_acc 0.861234303580228

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.9521663932344334
valid_acc: 0.9524254921134305
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.68      0.44      0.53       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.91      0.90      9782
          13       0.85      0.86      0.86       306
          14       0.94      0.88      0.91       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.92      0.91      0.92     15211
          18       0.94      0.93      0.93     19633
          19       0.85      0.61      0.71       266
          20       0.94      0.97      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      1.00      0.99      1397
          24       0.99      1.00      1.00       925
          25       0.95      0.92      0.94      2155
          26       0.88      0.55      0.67       115
          27       0.88      0.74      0.80        38
          28       0.85      0.89      0.87       248
          29       0.99      1.00      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.95      0.96      2601
          33       0.94      0.96      0.95      4030
          34       0.92      0.92      0.92      2051
          35       0.94      0.92      0.93      3387
          36       0.95      0.97      0.96      1654
          37       0.98      0.95      0.97      2611
          38       0.92      0.95      0.94       370
          39       0.99      0.98      0.99       270
          40       1.00      0.40      0.57        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.90      0.86      0.88    117605
weighted avg       0.95      0.95      0.95    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9484875292833971
train_acc 0.9486149343256699

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9635568776274069
valid_acc: 0.963666510777603
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.67      0.71       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.88      0.92      0.90       306
          14       0.96      0.91      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.84      0.71      0.77       266
          20       0.97      0.97      0.97      8344
          21       0.83      0.33      0.48        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.87      0.58      0.70       115
          27       0.86      0.84      0.85        38
          28       0.86      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.97      2601
          33       0.94      0.97      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.95      0.93      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.94      0.96      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9622832561456226
train_acc 0.9623540806443391

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.967598867718671
valid_acc: 0.9676629395008716
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.72      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.90      0.94      0.92       306
          14       0.93      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.74      0.80       266
          20       0.97      0.98      0.97      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.83      0.65      0.73       115
          27       0.93      0.71      0.81        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.97      0.95      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.94      0.97      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9701842730418182
train_acc 0.9702330886476016

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9693731885968939
valid_acc: 0.9694655839462608
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.69      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.91      0.94      0.93       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.84      0.75      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.87      0.69      0.77       115
          27       0.94      0.82      0.87        38
          28       0.89      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.975400034225898
train_acc 0.9754284124313946

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9711156825039527
valid_acc: 0.9711746949534459
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.73      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.90      0.95      0.93       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.84      0.78      0.81       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.86      0.69      0.76       115
          27       0.94      0.76      0.84        38
          28       0.88      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.97      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.20it/s]
train_weighted_f1 0.9796957040387585
train_acc 0.9797178467655605

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9715191862057972
valid_acc: 0.9715828408656094
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.70      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.93      0.95      0.94       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.85      0.77      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.60      0.75        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.86      0.74      0.79       115
          27       0.90      0.74      0.81        38
          28       0.88      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.983024778575101
train_acc 0.983039795415541

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.9720494843016271
valid_acc: 0.9721100293354874
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.70      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.91      0.96      0.93       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.84      0.77      0.81       266
          20       0.97      0.99      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.85      0.70      0.77       115
          27       0.89      0.84      0.86        38
          28       0.88      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.985771706939165
train_acc 0.9857797658493483

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9722234201464086
valid_acc: 0.9722630840525488
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.70      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.96      0.94       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.85      0.77      0.81       266
          20       0.97      0.99      0.98      8344
          21       1.00      0.67      0.80        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.86      0.70      0.78       115
          27       0.89      0.82      0.85        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.99      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.987993950867613
train_acc 0.987998292297497

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9727361115260168
valid_acc: 0.9727647634029165
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.76      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      1.00     12278
          12       0.93      0.94      0.94      9782
          13       0.90      0.97      0.93       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.80      0.82       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.88      0.67      0.76       115
          27       0.92      0.87      0.89        38
          28       0.90      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.989961314615404
train_acc 0.9899661857912355

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.51it/s]
valid_weighted_f1: 0.9725089531382062
valid_acc: 0.972518175247651
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.75      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      1.00     12278
          12       0.93      0.94      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.96      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.81      0.82      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.67      0.80        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.83      0.68      0.75       115
          27       0.94      0.84      0.89        38
          28       0.89      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.95      0.96      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9911634235872273
train_acc 0.9911662503610814

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9724290864527877
valid_acc: 0.9724246418094469
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.71      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.94      1.00      0.97        65
          11       1.00      0.99      0.99     12278
          12       0.92      0.95      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.80      0.81      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.84      0.74      0.79       115
          27       0.91      0.84      0.88        38
          28       0.88      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.98      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9924622947974737
train_acc 0.9924640193029856

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9730670675180375
valid_acc: 0.9730963819565495
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.72      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.82      0.79      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.60      0.75        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.87      0.73      0.79       115
          27       0.92      0.89      0.91        38
          28       0.91      0.94      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.97      0.96      0.97      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.99      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 12
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9935075315106575
train_acc 0.9935090312823911

Valid_Epoch: 12
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9728988009386791
valid_acc: 0.9729263211598146
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.68      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.97      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      0.99       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.79      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.67      0.80        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.82      0.73      0.77       115
          27       0.92      0.87      0.89        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 13
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9941350372037874
train_acc 0.9941356136684169

Valid_Epoch: 13
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9729619766450277
valid_acc: 0.9729688363589983
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.76      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.97      0.94       306
          14       0.97      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.80      0.80      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.84      0.76      0.80       115
          27       0.90      0.92      0.91        38
          28       0.90      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 14
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9946804168124255
train_acc 0.9946814837470901

Valid_Epoch: 14
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9730925187563724
valid_acc: 0.9731218910760597
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.73      0.76       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.81      0.79      0.80       266
          20       0.98      0.99      0.98      8344
          21       1.00      0.60      0.75        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.85      0.75      0.80       115
          27       0.91      0.79      0.85        38
          28       0.91      0.92      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.99      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
