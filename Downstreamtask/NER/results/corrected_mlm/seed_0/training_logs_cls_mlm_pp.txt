ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 4e-05, 'drop_out': 0.2}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:56<00:00,  3.39it/s]
train_weighted_f1 0.8603569114020848
train_acc 0.8602933679971453

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9525843408594801
valid_acc: 0.9527571106670635
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       0.99      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.57      0.47      0.51       101
           5       1.00      0.90      0.95        21
           6       1.00      0.99      0.99      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.91      0.89      9782
          13       0.87      0.85      0.86       306
          14       0.95      0.89      0.92       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.91      0.92      0.92     15211
          18       0.94      0.92      0.93     19633
          19       0.85      0.64      0.73       266
          20       0.95      0.96      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       1.00      0.99      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.94      0.92      0.93      2155
          26       0.82      0.57      0.67       115
          27       0.97      0.79      0.87        38
          28       0.85      0.92      0.88       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.96      2601
          33       0.93      0.97      0.95      4030
          34       0.93      0.91      0.92      2051
          35       0.95      0.92      0.93      3387
          36       0.95      0.97      0.96      1654
          37       0.98      0.94      0.96      2611
          38       0.94      0.95      0.95       370
          39       0.98      0.99      0.99       270
          40       1.00      0.70      0.82        10
          41       1.00      0.98      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.90      0.87      0.89    117605
weighted avg       0.95      0.95      0.95    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:45<00:00,  3.63it/s]
train_weighted_f1 0.9480028301438086
train_acc 0.9481232264532463

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9631492279269569
valid_acc: 0.9632328557459292
              precision    recall  f1-score   support

           1       0.99      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.63      0.71      0.67       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.89      0.91      0.90       306
          14       0.96      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.94      0.93      0.93     15211
          18       0.94      0.95      0.95     19633
          19       0.84      0.72      0.77       266
          20       0.97      0.97      0.97      8344
          21       0.89      0.53      0.67        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.87      0.62      0.72       115
          27       0.97      0.82      0.89        38
          28       0.87      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.93      0.96      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.20it/s]
train_weighted_f1 0.961937609643109
train_acc 0.9620046813138264

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9676202742223158
valid_acc: 0.9676969516602185
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.71      0.73       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.93      9782
          13       0.90      0.95      0.92       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.76      0.81       266
          20       0.97      0.98      0.97      8344
          21       1.00      0.87      0.93        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.88      0.64      0.74       115
          27       0.95      0.95      0.95        38
          28       0.88      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.96      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9697766245042718
train_acc 0.9698242170906187

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.49it/s]
valid_weighted_f1: 0.9700748737849355
valid_acc: 0.9701458271332001
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.71      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.89      0.95      0.92       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.86      0.76      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.90      0.67      0.77       115
          27       0.92      0.95      0.94        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.21it/s]
train_weighted_f1 0.9753057275278452
train_acc 0.9753423901038215

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9707079594212455
valid_acc: 0.9707835551209557
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.72      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.90      0.94      0.92       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.85      0.78      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.86      0.80      0.83        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.86      0.69      0.76       115
          27       0.90      0.95      0.92        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.95      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.979697050757796
train_acc 0.9797189087696045

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9719332732511775
valid_acc: 0.9719654776582628
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.76      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.94      0.93       306
          14       0.97      0.96      0.97       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.82      0.80      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.84      0.70      0.77       115
          27       0.95      0.92      0.93        38
          28       0.90      0.98      0.94       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9828155291714593
train_acc 0.9828284566107628

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9719488814777445
valid_acc: 0.9719824837379363
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.75      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.97      0.96      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.81      0.78      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.88      0.69      0.77       115
          27       0.95      0.92      0.93        38
          28       0.91      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9855588656418931
train_acc 0.9855673650405261

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.9721641681757321
valid_acc: 0.9722120658135284
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.72      0.77       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.91      0.96      0.93       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.85      0.77      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.85      0.70      0.77       115
          27       0.94      0.84      0.89        38
          28       0.91      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.95      0.96      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.21it/s]
train_weighted_f1 0.9879532432404463
train_acc 0.9879589981478649

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9724233294492183
valid_acc: 0.9724331448492837
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.71      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.79      0.81      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.83      0.74      0.78       115
          27       0.90      0.92      0.91        38
          28       0.90      0.97      0.94       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.23it/s]
train_weighted_f1 0.9897091485912177
train_acc 0.9897123668246929

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9724365158942362
valid_acc: 0.9724756600484673
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.69      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.96      0.97      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.84      0.78      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.85      0.75      0.80       115
          27       0.95      0.92      0.93        38
          28       0.91      0.94      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9912512445625954
train_acc 0.9912533346926985

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9724567693601248
valid_acc: 0.9724756600484673
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.70      0.76       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.95      0.93       306
          14       0.97      0.96      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.82      0.80      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.83      0.73      0.78       115
          27       0.92      0.92      0.92        38
          28       0.89      0.98      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.95      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9923410588123324
train_acc 0.9923429508419568

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9726629288536061
valid_acc: 0.9726797330045491
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.70      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.93      0.96      0.94       306
          14       0.96      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.80      0.81      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.86      0.75      0.80       115
          27       0.90      0.92      0.91        38
          28       0.93      0.94      0.94       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.95      0.96      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.98      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 12
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9933946629234239
train_acc 0.9933953968496712

Valid_Epoch: 12
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9722150532934044
valid_acc: 0.9722290718932018
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.68      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.97      0.97      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.80      0.80      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.94      0.96      2155
          26       0.85      0.75      0.80       115
          27       0.95      0.92      0.93        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.97      0.96      0.96      2051
          35       0.95      0.96      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 13
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.24it/s]
train_weighted_f1 0.9939661094647642
train_acc 0.9939667550254031

Valid_Epoch: 13
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.9729773928400411
valid_acc: 0.9729858424386718
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.73      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.96      0.93       306
          14       0.97      0.96      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.82      0.81      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.85      0.76      0.80       115
          27       0.92      0.92      0.92        38
          28       0.93      0.94      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.95      0.96      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 14
100%|█████████████████████████████████████████| 600/600 [03:05<00:00,  3.24it/s]
train_weighted_f1 0.9948635977076352
train_acc 0.9948641484426772

Valid_Epoch: 14
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.9728610260060755
valid_acc: 0.9728667998809575
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.72      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.93      0.95      0.94       306
          14       0.97      0.97      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.80      0.79      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.85      0.77      0.80       115
          27       0.95      0.92      0.93        38
          28       0.91      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.97      0.97      4030
          34       0.97      0.96      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
