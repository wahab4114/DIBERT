ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 5e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9074632222110066
train_acc 0.9078212349832628

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.52it/s]
valid_weighted_f1: 0.9572829326267159
valid_acc: 0.9575018068959653
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.57      0.65      0.61       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.92      0.91      9782
          13       0.84      0.93      0.88       306
          14       0.91      0.91      0.91       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.92      0.93      0.92     15211
          18       0.94      0.94      0.94     19633
          19       0.91      0.60      0.73       266
          20       0.96      0.97      0.96      8344
          21       0.80      0.27      0.40        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.90      0.93      2155
          26       0.87      0.45      0.59       115
          27       0.92      0.32      0.47        38
          28       0.87      0.85      0.86       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.95      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.88      0.91      2051
          35       0.96      0.93      0.94      3387
          36       0.94      0.97      0.96      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.88      0.89    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:16<00:00,  1.90it/s]
train_weighted_f1 0.9616565379215536
train_acc 0.9617455523270633

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9636653052268521
valid_acc: 0.9637855533353173
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.65      0.75      0.70       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.92      9782
          13       0.87      0.96      0.92       306
          14       0.91      0.95      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.96      0.91      0.93     15211
          18       0.93      0.96      0.94     19633
          19       0.81      0.70      0.75       266
          20       0.98      0.97      0.97      8344
          21       0.79      0.73      0.76        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.93      0.94      2155
          26       0.89      0.57      0.70       115
          27       0.94      0.45      0.61        38
          28       0.92      0.88      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.96      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.94      0.94      2051
          35       0.97      0.92      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.97      0.98      0.97      2611
          38       0.97      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.95      0.92      0.93    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:12<00:00,  1.92it/s]
train_weighted_f1 0.9729428653373625
train_acc 0.9729932371582471

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9685174446366197
valid_acc: 0.9685642617235661
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.76      0.75       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.95      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.92      0.97      0.94       306
          14       0.93      0.94      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.80      0.76      0.78       266
          20       0.98      0.97      0.98      8344
          21       0.78      0.93      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.94      2155
          26       0.87      0.70      0.77       115
          27       0.88      0.55      0.68        38
          28       0.92      0.91      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.97      0.96      0.96      4030
          34       0.92      0.97      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.97      0.98      2611
          38       0.98      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [04:43<00:00,  2.12it/s]
train_weighted_f1 0.978839255757781
train_acc 0.9788682435302714

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.49it/s]
valid_weighted_f1: 0.9691351672247658
valid_acc: 0.9692360018706687
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.67      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.95      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.87      0.97      0.92       306
          14       0.93      0.94      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.96      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.82      0.76      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.86      0.80      0.83        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.95      0.95      2155
          26       0.89      0.58      0.71       115
          27       0.87      0.53      0.66        38
          28       0.93      0.85      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.93      0.96      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.98      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      0.90      0.95        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.97    117605
   macro avg       0.96      0.92      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [04:46<00:00,  2.10it/s]
train_weighted_f1 0.9829453509273589
train_acc 0.982963331124365

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.50it/s]
valid_weighted_f1: 0.9695224954087894
valid_acc: 0.9696101356234854
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.69      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.95      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.90      0.97      0.93       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.81      0.77      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.87      0.87      0.87        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      0.99      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.92      0.63      0.75       115
          27       0.87      0.71      0.78        38
          28       0.94      0.88      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.91      0.97      0.94      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [04:48<00:00,  2.08it/s]
train_weighted_f1 0.9864951040539551
train_acc 0.9865061766155205

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.50it/s]
valid_weighted_f1: 0.9684172970098004
valid_acc: 0.9684962374048722
              precision    recall  f1-score   support

           1       0.99      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.65      0.73       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       1.00      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.90      0.96      0.93       306
          14       0.92      0.95      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.96      0.94     15211
          18       0.97      0.94      0.95     19633
          19       0.81      0.77      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.83      1.00      0.91        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.89      0.63      0.73       115
          27       0.95      0.55      0.70        38
          28       0.95      0.85      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.96      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.98      0.92      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.96      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [04:49<00:00,  2.07it/s]
train_weighted_f1 0.9887927507260353
train_acc 0.9887990433467571

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.52it/s]
valid_weighted_f1: 0.9697175494052394
valid_acc: 0.9698057055397304
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.66      0.74       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.95      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.95      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.83      0.75      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.76      0.87      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.94      0.66      0.78       115
          27       0.90      0.71      0.79        38
          28       0.91      0.94      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.96      0.95      2051
          35       0.98      0.92      0.95      3387
          36       0.95      0.98      0.96      1654
          37       0.99      0.97      0.98      2611
          38       0.93      0.97      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [04:59<00:00,  2.00it/s]
train_weighted_f1 0.9904923926129425
train_acc 0.9904971878132912

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9707624776981081
valid_acc: 0.9708345733599761
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.89      0.72      0.80       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.87      0.76      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.82      0.93      0.87        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.91      0.70      0.79       115
          27       0.87      0.71      0.78        38
          28       0.91      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.93      0.97      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [05:04<00:00,  1.97it/s]
train_weighted_f1 0.9920705899256266
train_acc 0.9920742638187966

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9709381644742191
valid_acc: 0.9710131371965478
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.75      0.80       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.95      0.93      0.94      9782
          13       0.94      0.96      0.95       306
          14       0.97      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.92      0.69      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       0.99      1.00      1.00      2100
          23       0.99      1.00      0.99      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.87      0.78      0.83       115
          27       0.86      0.84      0.85        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.96      0.95      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.94      0.97      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [05:16<00:00,  1.90it/s]
train_weighted_f1 0.9930440258001626
train_acc 0.9930459975191586

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9706998045803902
valid_acc: 0.9707835551209557
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.57      0.69       101
           5       0.88      1.00      0.93        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.94      0.93      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.90      0.73      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.86      0.80      0.83        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.91      0.74      0.82       115
          27       0.89      0.66      0.76        38
          28       0.90      0.95      0.92       248
          29       1.00      0.97      0.98        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.98      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [05:06<00:00,  1.96it/s]
train_weighted_f1 0.9944631072704437
train_acc 0.9944637729180472

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9702072905192044
valid_acc: 0.9702223544917308
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.76      0.77       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       1.00      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.92      0.95      0.93      9782
          13       0.93      0.96      0.94       306
          14       0.97      0.91      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.94      0.95     19633
          19       0.87      0.74      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.86      0.80      0.83        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.88      0.73      0.80       115
          27       0.87      0.89      0.88        38
          28       0.87      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.98      0.97      2601
          33       0.94      0.99      0.96      4030
          34       0.93      0.97      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.95      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9952558328925722
train_acc 0.9952560279349544

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.50it/s]
valid_weighted_f1: 0.9696384361023443
valid_acc: 0.9697631903405467
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.97      0.57      0.72       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.93      0.95      0.94       306
          14       0.97      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.91      0.64      0.75       266
          20       0.97      0.99      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.96      0.95      2155
          26       0.88      0.71      0.79       115
          27       0.88      0.79      0.83        38
          28       0.88      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.94      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.98      0.97      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      0.90      0.95        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
