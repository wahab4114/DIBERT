ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 2e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.91it/s]
train_weighted_f1 0.8834313963239011
train_acc 0.8841735909330343

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9492461215322788
valid_acc: 0.9497300284851835
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.42      0.53       101
           5       1.00      0.71      0.83        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.94      1.00      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.91      0.89      9782
          13       0.84      0.87      0.85       306
          14       0.88      0.85      0.86       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.93      0.90      0.91     15211
          18       0.91      0.94      0.93     19633
          19       0.87      0.55      0.68       266
          20       0.95      0.96      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.98      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.98      1.00      0.99       925
          25       0.95      0.89      0.92      2155
          26       0.84      0.47      0.60       115
          27       1.00      0.05      0.10        38
          28       0.81      0.85      0.83       248
          29       0.98      0.98      0.98        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.94      0.96      2601
          33       0.95      0.96      0.96      4030
          34       0.90      0.90      0.90      2051
          35       0.95      0.92      0.94      3387
          36       0.95      0.96      0.95      1654
          37       0.97      0.95      0.96      2611
          38       0.92      0.96      0.94       370
          39       0.98      0.99      0.98       270
          40       0.00      0.00      0.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.88      0.82      0.84    117605
weighted avg       0.95      0.95      0.95    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:06<00:00,  1.96it/s]
train_weighted_f1 0.9528362363099705
train_acc 0.9530403051774821

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9612154935165519
valid_acc: 0.96143021130054
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.60      0.65       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.94      0.92      9782
          13       0.84      0.94      0.89       306
          14       0.91      0.92      0.91       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.93      0.93      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.87      0.62      0.73       266
          20       0.97      0.97      0.97      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.92      0.94      2155
          26       0.89      0.49      0.63       115
          27       0.93      0.37      0.53        38
          28       0.85      0.91      0.88       248
          29       0.98      0.98      0.98        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.96      2601
          33       0.96      0.97      0.96      4030
          34       0.92      0.95      0.93      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.97      0.96      1654
          37       0.98      0.97      0.97      2611
          38       0.93      0.96      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.91      0.88      0.89    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9647883058177847
train_acc 0.9648912083057213

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9654992917216995
valid_acc: 0.9656562220994005
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.58      0.67       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.94      0.93      9782
          13       0.87      0.95      0.91       306
          14       0.91      0.94      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.94      0.95     19633
          19       0.84      0.67      0.75       266
          20       0.97      0.98      0.97      8344
          21       0.90      0.60      0.72        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.93      0.95      2155
          26       0.88      0.55      0.67       115
          27       0.88      0.39      0.55        38
          28       0.88      0.90      0.89       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.93      0.96      0.94      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.90      0.91    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9714412054472517
train_acc 0.9715191755450204

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9684750549848752
valid_acc: 0.9685897708430764
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.62      0.70       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.88      0.95      0.91       306
          14       0.91      0.95      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.95      0.94     15211
          18       0.96      0.95      0.95     19633
          19       0.82      0.75      0.78       266
          20       0.98      0.98      0.98      8344
          21       0.82      0.93      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.87      0.62      0.72       115
          27       0.88      0.39      0.55        38
          28       0.89      0.92      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.96      0.95      2051
          35       0.98      0.92      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.92      0.92    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [04:55<00:00,  2.03it/s]
train_weighted_f1 0.9762885435452063
train_acc 0.9763396119012421

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9696896564987617
valid_acc: 0.9697716933803835
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.63      0.70       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.88      0.95      0.91       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.95      0.95     19633
          19       0.79      0.76      0.78       266
          20       0.98      0.97      0.98      8344
          21       0.86      0.80      0.83        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.85      0.59      0.70       115
          27       0.84      0.71      0.77        38
          28       0.90      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.97      0.96      2051
          35       0.98      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.94      0.97      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.979927150466727
train_acc 0.9799599836876178

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9700932193352158
valid_acc: 0.9701883423323838
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.63      0.71       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.88      0.96      0.92       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.82      0.78      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.76      0.87      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.86      0.57      0.69       115
          27       0.88      0.76      0.82        38
          28       0.90      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.91it/s]
train_weighted_f1 0.9826654588187377
train_acc 0.9826903960850283

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.52it/s]
valid_weighted_f1: 0.9705215223429075
valid_acc: 0.970579482164874
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.66      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.81      0.78      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.78      0.93      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.83      0.73      0.78       115
          27       0.86      0.82      0.84        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.94      0.99      0.96      4030
          34       0.95      0.96      0.96      2051
          35       0.98      0.92      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9850141537849826
train_acc 0.9850299909942057

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9708388312694748
valid_acc: 0.9709281067981803
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.65      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.90      0.98      0.93       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.85      0.75      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.88      0.93      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.94      0.96      2155
          26       0.83      0.65      0.73       115
          27       0.88      0.79      0.83        38
          28       0.89      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9867348466771708
train_acc 0.9867472515335338

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.52it/s]
valid_weighted_f1: 0.9716115508870261
valid_acc: 0.9716593682241401
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.67      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.95      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.95      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.86      0.76      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.83      1.00      0.91        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.96      2155
          26       0.83      0.73      0.78       115
          27       0.86      0.82      0.84        38
          28       0.90      0.93      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.98      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.93      0.97      0.95       370
          39       1.00      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9886439652767257
train_acc 0.9886524867886697

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9713133237077176
valid_acc: 0.9713447557501806
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.71      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.89      0.97      0.93       306
          14       0.95      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.85      0.77      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.85      0.63      0.73       115
          27       0.88      0.74      0.80        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [05:07<00:00,  1.95it/s]
train_weighted_f1 0.9896432559832488
train_acc 0.9896507705901344

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9707490994476408
valid_acc: 0.9708175672803027
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.68      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.90      0.97      0.93       306
          14       0.97      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.94      0.96      0.95     19633
          19       0.84      0.79      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.84      0.66      0.74       115
          27       0.86      0.79      0.82        38
          28       0.91      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9908828428285339
train_acc 0.9908858812934359

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9704181089415702
valid_acc: 0.9704944517665065
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.68      0.71       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.91      0.96      0.94       306
          14       0.97      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.94      0.97      0.95     19633
          19       0.90      0.69      0.78       266
          20       0.98      0.98      0.98      8344
          21       0.86      0.80      0.83        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.82      0.72      0.77       115
          27       0.84      0.82      0.83        38
          28       0.86      0.97      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
