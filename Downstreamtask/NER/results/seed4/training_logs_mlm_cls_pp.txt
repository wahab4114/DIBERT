ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 2e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:09<00:00,  1.94it/s]
train_weighted_f1 0.8842818569888505
train_acc 0.8849446058690591

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.46it/s]
valid_weighted_f1: 0.9496345256497205
valid_acc: 0.9500956591981633
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.43      0.53       101
           5       1.00      0.76      0.86        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.94      1.00      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.87      0.92      0.89      9782
          13       0.83      0.86      0.85       306
          14       0.86      0.85      0.85       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.92      0.91      0.91     15211
          18       0.93      0.93      0.93     19633
          19       0.88      0.56      0.68       266
          20       0.95      0.96      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.95      0.89      0.92      2155
          26       0.90      0.46      0.61       115
          27       1.00      0.03      0.05        38
          28       0.81      0.84      0.83       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.94      0.95      2601
          33       0.94      0.97      0.95      4030
          34       0.90      0.90      0.90      2051
          35       0.97      0.90      0.93      3387
          36       0.94      0.96      0.95      1654
          37       0.97      0.94      0.96      2611
          38       0.91      0.96      0.94       370
          39       0.98      1.00      0.99       270
          40       0.00      0.00      0.00        10
          41       0.99      1.00      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.88      0.83      0.84    117605
weighted avg       0.95      0.95      0.95    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:16<00:00,  1.90it/s]
train_weighted_f1 0.9524795963700684
train_acc 0.9527015258874105

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.44it/s]
valid_weighted_f1: 0.9614311021956459
valid_acc: 0.9616682964159687
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.58      0.66       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.93      0.92      9782
          13       0.85      0.93      0.89       306
          14       0.92      0.92      0.92       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.93      0.93      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.89      0.62      0.73       266
          20       0.97      0.97      0.97      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.96      0.93      0.94      2155
          26       0.92      0.49      0.64       115
          27       0.84      0.42      0.56        38
          28       0.87      0.89      0.88       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.94      0.94      2051
          35       0.97      0.92      0.94      3387
          36       0.96      0.96      0.96      1654
          37       0.98      0.97      0.97      2611
          38       0.94      0.96      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.91      0.88      0.89    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:17<00:00,  1.89it/s]
train_weighted_f1 0.9647408832350715
train_acc 0.9648614721924861

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.44it/s]
valid_weighted_f1: 0.9663153862813202
valid_acc: 0.966464010883891
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.67      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.93      9782
          13       0.87      0.94      0.90       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.93      0.94     15211
          18       0.94      0.96      0.95     19633
          19       0.87      0.65      0.75       266
          20       0.98      0.97      0.98      8344
          21       0.67      0.40      0.50        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.92      0.53      0.67       115
          27       0.92      0.63      0.75        38
          28       0.90      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.98      0.96      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.90      0.92    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [05:17<00:00,  1.89it/s]
train_weighted_f1 0.9712863773372381
train_acc 0.971361998946492

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.45it/s]
valid_weighted_f1: 0.9683953361763467
valid_acc: 0.968538752604056
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.66      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.86      0.96      0.91       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.95      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.69      0.77       266
          20       0.98      0.98      0.98      8344
          21       0.78      0.47      0.58        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.89      0.55      0.68       115
          27       0.87      0.71      0.78        38
          28       0.90      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.91      0.92    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [05:16<00:00,  1.90it/s]
train_weighted_f1 0.9762444078130071
train_acc 0.9762960697354336

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.44it/s]
valid_weighted_f1: 0.9692678221394805
valid_acc: 0.9693975596275669
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.67      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.89      0.96      0.92       306
          14       0.93      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.85      0.73      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.73      0.73      0.73        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.95      2155
          26       0.87      0.63      0.73       115
          27       0.88      0.58      0.70        38
          28       0.90      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.95      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.92      0.92    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [05:16<00:00,  1.89it/s]
train_weighted_f1 0.9796681300073505
train_acc 0.979704040712987

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.45it/s]
valid_weighted_f1: 0.9704539724352401
valid_acc: 0.9705284639258535
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.68      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.89      0.97      0.93       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.83      0.76      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.79      0.73      0.76        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.87      0.64      0.74       115
          27       0.90      0.71      0.79        38
          28       0.91      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [05:17<00:00,  1.89it/s]
train_weighted_f1 0.9824858795877344
train_acc 0.9825119794056176

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.45it/s]
valid_weighted_f1: 0.9707288232278338
valid_acc: 0.970809064240466
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.67      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.95      0.93      0.94      9782
          13       0.89      0.97      0.93       306
          14       0.95      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.96      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.83      0.75      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.81      0.87      0.84        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.96      2155
          26       0.88      0.64      0.74       115
          27       0.91      0.76      0.83        38
          28       0.89      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.94      0.97      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.93      0.97      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [05:17<00:00,  1.89it/s]
train_weighted_f1 0.9846989431369096
train_acc 0.9847209478173693

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.47it/s]
valid_weighted_f1: 0.9706808439191367
valid_acc: 0.9707240338420986
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.63      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.97      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.83      0.75      0.79       266
          20       0.98      0.97      0.98      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.85      0.71      0.78       115
          27       0.85      0.87      0.86        38
          28       0.91      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.95      0.95      2051
          35       0.98      0.93      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.92      0.97      0.94       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [05:16<00:00,  1.89it/s]
train_weighted_f1 0.9864528299776091
train_acc 0.9864679444699326

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.47it/s]
valid_weighted_f1: 0.9703183081265295
valid_acc: 0.9703839122486289
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.74      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.89      0.97      0.93       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.97      0.93      0.95     15211
          18       0.94      0.97      0.95     19633
          19       0.80      0.77      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.82      0.93      0.87        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.86      0.63      0.73       115
          27       0.87      0.68      0.76        38
          28       0.90      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.98      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.94      0.97      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [05:17<00:00,  1.89it/s]
train_weighted_f1 0.988425666333147
train_acc 0.9884347759596268

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.46it/s]
valid_weighted_f1: 0.9715404438973618
valid_acc: 0.9716168530249564
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.64      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      1.00     12278
          12       0.93      0.95      0.94      9782
          13       0.90      0.97      0.94       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.83      0.77      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.91      0.67      0.77        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.67      0.76       115
          27       0.93      0.71      0.81        38
          28       0.91      0.93      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.98      0.93      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [05:10<00:00,  1.93it/s]
train_weighted_f1 0.9897329234278032
train_acc 0.9897389169257956

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.48it/s]
valid_weighted_f1: 0.9714709911907548
valid_acc: 0.9715148165469155
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.66      0.75       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.92      0.95      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.78      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.88      0.69      0.77       115
          27       0.89      0.82      0.85        38
          28       0.90      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.97      0.95      0.96      2051
          35       0.97      0.95      0.96      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.94      0.97      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [05:16<00:00,  1.89it/s]
train_weighted_f1 0.9910106054212431
train_acc 0.9910154457868176

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.44it/s]
valid_weighted_f1: 0.9715234162648549
valid_acc: 0.9715743378257727
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.70      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.85      0.75      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.85      0.70      0.77       115
          27       0.91      0.82      0.86        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
