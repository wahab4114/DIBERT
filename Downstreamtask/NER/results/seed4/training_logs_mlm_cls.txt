ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 5e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:08<00:00,  1.95it/s]
train_weighted_f1 0.9084107728550581
train_acc 0.9087536745339926

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.46it/s]
valid_weighted_f1: 0.9578865071120748
valid_acc: 0.9580885166447005
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.61      0.64      0.62       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.91      0.91      9782
          13       0.84      0.94      0.89       306
          14       0.89      0.93      0.91       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.92      0.94      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.87      0.62      0.72       266
          20       0.96      0.97      0.96      8344
          21       0.88      0.47      0.61        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.90      0.93      2155
          26       0.86      0.48      0.61       115
          27       1.00      0.32      0.48        38
          28       0.86      0.87      0.86       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.95      0.96      2601
          33       0.94      0.97      0.96      4030
          34       0.93      0.91      0.92      2051
          35       0.96      0.93      0.94      3387
          36       0.96      0.97      0.96      1654
          37       0.98      0.96      0.97      2611
          38       0.94      0.97      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.89      0.90    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [04:57<00:00,  2.02it/s]
train_weighted_f1 0.9617336853828684
train_acc 0.9618103345737541

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.47it/s]
valid_weighted_f1: 0.9651858549604302
valid_acc: 0.9653246035457677
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.67      0.70       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.92      9782
          13       0.87      0.96      0.91       306
          14       0.92      0.93      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.92      0.94     15211
          18       0.93      0.96      0.95     19633
          19       0.83      0.70      0.76       266
          20       0.97      0.98      0.97      8344
          21       1.00      0.60      0.75        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.93      0.95      2155
          26       0.89      0.54      0.67       115
          27       0.95      0.55      0.70        38
          28       0.91      0.89      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.98      0.95      0.96      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.95      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.91      0.92    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:12<00:00,  1.92it/s]
train_weighted_f1 0.9726531000541063
train_acc 0.9726990620380283

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.47it/s]
valid_weighted_f1: 0.9680446975739021
valid_acc: 0.9681306066918923
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.76      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.90      0.96      0.93       306
          14       0.93      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.87      0.74      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.85      0.73      0.79        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.93      0.94      2155
          26       0.87      0.63      0.73       115
          27       0.93      0.66      0.77        38
          28       0.90      0.90      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.93      0.97      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.95      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [04:59<00:00,  2.00it/s]
train_weighted_f1 0.9788349470025308
train_acc 0.9788618715060067

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.48it/s]
valid_weighted_f1: 0.9698593304146212
valid_acc: 0.9698822328982611
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.75      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.91      0.97      0.94       306
          14       0.93      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.79      0.81      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.88      0.93      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.86      0.66      0.75       115
          27       0.89      0.66      0.76        38
          28       0.92      0.93      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.96      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9833933566066809
train_acc 0.98341149683098

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.49it/s]
valid_weighted_f1: 0.9689770817008864
valid_acc: 0.9690914501934441
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.61      0.71       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.94      0.97        65
          11       1.00      0.99      0.99     12278
          12       0.95      0.91      0.93      9782
          13       0.89      0.97      0.93       306
          14       0.97      0.94      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.88      0.71      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.87      0.87      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.85      0.62      0.71       115
          27       0.89      0.89      0.89        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.96      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.94      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9862016494883014
train_acc 0.9862120014953017

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.48it/s]
valid_weighted_f1: 0.9694790985690183
valid_acc: 0.9695166021852812
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.64      0.73       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.95      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.91      0.96      0.94       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.96      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.76      0.82      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.80      0.73      0.76       115
          27       1.00      0.55      0.71        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.98      0.92      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.96      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9886340504488929
train_acc 0.9886408047441845

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.48it/s]
valid_weighted_f1: 0.9697932800687273
valid_acc: 0.9698652268185877
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.66      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.90      0.98      0.94       306
          14       0.93      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.82      0.76      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.76      0.87      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.88      0.69      0.77       115
          27       1.00      0.63      0.77        38
          28       0.91      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.95      0.98      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.97      0.92      0.95      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.91      0.97      0.94       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9907890850922911
train_acc 0.9907945489456423

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.48it/s]
valid_weighted_f1: 0.9707584435093911
valid_acc: 0.9708430763998129
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.62      0.72       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.94      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.98      0.95       306
          14       0.95      0.94      0.95       331
          15       1.00      0.98      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.89      0.73      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.95      0.95      2155
          26       0.87      0.71      0.78       115
          27       0.93      0.74      0.82        38
          28       0.93      0.87      0.90       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.96      0.98      2611
          38       0.92      0.97      0.94       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9921928414954357
train_acc 0.9921942702757812

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.47it/s]
valid_weighted_f1: 0.9702912588746767
valid_acc: 0.9703924152884656
              precision    recall  f1-score   support

           1       0.99      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.70      0.76       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       1.00      0.98      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.87      0.97      0.91       306
          14       0.94      0.95      0.94       331
          15       1.00      0.98      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.88      0.72      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.88      0.93      0.90        15
          22       1.00      1.00      1.00      2100
          23       0.99      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.86      0.59      0.70       115
          27       0.92      0.63      0.75        38
          28       0.91      0.97      0.94       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.98      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.97      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9933449205398358
train_acc 0.993346544663642

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.49it/s]
valid_weighted_f1: 0.9710821786474015
valid_acc: 0.9711576888737724
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.90      0.71      0.80       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.97      0.97        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.89      0.97      0.93       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.91      0.73      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.88      0.60      0.72       115
          27       0.93      0.71      0.81        38
          28       0.89      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.98      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.96      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [05:12<00:00,  1.92it/s]
train_weighted_f1 0.994722033324225
train_acc 0.9947229019048105

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.49it/s]
valid_weighted_f1: 0.9686673986793447
valid_acc: 0.9687428255601378
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.68      0.75       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.97      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.91      0.95      0.93      9782
          13       0.89      0.98      0.94       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.97      0.94      0.95     19633
          19       0.93      0.68      0.79       266
          20       0.97      0.99      0.98      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.86      0.67      0.75       115
          27       0.91      0.76      0.83        38
          28       0.90      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.95      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.98      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [05:16<00:00,  1.90it/s]
train_weighted_f1 0.995167640705703
train_acc 0.9951678815992931

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.50it/s]
valid_weighted_f1: 0.9710595655076694
valid_acc: 0.971106670634752
              precision    recall  f1-score   support

           1       0.99      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.77      0.81       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       1.00      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.93      0.95      0.94       306
          14       0.99      0.93      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.87      0.76      0.81       266
          20       0.97      0.99      0.98      8344
          21       1.00      0.80      0.89        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.93      0.95      2155
          26       0.84      0.71      0.77       115
          27       0.92      0.95      0.94        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.96      0.98      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
