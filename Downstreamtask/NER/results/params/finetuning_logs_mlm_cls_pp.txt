ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
results/params/dibert_NER_mlm_cls_pp_29_best.json
selecting grid search sampler
[I 2021-01-12 21:01:46,971] A new study created in memory with name: no-name-37789637-3f3f-4bbf-a16a-e20778fd8046
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.8857587826349198
train_acc 0.8863368931708892

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9509402924451209
valid_acc: 0.9514051273330215
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.68      0.44      0.53       101
           5       1.00      0.52      0.69        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.91      0.90      9782
          13       0.83      0.86      0.84       306
          14       0.89      0.85      0.87       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.92      0.91      0.92     15211
          18       0.93      0.94      0.93     19633
          19       0.89      0.55      0.68       266
          20       0.95      0.96      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       1.00      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.94      0.91      0.92      2155
          26       0.90      0.45      0.60       115
          27       0.80      0.11      0.19        38
          28       0.84      0.86      0.85       248
          29       1.00      0.97      0.98        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.94      0.95      2601
          33       0.94      0.97      0.95      4030
          34       0.91      0.90      0.91      2051
          35       0.95      0.92      0.93      3387
          36       0.95      0.96      0.96      1654
          37       0.98      0.94      0.96      2611
          38       0.93      0.97      0.95       370
          39       0.98      1.00      0.99       270
          40       0.00      0.00      0.00        10
          41       1.00      0.99      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.88      0.82      0.84    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9528181590624105
train_acc 0.9530318091451292

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9614601543575162
valid_acc: 0.9616938055354789
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.71      0.50      0.58       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.93      0.92      9782
          13       0.84      0.93      0.88       306
          14       0.92      0.91      0.92       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.92      0.93     15211
          18       0.94      0.95      0.94     19633
          19       0.86      0.64      0.74       266
          20       0.98      0.97      0.97      8344
          21       1.00      0.07      0.12        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.92      0.94      2155
          26       0.90      0.46      0.61       115
          27       0.86      0.50      0.63        38
          28       0.85      0.92      0.88       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.96      2601
          33       0.95      0.98      0.96      4030
          34       0.93      0.95      0.94      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.97      0.96      1654
          37       0.98      0.97      0.98      2611
          38       0.94      0.97      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.88      0.89    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.91it/s]
train_weighted_f1 0.9646202998632379
train_acc 0.9647255356748399

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.56it/s]
valid_weighted_f1: 0.9664819530716194
valid_acc: 0.9666170656009523
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.63      0.70       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.93      9782
          13       0.87      0.95      0.91       306
          14       0.94      0.92      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.68      0.76       266
          20       0.97      0.98      0.98      8344
          21       0.82      0.60      0.69        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.93      0.95      2155
          26       0.89      0.57      0.69       115
          27       0.87      0.71      0.78        38
          28       0.88      0.91      0.89       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.98      0.96      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.93      0.96      0.94      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.91it/s]
train_weighted_f1 0.9712446586635642
train_acc 0.9713173947766394

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9686733764333213
valid_acc: 0.9687768377194848
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.60      0.68       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.87      0.96      0.91       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.95      0.95      0.95     19633
          19       0.83      0.70      0.76       266
          20       0.98      0.97      0.98      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.94      0.96      2155
          26       0.88      0.58      0.70       115
          27       0.83      0.76      0.79        38
          28       0.89      0.93      0.91       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.91it/s]
train_weighted_f1 0.9761260603527833
train_acc 0.9761792492905813

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9694902556055933
valid_acc: 0.9696101356234854
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.61      0.70       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.89      0.96      0.92       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.88      0.72      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.80      0.80      0.80        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.84      0.63      0.72       115
          27       0.89      0.66      0.76        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.94      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9799201889747302
train_acc 0.9799557356714415

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.56it/s]
valid_weighted_f1: 0.9709301430945961
valid_acc: 0.9710131371965478
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.62      0.69       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.89      0.97      0.93       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.83      0.76      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.83      1.00      0.91        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.87      0.62      0.72       115
          27       0.85      0.74      0.79        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.94      0.96      0.95      2051
          35       0.98      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.92it/s]
train_weighted_f1 0.9824854714864688
train_acc 0.9825119794056176

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9710209358064538
valid_acc: 0.9710981675949152
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.66      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.89      0.97      0.92       306
          14       0.93      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.83      0.77      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.95      2155
          26       0.82      0.65      0.73       115
          27       0.86      0.66      0.75        38
          28       0.90      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.93      0.97      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-12 21:40:40,749] Trial 0 finished with value: 0.9710981675949152 and parameters: {'lrmain': 2e-05, 'drop_out': 0.1}. Best is trial 0 with value: 0.9710981675949152.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.91it/s]
train_weighted_f1 0.91409384822539
train_acc 0.9144024740446212

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9605000378629928
valid_acc: 0.9607329620339271
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.55      0.63       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.92      0.92      9782
          13       0.84      0.93      0.88       306
          14       0.94      0.91      0.92       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.92      0.94      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.89      0.61      0.72       266
          20       0.97      0.97      0.97      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.92      0.94      2155
          26       0.90      0.45      0.60       115
          27       0.88      0.61      0.72        38
          28       0.87      0.90      0.89       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.97      0.96      4030
          34       0.94      0.93      0.94      2051
          35       0.96      0.92      0.94      3387
          36       0.95      0.97      0.96      1654
          37       0.99      0.95      0.97      2611
          38       0.93      0.97      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.91      0.88      0.89    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9640850142334877
train_acc 0.9641764795840343

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9663927295099953
valid_acc: 0.9665150291229114
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.70      0.74       101
           5       0.95      1.00      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.86      0.95      0.91       306
          14       0.93      0.93      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.93      0.94     15211
          18       0.94      0.96      0.95     19633
          19       0.88      0.71      0.78       266
          20       0.98      0.97      0.97      8344
          21       1.00      0.47      0.64        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.93      0.95      2155
          26       0.86      0.53      0.66       115
          27       0.85      0.61      0.71        38
          28       0.91      0.88      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.94      0.99      0.96      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.91      0.92    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9736193159692158
train_acc 0.9736697337343461

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.57it/s]
valid_weighted_f1: 0.9681738701923167
valid_acc: 0.9682581522894435
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.72      0.70      0.71       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.87      0.96      0.91       306
          14       0.93      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.96      0.93      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.86      0.74      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.75      0.80      0.77        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.85      0.55      0.67       115
          27       0.86      0.63      0.73        38
          28       0.92      0.88      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.96      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.93      0.97      0.95      2051
          35       0.97      0.94      0.95      3387
          36       0.95      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.93      0.97      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9787420606378464
train_acc 0.9787747871743896

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.56it/s]
valid_weighted_f1: 0.9686673912198815
valid_acc: 0.9687598316398113
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.70      0.75       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.92      0.95      0.93      9782
          13       0.90      0.96      0.93       306
          14       0.93      0.94      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.92      0.94     15211
          18       0.94      0.96      0.95     19633
          19       0.86      0.72      0.79       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.53      0.70        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.93      0.95      2155
          26       0.85      0.67      0.75       115
          27       0.88      0.55      0.68        38
          28       0.90      0.88      0.89       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.94      0.97      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.97      0.99      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9828585241741494
train_acc 0.9828794328048801

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9700181617971961
valid_acc: 0.9700692997746695
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.74      0.72       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.95      0.93      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.94      0.96      0.95       331
          15       1.00      0.98      0.99        66
          16       1.00      1.00      1.00       678
          17       0.94      0.96      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.82      0.78      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.82      0.93      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.80      0.74      0.77       115
          27       0.92      0.63      0.75        38
          28       0.92      0.82      0.87       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.97      0.95      2051
          35       0.96      0.95      0.95      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [05:12<00:00,  1.92it/s]
train_weighted_f1 0.9860622301544574
train_acc 0.9860750029736113

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.58it/s]
valid_weighted_f1: 0.9700463847658345
valid_acc: 0.9701033119340164
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.89      0.69      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.95      0.93      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.92      0.96      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.96      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.78      0.81      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.87      0.87      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.95      2155
          26       0.82      0.75      0.78       115
          27       0.92      0.58      0.71        38
          28       0.93      0.86      0.90       248
          29       1.00      0.98      0.99        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.92      0.98      0.95      2051
          35       0.97      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.97      0.98      2611
          38       0.93      0.97      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [05:11<00:00,  1.93it/s]
train_weighted_f1 0.988403582758666
train_acc 0.9884124738747005

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.58it/s]
valid_weighted_f1: 0.9695681678448307
valid_acc: 0.969652650822669
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.68      0.74       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.95      0.92      0.93      9782
          13       0.91      0.97      0.94       306
          14       0.92      0.95      0.93       331
          15       1.00      0.98      0.99        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.80      0.82      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.78      0.47      0.58        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.96      0.95      2155
          26       0.89      0.70      0.78       115
          27       0.91      0.53      0.67        38
          28       0.90      0.94      0.92       248
          29       1.00      0.98      0.99        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.95      0.95      2051
          35       0.98      0.92      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.94      0.97      0.95       370
          39       1.00      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-12 22:19:30,561] Trial 1 finished with value: 0.969652650822669 and parameters: {'lrmain': 5e-05, 'drop_out': 0.1}. Best is trial 0 with value: 0.9710981675949152.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:12<00:00,  1.92it/s]
train_weighted_f1 0.9006447612138526
train_acc 0.9010658272586702

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9549205619888326
valid_acc: 0.9552825134985757
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.71      0.46      0.55       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.93      1.00      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.93      0.90      9782
          13       0.83      0.91      0.87       306
          14       0.90      0.87      0.89       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.93      0.91      0.92     15211
          18       0.93      0.94      0.93     19633
          19       0.88      0.59      0.71       266
          20       0.95      0.97      0.96      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       1.00      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.95      0.92      0.93      2155
          26       0.88      0.43      0.57       115
          27       0.89      0.21      0.34        38
          28       0.87      0.83      0.85       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.95      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.90      0.92      2051
          35       0.96      0.93      0.94      3387
          36       0.95      0.97      0.96      1654
          37       0.98      0.95      0.96      2611
          38       0.94      0.96      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      0.90      0.95        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.91      0.86      0.87    117605
weighted avg       0.96      0.96      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:12<00:00,  1.92it/s]
train_weighted_f1 0.9583794315819283
train_acc 0.9585276800734057

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9643034829810584
valid_acc: 0.9644657965222567
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.62      0.68       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.94      0.92      9782
          13       0.86      0.94      0.90       306
          14       0.93      0.92      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.95      0.93      0.94     15211
          18       0.94      0.95      0.95     19633
          19       0.86      0.65      0.74       266
          20       0.98      0.97      0.97      8344
          21       1.00      0.33      0.50        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.93      0.95      2155
          26       0.89      0.49      0.63       115
          27       0.91      0.55      0.69        38
          28       0.91      0.85      0.88       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.94      0.89      0.91    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.92it/s]
train_weighted_f1 0.9692752488975485
train_acc 0.9693548113031214

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.57it/s]
valid_weighted_f1: 0.9676003438961832
valid_acc: 0.9676884486203818
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.70      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.88      0.97      0.92       306
          14       0.94      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.93      0.94     15211
          18       0.94      0.96      0.95     19633
          19       0.84      0.71      0.77       266
          20       0.98      0.97      0.98      8344
          21       0.78      0.47      0.58        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.91      0.59      0.72       115
          27       0.89      0.66      0.76        38
          28       0.91      0.88      0.90       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.98      0.97      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.92      0.97      0.94      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [05:11<00:00,  1.92it/s]
train_weighted_f1 0.9755228799436114
train_acc 0.9755760309935261

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.57it/s]
valid_weighted_f1: 0.9699883571523674
valid_acc: 0.970086305854343
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.65      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.89      0.95      0.92       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.86      0.73      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.85      0.73      0.79        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.91      0.61      0.73       115
          27       0.90      0.71      0.79        38
          28       0.91      0.91      0.91       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.94      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [05:11<00:00,  1.92it/s]
train_weighted_f1 0.9802451763953003
train_acc 0.9802775228968071

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.57it/s]
valid_weighted_f1: 0.970061148898505
valid_acc: 0.9701373240933634
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.69      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.89      0.98      0.93       306
          14       0.94      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.82      0.77      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.80      0.80      0.80        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.86      0.63      0.72       115
          27       0.89      0.66      0.76        38
          28       0.90      0.94      0.92       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.94      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [05:12<00:00,  1.92it/s]
train_weighted_f1 0.9832735758864629
train_acc 0.9832946763861277

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9705837479505927
valid_acc: 0.9706475064835679
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.69      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.95      0.93      0.94      9782
          13       0.91      0.96      0.94       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.96      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.83      0.79      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.85      0.73      0.79        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.87      0.67      0.75       115
          27       0.85      0.76      0.81        38
          28       0.89      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.92it/s]
train_weighted_f1 0.9856887687118233
train_acc 0.9857054255662605

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.57it/s]
valid_weighted_f1: 0.970541374997862
valid_acc: 0.970613494324221
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.66      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.89      0.97      0.93       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.96      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.82      0.81      0.82       266
          20       0.98      0.98      0.98      8344
          21       0.79      1.00      0.88        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.84      0.63      0.72       115
          27       0.93      0.68      0.79        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.97      0.94      0.96      2051
          35       0.98      0.92      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-12 22:58:14,108] Trial 2 finished with value: 0.970613494324221 and parameters: {'lrmain': 3e-05, 'drop_out': 0.1}. Best is trial 0 with value: 0.9710981675949152.

Process finished with exit code 0
