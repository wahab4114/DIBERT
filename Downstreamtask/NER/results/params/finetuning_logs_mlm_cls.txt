ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
results/params/dibert_NER_mlm_cls_29_best.json
selecting grid search sampler
[I 2021-01-12 18:41:53,697] A new study created in memory with name: no-name-687d9c14-7d87-4a47-884d-156512ba5361
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.8925176755455749
train_acc 0.8928448539532039

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.46it/s]
valid_weighted_f1: 0.9516252836719266
valid_acc: 0.9519323158028995
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.60      0.50      0.54       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.94      0.98      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.90      0.90      9782
          13       0.84      0.91      0.87       306
          14       0.92      0.89      0.90       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.91      0.92      0.92     15211
          18       0.93      0.94      0.93     19633
          19       0.87      0.58      0.70       266
          20       0.96      0.95      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      0.99      1397
          24       0.99      1.00      1.00       925
          25       0.96      0.88      0.92      2155
          26       0.92      0.48      0.63       115
          27       1.00      0.45      0.62        38
          28       0.82      0.89      0.85       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.94      0.95      2601
          33       0.94      0.97      0.95      4030
          34       0.92      0.86      0.89      2051
          35       0.96      0.91      0.94      3387
          36       0.94      0.96      0.95      1654
          37       0.97      0.96      0.96      2611
          38       0.93      0.96      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      0.90      0.95        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.90      0.87      0.88    117605
weighted avg       0.95      0.95      0.95    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9547302819676656
train_acc 0.9548446500484273

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.50it/s]
valid_weighted_f1: 0.962920162883971
valid_acc: 0.9630372858296841
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.64      0.69       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.94      0.92      9782
          13       0.88      0.94      0.91       306
          14       0.93      0.92      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.92      0.93     15211
          18       0.94      0.95      0.95     19633
          19       0.87      0.65      0.75       266
          20       0.97      0.97      0.97      8344
          21       0.90      0.60      0.72        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.92      0.94      2155
          26       0.93      0.59      0.72       115
          27       0.90      0.50      0.64        38
          28       0.88      0.89      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.98      0.95      0.96      2601
          33       0.96      0.97      0.96      4030
          34       0.94      0.93      0.94      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.97      0.96      1654
          37       0.98      0.97      0.97      2611
          38       0.95      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.94      0.90      0.92    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9673279291023373
train_acc 0.9673985998538682

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9668020155293569
valid_acc: 0.9669486841545852
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.57      0.67       101
           5       0.95      1.00      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.93      9782
          13       0.88      0.96      0.92       306
          14       0.94      0.93      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.96      0.95      0.95     19633
          19       0.88      0.69      0.77       266
          20       0.98      0.97      0.97      8344
          21       0.86      0.80      0.83        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.90      0.55      0.68       115
          27       0.92      0.63      0.75        38
          28       0.90      0.91      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.92      0.97      0.94      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.91      0.92    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [05:12<00:00,  1.92it/s]
train_weighted_f1 0.9744975081263091
train_acc 0.974545887070738

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.49it/s]
valid_weighted_f1: 0.9678203897853798
valid_acc: 0.9679180306959738
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.67      0.75       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.89      0.95      0.92       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.95      0.94     15211
          18       0.96      0.95      0.95     19633
          19       0.88      0.70      0.78       266
          20       0.97      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.95      0.94      2155
          26       0.91      0.60      0.72       115
          27       0.96      0.66      0.78        38
          28       0.91      0.91      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.95      0.96      2601
          33       0.96      0.97      0.97      4030
          34       0.93      0.96      0.94      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.91it/s]
train_weighted_f1 0.979362066257476
train_acc 0.9793918115240183

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9690147269792759
valid_acc: 0.9691509714723013
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.63      0.72       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.89      0.98      0.93       306
          14       0.92      0.96      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.89      0.72      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.78      0.93      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.90      0.60      0.72       115
          27       1.00      0.55      0.71        38
          28       0.92      0.91      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.92      0.97      0.94      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9828202415830539
train_acc 0.9828390766512038

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.969289213605423
valid_acc: 0.9694230687470771
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.69      0.76       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.95      0.92      0.93      9782
          13       0.90      0.96      0.93       306
          14       0.94      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.88      0.71      0.78       266
          20       0.98      0.98      0.98      8344
          21       0.87      0.87      0.87        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.95      0.95      2155
          26       0.88      0.62      0.72       115
          27       1.00      0.63      0.77        38
          28       0.91      0.94      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.94      0.97      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.91it/s]
train_weighted_f1 0.9856955840169894
train_acc 0.9857086115783928

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9695920446485007
valid_acc: 0.9696866629820161
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.63      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.92      0.97      0.94       306
          14       0.94      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.85      0.77      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.79      1.00      0.88        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.88      0.70      0.78       115
          27       1.00      0.58      0.73        38
          28       0.93      0.90      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.95      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-12 19:20:50,204] Trial 0 finished with value: 0.9696866629820161 and parameters: {'lrmain': 3e-05, 'drop_out': 0.1}. Best is trial 0 with value: 0.9696866629820161.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.8744785030117188
train_acc 0.8751858507077195

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.49it/s]
valid_weighted_f1: 0.9446632026825121
valid_acc: 0.9450533565749756
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.58      0.44      0.50       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.86      0.91      0.88      9782
          13       0.83      0.87      0.85       306
          14       0.88      0.85      0.86       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.91      0.90      0.90     15211
          18       0.92      0.93      0.92     19633
          19       0.89      0.57      0.70       266
          20       0.94      0.94      0.94      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       1.00      0.99      0.99      1397
          24       0.99      1.00      1.00       925
          25       0.94      0.87      0.90      2155
          26       0.86      0.49      0.62       115
          27       1.00      0.03      0.05        38
          28       0.80      0.85      0.83       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.95      0.93      0.94      2601
          33       0.95      0.96      0.95      4030
          34       0.89      0.83      0.86      2051
          35       0.95      0.92      0.93      3387
          36       0.94      0.95      0.95      1654
          37       0.97      0.94      0.96      2611
          38       0.94      0.96      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      0.60      0.75        10
          41       1.00      0.99      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.90      0.84      0.86    117605
weighted avg       0.95      0.95      0.94    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.91it/s]
train_weighted_f1 0.9470715067542558
train_acc 0.9472534451411191

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.48it/s]
valid_weighted_f1: 0.9585614410253116
valid_acc: 0.9587602567918031
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.67      0.52      0.59       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.99      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.93      0.91      9782
          13       0.85      0.93      0.89       306
          14       0.92      0.92      0.92       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.93      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.88      0.66      0.75       266
          20       0.96      0.97      0.96      8344
          21       0.75      0.20      0.32        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      0.99      1397
          24       0.99      1.00      1.00       925
          25       0.95      0.92      0.93      2155
          26       0.90      0.48      0.62       115
          27       0.89      0.45      0.60        38
          28       0.85      0.87      0.86       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.94      0.96      2601
          33       0.94      0.97      0.96      4030
          34       0.92      0.91      0.91      2051
          35       0.96      0.92      0.94      3387
          36       0.95      0.97      0.96      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.96      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.88      0.90    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.92it/s]
train_weighted_f1 0.9612585015048705
train_acc 0.9613557968428744

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.56it/s]
valid_weighted_f1: 0.9642396649238677
valid_acc: 0.9643467539645423
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.64      0.67       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.92      9782
          13       0.86      0.94      0.90       306
          14       0.95      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.89      0.70      0.78       266
          20       0.97      0.97      0.97      8344
          21       0.90      0.60      0.72        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.94      2155
          26       0.91      0.53      0.67       115
          27       0.86      0.79      0.82        38
          28       0.88      0.90      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.95      0.96      2601
          33       0.95      0.98      0.96      4030
          34       0.90      0.95      0.93      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.92      0.93    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [05:12<00:00,  1.92it/s]
train_weighted_f1 0.9694537958377267
train_acc 0.9695151739137823

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.56it/s]
valid_weighted_f1: 0.9667687816082986
valid_acc: 0.9668636537562179
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.65      0.71       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.92      0.93      9782
          13       0.90      0.94      0.92       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.95      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.70      0.77       266
          20       0.97      0.98      0.97      8344
          21       0.86      0.80      0.83        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.94      0.94      2155
          26       0.91      0.62      0.74       115
          27       0.91      0.76      0.83        38
          28       0.91      0.90      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.95      0.94      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.96      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.91it/s]
train_weighted_f1 0.974744977614852
train_acc 0.9747922720089718

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.968234667486779
valid_acc: 0.9683686918073211
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.69      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.89      0.96      0.92       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.88      0.67      0.76       266
          20       0.97      0.98      0.98      8344
          21       0.87      0.87      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.91      0.59      0.72       115
          27       0.93      0.74      0.82        38
          28       0.89      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.95      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.92it/s]
train_weighted_f1 0.9788728416222142
train_acc 0.9789054136718153

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9695043304383234
valid_acc: 0.9695846265039751
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.65      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.89      0.96      0.92       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.94     15211
          18       0.95      0.96      0.96     19633
          19       0.83      0.76      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.94      0.95      2155
          26       0.91      0.60      0.72       115
          27       0.94      0.76      0.84        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.95      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [05:12<00:00,  1.92it/s]
train_weighted_f1 0.9818818751008629
train_acc 0.9819045130923859

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.56it/s]
valid_weighted_f1: 0.970238576054459
valid_acc: 0.9703243909697717
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.65      0.74       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.90      0.97      0.94       306
          14       0.94      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.88      0.73      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.85      0.73      0.79        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.87      0.67      0.75       115
          27       0.93      0.68      0.79        38
          28       0.90      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.96      0.95      2051
          35       0.97      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-12 19:59:38,301] Trial 1 finished with value: 0.9703243909697717 and parameters: {'lrmain': 2e-05, 'drop_out': 0.1}. Best is trial 1 with value: 0.9703243909697717.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:12<00:00,  1.92it/s]
train_weighted_f1 0.9082275416038833
train_acc 0.9084563134016415

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.58it/s]
valid_weighted_f1: 0.9576364578550142
valid_acc: 0.9578249224097615
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.57      0.61      0.59       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.91      0.91      9782
          13       0.84      0.93      0.89       306
          14       0.91      0.92      0.91       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.92      0.93      0.92     15211
          18       0.94      0.94      0.94     19633
          19       0.91      0.61      0.73       266
          20       0.97      0.96      0.96      8344
          21       0.83      0.33      0.48        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.91      0.93      2155
          26       0.87      0.47      0.61       115
          27       1.00      0.34      0.51        38
          28       0.85      0.91      0.88       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.95      0.96      2601
          33       0.95      0.97      0.96      4030
          34       0.93      0.90      0.92      2051
          35       0.96      0.93      0.94      3387
          36       0.95      0.96      0.96      1654
          37       0.98      0.96      0.97      2611
          38       0.93      0.97      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.89      0.90    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:11<00:00,  1.92it/s]
train_weighted_f1 0.9616643652713219
train_acc 0.9617434283189751

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9651997094395027
valid_acc: 0.9653671187449513
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.72      0.70      0.71       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.92      9782
          13       0.86      0.94      0.90       306
          14       0.91      0.93      0.92       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.93      0.94     15211
          18       0.94      0.96      0.95     19633
          19       0.85      0.69      0.76       266
          20       0.97      0.97      0.97      8344
          21       1.00      0.87      0.93        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.92      0.94      2155
          26       0.87      0.50      0.64       115
          27       1.00      0.29      0.45        38
          28       0.92      0.87      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.95      0.96      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.94      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.95      0.98      0.96      1654
          37       0.98      0.97      0.97      2611
          38       0.97      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.91      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:12<00:00,  1.92it/s]
train_weighted_f1 0.9727716565834366
train_acc 0.9728180064909687

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.58it/s]
valid_weighted_f1: 0.9691091496936104
valid_acc: 0.9691594745121381
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.76      0.77       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.95      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.95      0.93      9782
          13       0.88      0.97      0.93       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.84      0.76      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.81      0.87      0.84        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.89      0.58      0.71       115
          27       0.96      0.63      0.76        38
          28       0.91      0.93      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.96      0.97      2601
          33       0.97      0.96      0.96      4030
          34       0.94      0.96      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.95      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [05:11<00:00,  1.93it/s]
train_weighted_f1 0.9792210635483044
train_acc 0.9792516269901956

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.60it/s]
valid_weighted_f1: 0.9696408114069411
valid_acc: 0.9697036690616896
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.73      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.97      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.90      0.96      0.93       306
          14       0.93      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.96      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.82      0.74      0.78       266
          20       0.98      0.98      0.98      8344
          21       0.88      0.93      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.86      0.68      0.76       115
          27       1.00      0.61      0.75        38
          28       0.93      0.92      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.97      0.97      0.97      2601
          33       0.97      0.96      0.97      4030
          34       0.96      0.95      0.95      2051
          35       0.94      0.96      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [05:11<00:00,  1.93it/s]
train_weighted_f1 0.9831224584490291
train_acc 0.9831406857997316

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.61it/s]
valid_weighted_f1: 0.9692249383355591
valid_acc: 0.9693465413885464
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.78      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.96      0.91      0.93      9782
          13       0.88      0.98      0.92       306
          14       0.92      0.96      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.96      0.94     15211
          18       0.96      0.95      0.96     19633
          19       0.88      0.74      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.81      0.87      0.84        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.93      0.95      0.94      2155
          26       0.88      0.58      0.70       115
          27       1.00      0.47      0.64        38
          28       0.91      0.93      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.94      0.95      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [05:10<00:00,  1.93it/s]
train_weighted_f1 0.9863094415739988
train_acc 0.9863213879118452

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.59it/s]
valid_weighted_f1: 0.9695324412886216
valid_acc: 0.9696271417031589
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.69      0.76       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.97      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.95      0.92      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.92      0.97      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.86      0.76      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.83      1.00      0.91        15
          22       1.00      1.00      1.00      2100
          23       0.99      1.00      1.00      1397
          24       1.00      0.99      1.00       925
          25       0.94      0.96      0.95      2155
          26       0.89      0.64      0.75       115
          27       1.00      0.58      0.73        38
          28       0.90      0.93      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.93      0.96      0.94      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.94      0.98      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [05:11<00:00,  1.92it/s]
train_weighted_f1 0.9887185708914423
train_acc 0.9887268270717575

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.61it/s]
valid_weighted_f1: 0.970374503129094
valid_acc: 0.9704519365673229
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.66      0.72       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.97      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.90      0.97      0.93       306
          14       0.92      0.95      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.81      0.77      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.81      0.87      0.84        15
          22       1.00      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.88      0.61      0.72       115
          27       1.00      0.53      0.69        38
          28       0.91      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.98      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.97      0.94      0.96      2051
          35       0.98      0.92      0.95      3387
          36       0.95      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.98      0.96       370
          39       1.00      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-01-12 20:38:14,525] Trial 2 finished with value: 0.9704519365673229 and parameters: {'lrmain': 5e-05, 'drop_out': 0.1}. Best is trial 2 with value: 0.9704519365673229.

Process finished with exit code 0
