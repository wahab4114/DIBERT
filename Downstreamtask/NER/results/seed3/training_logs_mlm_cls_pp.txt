ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 2e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:02<00:00,  1.98it/s]
train_weighted_f1 0.8855888821066182
train_acc 0.8862657388999338

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.50it/s]
valid_weighted_f1: 0.9505162173385341
valid_acc: 0.9509799753411845
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.66      0.43      0.52       101
           5       1.00      0.67      0.80        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.88      1.00      0.94        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.92      0.90      9782
          13       0.83      0.85      0.84       306
          14       0.87      0.84      0.85       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.92      0.91      0.91     15211
          18       0.93      0.93      0.93     19633
          19       0.85      0.55      0.67       266
          20       0.95      0.96      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.96      0.89      0.92      2155
          26       0.90      0.47      0.62       115
          27       0.00      0.00      0.00        38
          28       0.82      0.89      0.85       248
          29       1.00      0.97      0.98        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.94      0.95      2601
          33       0.95      0.97      0.96      4030
          34       0.90      0.90      0.90      2051
          35       0.96      0.91      0.94      3387
          36       0.95      0.96      0.95      1654
          37       0.98      0.95      0.96      2611
          38       0.94      0.96      0.95       370
          39       0.98      1.00      0.99       270
          40       0.00      0.00      0.00        10
          41       0.99      1.00      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.85      0.82      0.83    117605
weighted avg       0.95      0.95      0.95    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9526757217562953
train_acc 0.9528873765951301

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9614000238856759
valid_acc: 0.9616002720972747
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.55      0.63       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.94      1.00      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.94      0.92      9782
          13       0.85      0.93      0.88       306
          14       0.93      0.91      0.92       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.93      0.93     15211
          18       0.94      0.95      0.94     19633
          19       0.88      0.64      0.74       266
          20       0.98      0.97      0.97      8344
          21       1.00      0.07      0.12        15
          22       0.99      1.00      0.99      2100
          23       1.00      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.97      0.90      0.94      2155
          26       0.90      0.49      0.63       115
          27       0.91      0.55      0.69        38
          28       0.85      0.88      0.87       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.98      0.96      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.93      0.94      0.94      2051
          35       0.97      0.92      0.94      3387
          36       0.96      0.97      0.96      1654
          37       0.98      0.97      0.98      2611
          38       0.94      0.97      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.94      0.88      0.90    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:03<00:00,  1.97it/s]
train_weighted_f1 0.9648246494572111
train_acc 0.9649379364836621

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9662623367061843
valid_acc: 0.9664044896050338
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.67      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.87      0.94      0.91       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.94      0.95      0.95     19633
          19       0.87      0.67      0.76       266
          20       0.98      0.97      0.98      8344
          21       0.75      0.40      0.52        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.89      0.56      0.68       115
          27       0.92      0.61      0.73        38
          28       0.87      0.94      0.90       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.98      0.97       370
          39       0.99      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.90      0.92    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [05:10<00:00,  1.93it/s]
train_weighted_f1 0.9714696116287692
train_acc 0.971542539633991

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9685704270012435
valid_acc: 0.9686833042812806
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.69      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.88      0.94      0.91       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.95      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.70      0.77       266
          20       0.98      0.98      0.98      8344
          21       0.69      0.73      0.71        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.91      0.58      0.71       115
          27       0.92      0.58      0.71        38
          28       0.92      0.92      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.98      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.92      0.92    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9761325089150397
train_acc 0.976185621314846

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.52it/s]
valid_weighted_f1: 0.9694194777981145
valid_acc: 0.9695421113047915
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.64      0.71       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.89      0.95      0.92       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.84      0.74      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.82      0.93      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.63      0.73       115
          27       0.86      0.63      0.73        38
          28       0.90      0.93      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.94      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [04:32<00:00,  2.20it/s]
train_weighted_f1 0.9799652276410745
train_acc 0.9800024638493824

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.50it/s]
valid_weighted_f1: 0.9699333707412904
valid_acc: 0.9700692997746695
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.65      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.87      0.97      0.92       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.87      0.73      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.72      0.87      0.79        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.86      0.58      0.69       115
          27       0.90      0.71      0.79        38
          28       0.90      0.93      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.98      0.97      2601
          33       0.94      0.99      0.96      4030
          34       0.94      0.97      0.95      2051
          35       0.97      0.92      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [04:41<00:00,  2.13it/s]
train_weighted_f1 0.9826538476358028
train_acc 0.9826840240607636

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9706361542549308
valid_acc: 0.9707325368819353
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.65      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.95      0.92      0.94      9782
          13       0.89      0.98      0.93       306
          14       0.94      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.83      0.79      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.88      0.93      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.88      0.63      0.74       115
          27       0.93      0.66      0.77        38
          28       0.90      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.99      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [04:43<00:00,  2.11it/s]
train_weighted_f1 0.9847669253888802
train_acc 0.984784668060016

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9703199470658285
valid_acc: 0.9703754092087922
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.69      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.86      0.75      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.88      0.93      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.85      0.67      0.75       115
          27       0.89      0.82      0.85        38
          28       0.88      0.94      0.91       248
          29       1.00      0.98      0.99        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.96      0.95      2051
          35       0.97      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [04:58<00:00,  2.01it/s]
train_weighted_f1 0.9867265193217107
train_acc 0.9867419415133133

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.52it/s]
valid_weighted_f1: 0.9705930261317699
valid_acc: 0.9706560095234046
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.69      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.84      0.77      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.82      0.93      0.87        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.97      0.94      0.96      2155
          26       0.83      0.70      0.76       115
          27       0.88      0.76      0.82        38
          28       0.89      0.95      0.92       248
          29       1.00      0.98      0.99        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.99      0.97      4030
          34       0.97      0.95      0.96      2051
          35       0.98      0.92      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9880220782081115
train_acc 0.9880333384309528

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9716741280911178
valid_acc: 0.9717358955826708
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.68      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.84      0.78      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.82      0.93      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.87      0.69      0.77       115
          27       0.97      0.74      0.84        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [05:05<00:00,  1.96it/s]
train_weighted_f1 0.989376430271383
train_acc 0.9893831455710184

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9720111040039175
valid_acc: 0.9720845202159772
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.70      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.95      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.87      0.72      0.79       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.93      0.97        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.88      0.68      0.76       115
          27       0.90      0.74      0.81        38
          28       0.90      0.93      0.91       248
          29       1.00      0.98      0.99        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.93      0.97      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9909842728503385
train_acc 0.9909899576897588

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.52it/s]
valid_weighted_f1: 0.9718021756601123
valid_acc: 0.971829429020875
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.65      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.80      0.79      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.84      0.73      0.78       115
          27       0.91      0.82      0.86        38
          28       0.90      0.95      0.93       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
