ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 5e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:02<00:00,  1.98it/s]
train_weighted_f1 0.9094286747971853
train_acc 0.9095682316358261

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.47it/s]
valid_weighted_f1: 0.9578641886193164
valid_acc: 0.9580204923260065
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.60      0.55      0.57       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.91      0.91      9782
          13       0.84      0.94      0.89       306
          14       0.94      0.90      0.92       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.92      0.94      0.93     15211
          18       0.94      0.94      0.94     19633
          19       0.88      0.62      0.73       266
          20       0.97      0.96      0.96      8344
          21       0.82      0.60      0.69        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.90      0.93      2155
          26       0.91      0.44      0.60       115
          27       0.92      0.61      0.73        38
          28       0.84      0.91      0.87       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.95      0.96      0.95      2601
          33       0.95      0.96      0.96      4030
          34       0.93      0.91      0.92      2051
          35       0.96      0.92      0.94      3387
          36       0.94      0.97      0.96      1654
          37       0.98      0.96      0.97      2611
          38       0.92      0.98      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.90      0.91    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:10<00:00,  1.93it/s]
train_weighted_f1 0.9616185357499716
train_acc 0.9616924521248577

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9641149018283333
valid_acc: 0.9642447174865014
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.65      0.72      0.69       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.92      9782
          13       0.87      0.96      0.91       306
          14       0.91      0.94      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.92      0.94     15211
          18       0.93      0.96      0.95     19633
          19       0.84      0.69      0.76       266
          20       0.97      0.97      0.97      8344
          21       0.80      0.80      0.80        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.92      0.94      2155
          26       0.90      0.53      0.67       115
          27       0.95      0.47      0.63        38
          28       0.91      0.90      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.95      0.96      2601
          33       0.97      0.96      0.96      4030
          34       0.96      0.93      0.94      2051
          35       0.96      0.95      0.95      3387
          36       0.95      0.98      0.96      1654
          37       0.98      0.97      0.97      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.96    117605
   macro avg       0.96      0.92      0.93    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [04:59<00:00,  2.00it/s]
train_weighted_f1 0.9727710097903605
train_acc 0.9728169444869246

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.50it/s]
valid_weighted_f1: 0.9682114014105749
valid_acc: 0.9683006674886272
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.65      0.71       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.91      0.96      0.93       306
          14       0.94      0.93      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.82      0.73      0.77       266
          20       0.98      0.97      0.97      8344
          21       0.80      0.80      0.80        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.93      0.95      2155
          26       0.84      0.70      0.76       115
          27       0.88      0.61      0.72        38
          28       0.91      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.96      0.96      4030
          34       0.94      0.96      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [04:46<00:00,  2.10it/s]
train_weighted_f1 0.9791269332573393
train_acc 0.9791581706343138

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9694653271490666
valid_acc: 0.9695166021852812
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.75      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.95      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.91      0.96      0.93       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.82      0.77      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.80      0.80      0.80        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.89      0.67      0.76       115
          27       0.88      0.74      0.80        38
          28       0.90      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.96      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.97      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.97      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9833615776798568
train_acc 0.9833806987137007

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9695197479988786
valid_acc: 0.9696016325836486
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.72      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.87      0.98      0.92       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.96      0.94     15211
          18       0.96      0.95      0.95     19633
          19       0.88      0.75      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.78      0.93      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.95      2155
          26       0.87      0.59      0.70       115
          27       0.93      0.66      0.77        38
          28       0.92      0.91      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.96      0.94      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9861787151859961
train_acc 0.9861886374063312

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9703723847765038
valid_acc: 0.9704519365673229
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.77      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.92      0.98      0.95       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.74      0.78       266
          20       0.97      0.98      0.98      8344
          21       0.70      0.93      0.80        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.93      0.96      0.95      2155
          26       0.92      0.70      0.80       115
          27       0.96      0.66      0.78        38
          28       0.94      0.89      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.98      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.95      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [04:34<00:00,  2.18it/s]
train_weighted_f1 0.9889673293239676
train_acc 0.9889742740140355

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9687183820123715
valid_acc: 0.9687768377194848
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.62      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.92      0.97      0.94       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.93      0.95      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.79      0.78      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.78      0.93      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.87      0.71      0.78       115
          27       1.00      0.68      0.81        38
          28       0.91      0.91      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.97      0.93      0.95      2051
          35       0.98      0.92      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9906980331714661
train_acc 0.9907010925897606

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.52it/s]
valid_weighted_f1: 0.9706649339265299
valid_acc: 0.9707580460014456
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.76      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.94      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.93      0.96      0.94       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.91      0.70      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.81      0.87      0.84        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.91      0.74      0.82       115
          27       1.00      0.63      0.77        38
          28       0.93      0.91      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.98      0.96      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9920849020490924
train_acc 0.9920880698713701

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9698362974079512
valid_acc: 0.9698822328982611
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.76      0.79       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.89      0.76      0.82       266
          20       0.97      0.98      0.98      8344
          21       0.87      0.87      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.92      0.72      0.81       115
          27       0.97      0.76      0.85        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.98      0.96      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.91      0.97      0.94       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9931261855050479
train_acc 0.9931277718305551

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9702842898569944
valid_acc: 0.9703499000892819
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.73      0.75       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.97      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.92      0.95      0.93      9782
          13       0.91      0.97      0.94       306
          14       0.93      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.90      0.71      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.86      0.80      0.83        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.87      0.72      0.79       115
          27       0.96      0.61      0.74        38
          28       0.91      0.92      0.92       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.96      0.97      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.96      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.95      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [05:02<00:00,  1.98it/s]
train_weighted_f1 0.9942234922768882
train_acc 0.9942237600040781

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9688585658558508
valid_acc: 0.968929892436546
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.90      0.65      0.76       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.91      0.95      0.93      9782
          13       0.92      0.98      0.95       306
          14       0.94      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.97      0.94      0.95     19633
          19       0.88      0.71      0.79       266
          20       0.97      0.99      0.98      8344
          21       0.87      0.87      0.87        15
          22       1.00      1.00      1.00      2100
          23       0.99      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.84      0.76      0.80       115
          27       0.90      0.68      0.78        38
          28       0.91      0.93      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.97      0.97      2601
          33       0.93      0.99      0.96      4030
          34       0.96      0.96      0.96      2051
          35       0.98      0.91      0.94      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [05:05<00:00,  1.96it/s]
train_weighted_f1 0.9951696252817858
train_acc 0.9951700056073813

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9703433993703742
valid_acc: 0.9703669061689554
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.89      0.70      0.78       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       1.00      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.93      0.93      0.93       306
          14       0.94      0.95      0.94       331
          15       1.00      0.98      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.84      0.75      0.80       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.85      0.81      0.83       115
          27       0.88      0.79      0.83        38
          28       0.88      0.94      0.91       248
          29       1.00      0.98      0.99        66
          30       1.00      0.99      0.99      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.96      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.93      0.97      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
