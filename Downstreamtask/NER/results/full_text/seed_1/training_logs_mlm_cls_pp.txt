ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 5e-05, 'drop_out': 0.0}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.32it/s]
train_weighted_f1 0.9101089956812277
train_acc 0.9101056056821465

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.46it/s]
valid_weighted_f1: 0.9678917580713469
valid_acc: 0.9679945580545045
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.66      0.69       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.94      0.93      9782
          13       0.89      0.94      0.91       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.95      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.85      0.68      0.75       266
          20       0.97      0.98      0.98      8344
          21       0.70      0.47      0.56        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.90      0.63      0.74       115
          27       0.92      0.58      0.71        38
          28       0.89      0.96      0.92       248
          29       0.97      1.00      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.98       405

    accuracy                           0.97    117605
   macro avg       0.93      0.91      0.92    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.16it/s]
train_weighted_f1 0.9673613801419331
train_acc 0.9674378940035003

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.9731160746742937
valid_acc: 0.9731729093150802
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.79      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.95      0.93      0.94      9782
          13       0.92      0.95      0.94       306
          14       0.93      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.81      0.78      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.78      0.93      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.97      0.96      2155
          26       0.85      0.76      0.80       115
          27       0.92      0.63      0.75        38
          28       0.90      0.97      0.93       248
          29       0.97      1.00      0.99        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.99      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.95      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.16it/s]
train_weighted_f1 0.9744805752100656
train_acc 0.9745235849858116

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.45it/s]
valid_weighted_f1: 0.9751504159589177
valid_acc: 0.9752136388758982
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.88      0.74      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.94      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.93      0.97      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.81      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.78      0.93      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.86      0.71      0.78       115
          27       0.96      0.61      0.74        38
          28       0.91      0.97      0.94       248
          29       0.99      1.00      0.99        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.97      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.16it/s]
train_weighted_f1 0.9792151576735844
train_acc 0.9792410069497545

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.9756533138326979
valid_acc: 0.9757238212661027
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.77      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       0.99      1.00      1.00     12278
          12       0.95      0.94      0.95      9782
          13       0.92      0.96      0.94       306
          14       0.93      0.97      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.96      0.97      0.96     19633
          19       0.85      0.82      0.83       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.97      0.96      2155
          26       0.86      0.76      0.81       115
          27       0.96      0.63      0.76        38
          28       0.92      0.97      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.98      0.98      2601
          33       0.95      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.97      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.16it/s]
train_weighted_f1 0.9827711357293765
train_acc 0.9827902244651747

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.44it/s]
valid_weighted_f1: 0.9766326321237776
valid_acc: 0.9766591556481442
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.82      0.82       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.91      0.97      0.94       306
          14       0.93      0.98      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.80      0.86      0.83       266
          20       0.98      0.99      0.99      8344
          21       0.87      0.87      0.87        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.97      0.96      2155
          26       0.88      0.72      0.79       115
          27       0.96      0.63      0.76        38
          28       0.90      0.98      0.94       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.97      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.99      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9854983735749245
train_acc 0.9855121408302323

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.45it/s]
valid_weighted_f1: 0.9773778216257349
valid_acc: 0.977390417074104
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.79      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.92      0.97      0.94       306
          14       0.94      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.80      0.85      0.82       266
          20       0.98      0.99      0.99      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.84      0.75      0.79       115
          27       0.96      0.63      0.76        38
          28       0.92      0.97      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.99      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.9881831754513692
train_acc 0.9881905150294812

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.44it/s]
valid_weighted_f1: 0.9773080614258094
valid_acc: 0.9773053866757365
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.79      0.83       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.94      0.96      0.95      9782
          13       0.91      0.98      0.94       306
          14       0.96      0.97      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.79      0.85      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.88      0.74      0.80       115
          27       0.94      0.84      0.89        38
          28       0.91      0.98      0.94       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.99      0.98      2601
          33       0.97      0.98      0.98      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.9902961183244203
train_acc 0.9903007170651306

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.46it/s]
valid_weighted_f1: 0.9774403152374586
valid_acc: 0.9774499383529612
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.82      0.84       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.92      0.97      0.94       306
          14       0.95      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.79      0.85      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.97      0.97      2155
          26       0.89      0.77      0.82       115
          27       0.97      0.74      0.84        38
          28       0.93      0.97      0.95       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.97      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.99      0.99      2611
          38       0.98      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [02:58<00:00,  3.35it/s]
train_weighted_f1 0.9916920750241301
train_acc 0.9916951283750488

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.41it/s]
valid_weighted_f1: 0.9776437711828019
valid_acc: 0.9776625143488797
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.90      0.79      0.84       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.91      0.97      0.94       306
          14       0.94      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.81      0.86      0.83       266
          20       0.98      0.99      0.99      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.97      0.97      2155
          26       0.90      0.76      0.82       115
          27       0.96      0.66      0.78        38
          28       0.89      0.98      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.97      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.99      0.99      2611
          38       0.98      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.16it/s]
train_weighted_f1 0.9928132515575526
train_acc 0.9928155426415863

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.39it/s]
valid_weighted_f1: 0.9773280939577386
valid_acc: 0.9773223927554101
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.84      0.84       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.92      0.97      0.94       306
          14       0.95      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.79      0.86      0.82       266
          20       0.98      0.99      0.99      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.97      0.97      2155
          26       0.88      0.77      0.82       115
          27       0.97      0.76      0.85        38
          28       0.92      0.97      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.98      0.96      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.16it/s]
train_weighted_f1 0.9939233412192013
train_acc 0.9939253368676828

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.9774777149580559
valid_acc: 0.9774669444326347
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.89      0.84      0.86       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.93      0.97      0.95       306
          14       0.96      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.79      0.86      0.82       266
          20       0.98      0.99      0.99      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.85      0.79      0.82       115
          27       0.97      0.84      0.90        38
          28       0.91      0.97      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.98      0.97      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.97      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.98      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.16it/s]
train_weighted_f1 0.9948626796437267
train_acc 0.9948630864386332

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.41it/s]
valid_weighted_f1: 0.9773146410624876
valid_acc: 0.9773308957952468
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.71      0.78       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.91      0.97      0.94       306
          14       0.96      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.81      0.85      0.83       266
          20       0.98      0.99      0.99      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.87      0.76      0.81       115
          27       0.97      0.84      0.90        38
          28       0.92      0.96      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.98      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.97      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 12
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.16it/s]
train_weighted_f1 0.9952509863857312
train_acc 0.9952517799187779

Valid_Epoch: 12
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.44it/s]
valid_weighted_f1: 0.97728585417339
valid_acc: 0.9773138897155733
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.79      0.82       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.93      0.96      0.95       306
          14       0.97      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.86      0.81      0.83       266
          20       0.98      0.99      0.99      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.97      2155
          26       0.87      0.79      0.83       115
          27       0.95      0.92      0.93        38
          28       0.93      0.93      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.98      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.98      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 13
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.9958927315167087
train_acc 0.9958932303614212

Valid_Epoch: 13
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.9777355062428332
valid_acc: 0.9777560477870839
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.90      0.81      0.85       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.93      0.98      0.95       306
          14       0.97      0.97      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.84      0.83      0.83       266
          20       0.98      0.99      0.99      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.97      0.97      2155
          26       0.90      0.79      0.84       115
          27       0.94      0.89      0.92        38
          28       0.93      0.95      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.99      0.99      2611
          38       0.98      0.98      0.98       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 14
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.16it/s]
train_weighted_f1 0.9962732874211422
train_acc 0.9962734278092131

Valid_Epoch: 14
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.44it/s]
valid_weighted_f1: 0.9775697375021978
valid_acc: 0.977585986990349
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.90      0.77      0.83       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       1.00      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.92      0.97      0.94       306
          14       0.96      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.81      0.83      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.88      0.77      0.82       115
          27       0.97      0.84      0.90        38
          28       0.91      0.97      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.97      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Process finished with exit code 0
