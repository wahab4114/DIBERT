ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 5e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [03:07<00:00,  3.20it/s]
train_weighted_f1 0.9021891105184145
train_acc 0.9020216308983705

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.41it/s]
valid_weighted_f1: 0.9655873788646212
valid_acc: 0.965707240338421
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.66      0.72      0.69       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.93      0.92      9782
          13       0.88      0.92      0.90       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.84      0.66      0.74       266
          20       0.97      0.99      0.98      8344
          21       0.33      0.13      0.19        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.94      2155
          26       0.85      0.62      0.71       115
          27       0.96      0.71      0.82        38
          28       0.86      0.95      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.93      0.96      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.92      0.90      0.91    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [03:11<00:00,  3.13it/s]
train_weighted_f1 0.9634847599278046
train_acc 0.9635520212060967

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.36it/s]
valid_weighted_f1: 0.9718446353920459
valid_acc: 0.9719314654989158
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.78      0.76       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.90      0.94      0.92       306
          14       0.94      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.74      0.78       266
          20       0.98      0.99      0.98      8344
          21       0.79      0.73      0.76        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.90      0.68      0.77       115
          27       1.00      0.61      0.75        38
          28       0.87      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [03:11<00:00,  3.13it/s]
train_weighted_f1 0.9717678632244372
train_acc 0.9718133506652393

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.39it/s]
valid_weighted_f1: 0.9740561361249839
valid_acc: 0.9741422558564687
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.83      0.82       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.92      0.98      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.86      0.77      0.81       266
          20       0.98      0.99      0.98      8344
          21       0.79      0.73      0.76        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.88      0.73      0.80       115
          27       1.00      0.39      0.57        38
          28       0.86      0.97      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.95      0.98      0.96      2051
          35       0.95      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [03:11<00:00,  3.14it/s]
train_weighted_f1 0.9770666657542347
train_acc 0.9770978827887377

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.35it/s]
valid_weighted_f1: 0.975716689204849
valid_acc: 0.9757578334254496
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.82      0.81       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.92      0.97      0.94       306
          14       0.95      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.97      0.96      0.96     19633
          19       0.85      0.80      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.88      0.75      0.81       115
          27       1.00      0.71      0.83        38
          28       0.89      0.98      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.95      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.98      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [03:11<00:00,  3.13it/s]
train_weighted_f1 0.9807250251826107
train_acc 0.9807458666802603

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.39it/s]
valid_weighted_f1: 0.9762998048438757
valid_acc: 0.976336040134348
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.79      0.81       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.91      0.97      0.94       306
          14       0.96      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.97      0.96      0.96     19633
          19       0.83      0.81      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.91      0.67      0.77        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.89      0.73      0.80       115
          27       0.97      0.84      0.90        38
          28       0.89      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9838769266760449
train_acc 0.9838947086710507

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.9762845854269819
valid_acc: 0.9763105310148378
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.81      0.82       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.91      0.97      0.94       306
          14       0.94      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.83      0.82      0.82       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.87      0.72      0.79       115
          27       1.00      0.68      0.81        38
          28       0.87      0.98      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.14it/s]
train_weighted_f1 0.9864095952353642
train_acc 0.9864201542879475

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.39it/s]
valid_weighted_f1: 0.9765462090829166
valid_acc: 0.9765571191701033
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.83      0.82       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.92      0.97      0.94       306
          14       0.95      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.96     19633
          19       0.77      0.82      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.87      0.75      0.80       115
          27       0.93      0.74      0.82        38
          28       0.89      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.95      0.95      0.95    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.14it/s]
train_weighted_f1 0.9883517576517034
train_acc 0.9883572496644067

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.38it/s]
valid_weighted_f1: 0.9767974831466748
valid_acc: 0.9768122103652056
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.82      0.83       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       1.00      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.93      0.97      0.95       306
          14       0.95      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.97      0.97     19633
          19       0.79      0.80      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.87      0.77      0.81       115
          27       0.97      0.74      0.84        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9901289927953234
train_acc 0.9901339824302051

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.38it/s]
valid_weighted_f1: 0.9764822236968146
valid_acc: 0.9764890948514093
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.81      0.82       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       1.00      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.94      0.96      0.95       306
          14       0.94      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.79      0.80      0.79       266
          20       0.99      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.83      0.83      0.83       115
          27       1.00      0.61      0.75        38
          28       0.91      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9913829095190594
train_acc 0.9913850231941683

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.32it/s]
valid_weighted_f1: 0.9771872402259606
valid_acc: 0.977194847157859
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.83      0.84       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.93      0.97      0.95       306
          14       0.96      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.79      0.82      0.81       266
          20       0.98      0.99      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.88      0.79      0.83       115
          27       0.97      0.79      0.87        38
          28       0.90      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.97      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.95      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9926419893175311
train_acc 0.9926434979864404

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.38it/s]
valid_weighted_f1: 0.9769141418996942
valid_acc: 0.9769312529229199
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.81      0.80       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       1.00      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.96      0.95      9782
          13       0.92      0.97      0.94       306
          14       0.95      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.97      0.97      0.97     19633
          19       0.80      0.79      0.79       266
          20       0.99      0.99      0.99      8344
          21       0.91      0.67      0.77        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.90      0.77      0.83       115
          27       1.00      0.68      0.81        38
          28       0.92      0.96      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [03:11<00:00,  3.14it/s]
train_weighted_f1 0.9934787078940301
train_acc 0.9934803571732002

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.38it/s]
valid_weighted_f1: 0.9770046291325404
valid_acc: 0.9770247863611241
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.82      0.83       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       1.00      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.93      0.97      0.95       306
          14       0.96      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.97      0.97     19633
          19       0.81      0.82      0.81       266
          20       0.98      0.99      0.98      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.84      0.77      0.81       115
          27       1.00      0.74      0.85        38
          28       0.90      0.98      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.97      0.97      4030
          34       0.98      0.96      0.97      2051
          35       0.95      0.96      0.96      3387
          36       0.97      0.99      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 12
100%|█████████████████████████████████████████| 600/600 [03:11<00:00,  3.14it/s]
train_weighted_f1 0.994264056758193
train_acc 0.9942651781617985

Valid_Epoch: 12
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.39it/s]
valid_weighted_f1: 0.9769990855315519
valid_acc: 0.9770332894009608
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.84      0.83       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       1.00      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.92      0.96      0.94       306
          14       0.95      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.82      0.78      0.80       266
          20       0.98      0.99      0.99      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.86      0.77      0.81       115
          27       0.96      0.68      0.80        38
          28       0.94      0.92      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 13
100%|█████████████████████████████████████████| 600/600 [03:11<00:00,  3.14it/s]
train_weighted_f1 0.9948155667546881
train_acc 0.9948163582606923

Valid_Epoch: 13
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.38it/s]
valid_weighted_f1: 0.977090641876614
valid_acc: 0.9771353258790018
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.77      0.81       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.95      0.95      0.95      9782
          13       0.93      0.97      0.95       306
          14       0.95      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.85      0.79      0.82       266
          20       0.98      0.99      0.99      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.88      0.77      0.82       115
          27       0.97      0.74      0.84        38
          28       0.93      0.94      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 14
100%|█████████████████████████████████████████| 600/600 [03:11<00:00,  3.14it/s]
train_weighted_f1 0.9954200235831959
train_acc 0.9954206385617916

Valid_Epoch: 14
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.36it/s]
valid_weighted_f1: 0.9771039444825379
valid_acc: 0.9771183197993283
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.75      0.81       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.91      0.97      0.94       306
          14       0.96      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.78      0.82      0.80       266
          20       0.98      0.99      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.86      0.77      0.81       115
          27       0.97      0.76      0.85        38
          28       0.92      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.97      0.97      4030
          34       0.98      0.96      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Process finished with exit code 0
