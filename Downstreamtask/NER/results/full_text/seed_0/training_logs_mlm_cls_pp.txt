ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 5e-05, 'drop_out': 0.0}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [03:01<00:00,  3.30it/s]
train_weighted_f1 0.9104671584703816
train_acc 0.9104974851744235

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.46it/s]
valid_weighted_f1: 0.9675503877348846
valid_acc: 0.9676884486203818
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.75      0.64      0.69       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.92      9782
          13       0.88      0.94      0.91       306
          14       0.93      0.93      0.93       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.94      0.95      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.83      0.67      0.74       266
          20       0.97      0.98      0.98      8344
          21       0.71      0.33      0.45        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.91      0.63      0.74       115
          27       1.00      0.53      0.69        38
          28       0.88      0.95      0.91       248
          29       0.99      1.00      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.98      0.98      0.98      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.98       405

    accuracy                           0.97    117605
   macro avg       0.93      0.90      0.91    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.16it/s]
train_weighted_f1 0.9673816876046379
train_acc 0.9674485140439415

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.46it/s]
valid_weighted_f1: 0.9723848359319133
valid_acc: 0.9725011691679776
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.64      0.73       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.93      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.74      0.78       266
          20       0.98      0.99      0.98      8344
          21       0.79      1.00      0.88        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.91      0.64      0.76       115
          27       1.00      0.58      0.73        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.95      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.16it/s]
train_weighted_f1 0.9745370946921593
train_acc 0.9745788091961054

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.45it/s]
valid_weighted_f1: 0.9746994067982385
valid_acc: 0.9747714808043876
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.74      0.79       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.95      0.93      0.94      9782
          13       0.91      0.95      0.93       306
          14       0.94      0.97      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.97      0.96     19633
          19       0.81      0.78      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.79      1.00      0.88        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.97      0.96      2155
          26       0.86      0.70      0.78       115
          27       0.96      0.68      0.80        38
          28       0.89      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.99      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.95      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.9793532712527123
train_acc 0.9793780054714448

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.9753040566293101
valid_acc: 0.9753751966327963
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.76      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.94      0.94      9782
          13       0.89      0.97      0.93       306
          14       0.94      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.96      0.97      0.96     19633
          19       0.81      0.77      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.78      0.93      0.85        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.97      0.97      2155
          26       0.88      0.69      0.77       115
          27       0.96      0.71      0.82        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.96      0.95      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.9828698403896172
train_acc 0.982887928837233

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.48it/s]
valid_weighted_f1: 0.9765157779622602
valid_acc: 0.9765741252497768
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.77      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.91      0.96      0.93       306
          14       0.92      0.99      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.97      0.95      0.96     15211
          18       0.96      0.97      0.97     19633
          19       0.81      0.79      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.82      0.93      0.87        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.97      0.97      2155
          26       0.86      0.72      0.78       115
          27       1.00      0.50      0.67        38
          28       0.91      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.16it/s]
train_weighted_f1 0.9857162802828237
train_acc 0.9857277276511869

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.44it/s]
valid_weighted_f1: 0.9771923820843523
valid_acc: 0.9772033501976957
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.81      0.82       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.96      0.95      9782
          13       0.91      0.96      0.93       306
          14       0.95      0.98      0.97       331
          15       0.99      1.00      0.99        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.80      0.83      0.81       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.97      2155
          26       0.86      0.75      0.80       115
          27       0.96      0.71      0.82        38
          28       0.88      0.99      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.99      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.97      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.16it/s]
train_weighted_f1 0.9883092726082051
train_acc 0.9883158315066863

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.45it/s]
valid_weighted_f1: 0.9767247383967009
valid_acc: 0.9767356830066749
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.79      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.90      0.96      0.93       306
          14       0.95      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.96      0.96     15211
          18       0.98      0.96      0.97     19633
          19       0.79      0.84      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.97      0.97      2155
          26       0.85      0.70      0.77       115
          27       0.97      0.74      0.84        38
          28       0.90      0.97      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.9901017617132788
train_acc 0.9901074323291023

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.45it/s]
valid_weighted_f1: 0.9771144421563674
valid_acc: 0.977126822839165
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.82      0.83       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.91      0.97      0.94       306
          14       0.95      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.77      0.83      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.97      0.97      2155
          26       0.90      0.69      0.78       115
          27       1.00      0.66      0.79        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.98      0.97      2051
          35       0.97      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.9916249799498429
train_acc 0.9916282221202698

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.45it/s]
valid_weighted_f1: 0.977234896334589
valid_acc: 0.9772203562773691
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.84      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.91      0.97      0.94       306
          14       0.96      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.75      0.85      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.97      2155
          26       0.87      0.73      0.79       115
          27       0.94      0.76      0.84        38
          28       0.93      0.95      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.98      0.97      2051
          35       0.97      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.99      0.99      2611
          38       0.98      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.9929659105078027
train_acc 0.9929684712239384

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.40it/s]
valid_weighted_f1: 0.977614575220956
valid_acc: 0.9776285021895328
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.82      0.83       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       1.00      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.90      0.98      0.94       306
          14       0.96      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.79      0.83      0.81       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.87      0.69      0.77       115
          27       0.94      0.84      0.89        38
          28       0.90      0.98      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.97      0.98      0.97      2051
          35       0.97      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.99      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.9939413575438354
train_acc 0.9939423289323885

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.46it/s]
valid_weighted_f1: 0.9775988182199341
valid_acc: 0.9775944900301858
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.80      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.96      0.95      9782
          13       0.92      0.96      0.94       306
          14       0.96      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.78      0.84      0.81       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.88      0.73      0.80       115
          27       0.94      0.79      0.86        38
          28       0.91      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.98      4030
          34       0.98      0.97      0.97      2051
          35       0.97      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.99      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.994854733699601
train_acc 0.9948556524103244

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.44it/s]
valid_weighted_f1: 0.9772637775336404
valid_acc: 0.9772798775562264
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.78      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.96      0.95      9782
          13       0.93      0.97      0.95       306
          14       0.95      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.80      0.80      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.88      0.77      0.82       115
          27       0.96      0.71      0.82        38
          28       0.93      0.95      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.98      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 12
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.995362862221894
train_acc 0.9953632903434096

Valid_Epoch: 12
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.47it/s]
valid_weighted_f1: 0.9772904272954086
valid_acc: 0.9773053866757365
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.80      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.94      0.95      9782
          13       0.94      0.97      0.95       306
          14       0.96      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.97      0.97     19633
          19       0.79      0.81      0.80       266
          20       0.98      0.99      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.97      2155
          26       0.85      0.81      0.83       115
          27       0.94      0.79      0.86        38
          28       0.92      0.97      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.98      0.98      0.98      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.97      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 13
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.9958613165429975
train_acc 0.9958613702400979

Valid_Epoch: 13
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.48it/s]
valid_weighted_f1: 0.9772699521634658
valid_acc: 0.9772798775562264
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.81      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.91      0.98      0.94       306
          14       0.95      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.78      0.85      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.97      0.97      2155
          26       0.90      0.70      0.79       115
          27       0.94      0.79      0.86        38
          28       0.94      0.95      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.97      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 14
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.9963507220480807
train_acc 0.9963509541044332

Valid_Epoch: 14
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.43it/s]
valid_weighted_f1: 0.9774101384648658
valid_acc: 0.977390417074104
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.83      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.94      0.96      0.95      9782
          13       0.93      0.97      0.95       306
          14       0.96      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.98      0.96      0.97     19633
          19       0.78      0.85      0.81       266
          20       0.98      0.99      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.83      0.79      0.81       115
          27       0.94      0.82      0.87        38
          28       0.92      0.96      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.99      0.98      2601
          33       0.98      0.97      0.97      4030
          34       0.98      0.97      0.97      2051
          35       0.96      0.97      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.98      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.97      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Process finished with exit code 0
