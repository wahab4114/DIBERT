ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 5e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.32it/s]
train_weighted_f1 0.9030093840370201
train_acc 0.9026864454299842

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.44it/s]
valid_weighted_f1: 0.9662655776224763
valid_acc: 0.9664044896050338
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.69      0.74       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.94      1.00      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.93      0.92      9782
          13       0.87      0.95      0.91       306
          14       0.94      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.94      0.94      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.86      0.68      0.76       266
          20       0.97      0.98      0.98      8344
          21       0.67      0.27      0.38        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.89      0.57      0.69       115
          27       0.93      0.68      0.79        38
          28       0.86      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.95      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.94      0.98      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.91      0.91    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.14it/s]
train_weighted_f1 0.9639576260290297
train_acc 0.9640299230259469

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.41it/s]
valid_weighted_f1: 0.972111276312007
valid_acc: 0.9721865566940181
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.78      0.79       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.90      0.95      0.92       306
          14       0.96      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      0.99       678
          17       0.96      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.84      0.75      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.77      0.67      0.71        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.91      0.67      0.77       115
          27       0.94      0.84      0.89        38
          28       0.87      0.98      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.14it/s]
train_weighted_f1 0.9719136545050194
train_acc 0.9719641552395032

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.41it/s]
valid_weighted_f1: 0.9743383413154271
valid_acc: 0.9743888440117342
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.78      0.81       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.89      0.96      0.92       306
          14       0.93      0.98      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.97      0.96      0.96     19633
          19       0.84      0.80      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.85      0.73      0.79        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.93      0.65      0.77       115
          27       1.00      0.61      0.75        38
          28       0.87      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.97      0.94      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9769457901246379
train_acc 0.9769789383357972

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.36it/s]
valid_weighted_f1: 0.9750965189452999
valid_acc: 0.9751371115173675
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.82      0.83       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       0.99      1.00      1.00     12278
          12       0.94      0.95      0.94      9782
          13       0.89      0.96      0.93       306
          14       0.92      0.99      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.96      0.96      0.96     19633
          19       0.80      0.81      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.93      0.69      0.79       115
          27       1.00      0.66      0.79        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.98    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.16it/s]
train_weighted_f1 0.9806831406445409
train_acc 0.9807076345346724

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.39it/s]
valid_weighted_f1: 0.9759810824831635
valid_acc: 0.9760044215807151
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.83      0.81       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.91      0.96      0.93       306
          14       0.95      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.97      0.96      0.96     19633
          19       0.82      0.82      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.85      0.73      0.79        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.89      0.74      0.81       115
          27       1.00      0.76      0.87        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.95      0.94      0.95    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9838525157742153
train_acc 0.9838702825780361

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.41it/s]
valid_weighted_f1: 0.9764009596225713
valid_acc: 0.9764380766123889
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.83      0.82       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.89      0.98      0.93       306
          14       0.93      0.99      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.83      0.79      0.81       266
          20       0.98      0.99      0.99      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.92      0.67      0.77       115
          27       1.00      0.74      0.85        38
          28       0.88      0.98      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.9862372099865309
train_acc 0.9862481096328015

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.40it/s]
valid_weighted_f1: 0.9762665935439746
valid_acc: 0.9762850218953276
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.84      0.83       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.95      0.95      9782
          13       0.87      0.98      0.92       306
          14       0.94      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.79      0.82      0.81       266
          20       0.99      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.88      0.63      0.74       115
          27       1.00      0.76      0.87        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9883993024825783
train_acc 0.9884082258585241

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.40it/s]
valid_weighted_f1: 0.9766903696041008
valid_acc: 0.9767101738871646
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.83      0.83       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.92      0.96      0.94       306
          14       0.94      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.82      0.80      0.81       266
          20       0.99      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.74      0.81       115
          27       1.00      0.71      0.83        38
          28       0.90      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.50      0.67      0.57         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9900298279524329
train_acc 0.9900352160541027

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.40it/s]
valid_weighted_f1: 0.9765438912633567
valid_acc: 0.9765571191701033
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.82      0.84       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.91      0.97      0.94       306
          14       0.94      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.79      0.81      0.80       266
          20       0.99      0.99      0.99      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.88      0.76      0.81       115
          27       1.00      0.68      0.81        38
          28       0.91      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.96      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9914742730876628
train_acc 0.9914784795500501

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.35it/s]
valid_weighted_f1: 0.9770081416047756
valid_acc: 0.9769992772416138
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.86      0.84       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.91      0.97      0.94       306
          14       0.95      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.79      0.84      0.81       266
          20       0.98      0.99      0.99      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.90      0.76      0.82       115
          27       0.94      0.79      0.86        38
          28       0.92      0.96      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.60      1.00      0.75         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.97      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.14it/s]
train_weighted_f1 0.9925859274184478
train_acc 0.9925882737761466

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.41it/s]
valid_weighted_f1: 0.9767525545017555
valid_acc: 0.9767696951660219
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.82      0.82       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.92      0.97      0.94       306
          14       0.94      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.80      0.80      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      0.99      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.88      0.75      0.81       115
          27       1.00      0.66      0.79        38
          28       0.91      0.98      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9935349620659186
train_acc 0.9935377053915821

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.40it/s]
valid_weighted_f1: 0.9769037075138484
valid_acc: 0.9769227498830833
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.83      0.85       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.93      0.96      0.95       306
          14       0.94      0.99      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.80      0.78      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.86      0.77      0.81       115
          27       1.00      0.63      0.77        38
          28       0.93      0.95      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.97      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.95      0.96      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 12
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9942083996154577
train_acc 0.9942099539515047

Valid_Epoch: 12
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.97677941909726
valid_acc: 0.9768122103652056
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.81      0.84       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      0.98      0.97        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.92      0.97      0.94       306
          14       0.96      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.86      0.78      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.85      0.77      0.81       115
          27       0.97      0.74      0.84        38
          28       0.93      0.95      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.97      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 13
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.17it/s]
train_weighted_f1 0.9949078646045152
train_acc 0.99490875261253

Valid_Epoch: 13
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.40it/s]
valid_weighted_f1: 0.9770952505191286
valid_acc: 0.9771183197993283
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.80      0.82       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.92      0.98      0.95       306
          14       0.97      0.99      0.98       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.83      0.81      0.82       266
          20       0.98      0.99      0.98      8344
          21       1.00      0.87      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.90      0.73      0.81       115
          27       0.97      0.84      0.90        38
          28       0.92      0.96      0.94       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.96      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 14
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9955307560853809
train_acc 0.9955310869823792

Valid_Epoch: 14
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.37it/s]
valid_weighted_f1: 0.9772074037005392
valid_acc: 0.9772288593172059
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.82      0.83       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.92      0.97      0.94       306
          14       0.95      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.84      0.82      0.83       266
          20       0.98      0.99      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.91      0.72      0.81       115
          27       0.94      0.87      0.90        38
          28       0.94      0.94      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.97      0.97      4030
          34       0.98      0.96      0.97      2051
          35       0.95      0.96      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.97    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Process finished with exit code 0
