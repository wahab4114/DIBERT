ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
results/full_text/params/dibert_NER_mlm_cls_pprediction_best.json
selecting grid search sampler
[I 2021-02-22 17:52:07,140] A new study created in memory with name: no-name-ce4d4fbe-6814-4691-8a39-ba710dacbd3b
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.31it/s]
train_weighted_f1 0.8999900213796764
train_acc 0.8999496610083091

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.9662630623417402
valid_acc: 0.9664555078440542
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.64      0.71       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.93      0.92      9782
          13       0.88      0.94      0.91       306
          14       0.92      0.94      0.93       331
          15       0.99      1.00      0.99        66
          16       1.00      0.99      1.00       678
          17       0.93      0.95      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.88      0.63      0.73       266
          20       0.97      0.98      0.98      8344
          21       0.33      0.07      0.11        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.88      0.58      0.70       115
          27       1.00      0.45      0.62        38
          28       0.87      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.95      0.98      0.97      4030
          34       0.97      0.95      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.93      0.98      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.90      0.92    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:20<00:00,  4.29it/s]
train_weighted_f1 0.9643641406496068
train_acc 0.9644430425991062

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.9718721612798729
valid_acc: 0.9719484715785893
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.78      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.90      0.95      0.93       306
          14       0.95      0.96      0.95       331
          15       0.99      1.00      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.85      0.72      0.78       266
          20       0.98      0.99      0.98      8344
          21       0.78      0.93      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.68      0.77       115
          27       0.96      0.71      0.82        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.29it/s]
train_weighted_f1 0.9719007807935763
train_acc 0.9719471631747973

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.9747928192467593
valid_acc: 0.9748395051230815
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.81      0.82       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.95      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.82      0.79      0.81       266
          20       0.98      0.99      0.98      8344
          21       0.82      0.93      0.87        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.91      0.72      0.81       115
          27       0.94      0.76      0.84        38
          28       0.88      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.29it/s]
train_weighted_f1 0.9767018516605572
train_acc 0.9767357394096957

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.975870566161271
valid_acc: 0.9759023851026742
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.82      0.83       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.93      0.96      0.94       306
          14       0.95      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.97      0.96      0.96     19633
          19       0.84      0.82      0.83       266
          20       0.98      0.99      0.98      8344
          21       1.00      0.93      0.97        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.75      0.81       115
          27       0.96      0.71      0.82        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.98      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.99      0.98      1654
          37       0.99      0.99      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      1.00      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.98      0.98      0.98    117605

[I 2021-02-22 18:02:26,606] Trial 0 finished with value: 0.9759023851026742 and parameters: {'lrmain': 5e-05, 'drop_out': 0.2}. Best is trial 0 with value: 0.9759023851026742.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.29it/s]
train_weighted_f1 0.8847257182834115
train_acc 0.8844890061341354

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.41it/s]
valid_weighted_f1: 0.9636477819322413
valid_acc: 0.9638365715743378
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.72      0.52      0.61       101
           5       1.00      0.76      0.86        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.93      0.92      9782
          13       0.89      0.92      0.90       306
          14       0.92      0.93      0.92       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.94      0.93     15211
          18       0.96      0.94      0.95     19633
          19       0.85      0.62      0.72       266
          20       0.97      0.98      0.97      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.90      0.63      0.74       115
          27       0.96      0.63      0.76        38
          28       0.86      0.96      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.94      0.95      2051
          35       0.96      0.93      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      0.99       229
          42       0.98      0.98      0.98       405

    accuracy                           0.96    117605
   macro avg       0.91      0.89      0.90    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.30it/s]
train_weighted_f1 0.9614666417290724
train_acc 0.9615958097568436

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.43it/s]
valid_weighted_f1: 0.9702182471763066
valid_acc: 0.970315887929935
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.71      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.90      0.96      0.93       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.85      0.74      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.64      0.47      0.54        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.94      0.69      0.79       115
          27       0.97      0.76      0.85        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.30it/s]
train_weighted_f1 0.9694720492785917
train_acc 0.9695353519906204

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.47it/s]
valid_weighted_f1: 0.9731543388275498
valid_acc: 0.9732579397134475
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.66      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.87      0.73      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.81      0.87      0.84        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.95      0.67      0.79       115
          27       0.97      0.76      0.85        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.99      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.29it/s]
train_weighted_f1 0.9741796160683857
train_acc 0.9742262238534605

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.39it/s]
valid_weighted_f1: 0.9749008909403407
valid_acc: 0.9749670507206326
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.75      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.95      0.94      0.94      9782
          13       0.91      0.96      0.94       306
          14       0.95      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.79      0.81       266
          20       0.98      0.99      0.98      8344
          21       0.79      1.00      0.88        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.93      0.70      0.80       115
          27       0.93      0.74      0.82        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-02-22 18:12:43,424] Trial 1 finished with value: 0.9749670507206326 and parameters: {'lrmain': 3e-05, 'drop_out': 0.0}. Best is trial 0 with value: 0.9759023851026742.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.29it/s]
train_weighted_f1 0.9043868119456066
train_acc 0.9043877759086507

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.35it/s]
valid_weighted_f1: 0.9672653690831049
valid_acc: 0.9674163513456061
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.65      0.69       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.92      9782
          13       0.88      0.95      0.91       306
          14       0.94      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.90      0.68      0.78       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.13      0.24        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.91      0.63      0.74       115
          27       0.89      0.66      0.76        38
          28       0.87      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.98       405

    accuracy                           0.97    117605
   macro avg       0.94      0.90      0.91    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.29it/s]
train_weighted_f1 0.9659102944349778
train_acc 0.9659988785237295

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.41it/s]
valid_weighted_f1: 0.9724017499803913
valid_acc: 0.9725096722078143
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.74      0.77       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.95      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.87      0.72      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.88      1.00      0.94        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.96      2155
          26       0.93      0.67      0.78       115
          27       0.93      0.74      0.82        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.29it/s]
train_weighted_f1 0.9731141753380677
train_acc 0.9731599717931726

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.36it/s]
valid_weighted_f1: 0.9751118170911701
valid_acc: 0.9751711236767144
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.78      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.93      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.97      0.96      0.96     19633
          19       0.85      0.80      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.79      1.00      0.88        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.92      0.75      0.83       115
          27       0.96      0.66      0.78        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.95      0.95    117605
weighted avg       0.98      0.98      0.98    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:20<00:00,  4.27it/s]
train_weighted_f1 0.9780339506454939
train_acc 0.9780696164890996

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.48it/s]
valid_weighted_f1: 0.9757927877151201
valid_acc: 0.9758173547043067
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.80      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.92      0.96      0.94       306
          14       0.93      0.97      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.97      0.95      0.96     15211
          18       0.96      0.96      0.96     19633
          19       0.81      0.83      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.88      0.77      0.82       115
          27       1.00      0.71      0.83        38
          28       0.88      0.98      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      1.00      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.97    117605
weighted avg       0.98      0.98      0.98    117605

[I 2021-02-22 18:23:02,252] Trial 2 finished with value: 0.9758173547043067 and parameters: {'lrmain': 5e-05, 'drop_out': 0.1}. Best is trial 0 with value: 0.9759023851026742.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.30it/s]
train_weighted_f1 0.8966364608340289
train_acc 0.8965693021359026

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.47it/s]
valid_weighted_f1: 0.9652227467017809
valid_acc: 0.9653671187449513
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.67      0.61      0.64       101
           5       1.00      0.86      0.92        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.94      0.92      9782
          13       0.90      0.94      0.92       306
          14       0.93      0.93      0.93       331
          15       1.00      0.98      0.99        66
          16       1.00      0.99      1.00       678
          17       0.93      0.95      0.94     15211
          18       0.97      0.93      0.95     19633
          19       0.87      0.65      0.75       266
          20       0.97      0.98      0.98      8344
          21       0.00      0.00      0.00        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.93      0.65      0.77       115
          27       0.88      0.58      0.70        38
          28       0.86      0.97      0.91       248
          29       0.99      1.00      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.98      0.98      0.98       405

    accuracy                           0.97    117605
   macro avg       0.91      0.89      0.90    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.31it/s]
train_weighted_f1 0.9647441206556675
train_acc 0.9648402321116039

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.50it/s]
valid_weighted_f1: 0.9717279416292435
valid_acc: 0.9718124229412015
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.76      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.90      0.96      0.93       306
          14       0.94      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.85      0.75      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.82      0.93      0.87        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.96      2155
          26       0.93      0.70      0.80       115
          27       0.88      0.61      0.72        38
          28       0.88      0.98      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.33it/s]
train_weighted_f1 0.9721827235219663
train_acc 0.9722381522828839

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.45it/s]
valid_weighted_f1: 0.974342445343811
valid_acc: 0.9743888440117342
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.80      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.94      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.82      0.79      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.79      1.00      0.88        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.91      0.75      0.82       115
          27       0.90      0.71      0.79        38
          28       0.89      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.97      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.95      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.35it/s]
train_weighted_f1 0.9766369859305019
train_acc 0.9766730811710931

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9758922264775926
valid_acc: 0.9759363972620212
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.79      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.91      0.97      0.94       306
          14       0.94      0.97      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.96      0.96      0.96     19633
          19       0.86      0.79      0.82       266
          20       0.98      0.99      0.99      8344
          21       0.86      0.80      0.83        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.88      0.74      0.80       115
          27       0.90      0.71      0.79        38
          28       0.89      0.98      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.98      0.98      0.98    117605

[I 2021-02-22 18:33:15,655] Trial 3 finished with value: 0.9759363972620212 and parameters: {'lrmain': 4e-05, 'drop_out': 0.0}. Best is trial 3 with value: 0.9759363972620212.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.8516259980995347
train_acc 0.8517633515148426

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.9571009895200882
valid_acc: 0.9573657582585774
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.58      0.49      0.53       101
           5       1.00      0.57      0.73        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.93      0.90      9782
          13       0.88      0.85      0.86       306
          14       0.90      0.90      0.90       331
          15       0.99      1.00      0.99        66
          16       0.99      0.99      0.99       678
          17       0.92      0.93      0.92     15211
          18       0.96      0.92      0.94     19633
          19       0.83      0.58      0.68       266
          20       0.96      0.97      0.97      8344
          21       0.00      0.00      0.00        15
          22       0.98      1.00      0.99      2100
          23       1.00      0.99      0.99      1397
          24       0.98      1.00      0.99       925
          25       0.94      0.92      0.93      2155
          26       0.90      0.55      0.68       115
          27       0.89      0.42      0.57        38
          28       0.83      0.94      0.88       248
          29       0.96      0.98      0.97        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.92      0.93      2051
          35       0.95      0.93      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.98      1.00      0.99       270
          40       0.00      0.00      0.00        10
          41       1.00      0.99      1.00       229
          42       0.96      0.98      0.97       405

    accuracy                           0.96    117605
   macro avg       0.88      0.84      0.85    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:19<00:00,  4.31it/s]
train_weighted_f1 0.9551392063416281
train_acc 0.9553151178399687

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9669208844784198
valid_acc: 0.9670337145529527
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.65      0.69       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.94      0.92      9782
          13       0.91      0.95      0.93       306
          14       0.97      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.94      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.85      0.67      0.75       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.13      0.24        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.90      0.70      0.79       115
          27       0.91      0.82      0.86        38
          28       0.87      0.96      0.91       248
          29       0.99      1.00      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.95      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.98      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.91      0.91    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.34it/s]
train_weighted_f1 0.9645548418345158
train_acc 0.9646543814038844

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9704900625525318
valid_acc: 0.970579482164874
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.68      0.73       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.91      0.95      0.93       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.90      0.70      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.78      0.47      0.58        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.91      0.70      0.79       115
          27       0.91      0.79      0.85        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.99      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9696642266958375
train_acc 0.969731822738781

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9728422098597485
valid_acc: 0.9729093150801411
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.71      0.78       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.96      0.93       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.97      0.95      0.96     19633
          19       0.89      0.73      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.85      0.73      0.79        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.91      0.71      0.80       115
          27       0.91      0.79      0.85        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-02-22 18:43:25,947] Trial 4 finished with value: 0.9729093150801411 and parameters: {'lrmain': 2e-05, 'drop_out': 0.0}. Best is trial 3 with value: 0.9759363972620212.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.34it/s]
train_weighted_f1 0.8599899005315167
train_acc 0.8598016601247217

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.51it/s]
valid_weighted_f1: 0.9612783829083472
valid_acc: 0.9614897325793972
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.72      0.58      0.64       101
           5       1.00      0.81      0.89        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      0.98      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.93      0.91      9782
          13       0.88      0.87      0.87       306
          14       0.95      0.91      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.93      0.94      0.93     15211
          18       0.96      0.93      0.94     19633
          19       0.87      0.57      0.69       266
          20       0.97      0.98      0.97      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       0.99      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.85      0.57      0.68       115
          27       0.93      0.66      0.77        38
          28       0.86      0.95      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.93      0.95      2051
          35       0.96      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.97      0.94      0.96       370
          39       0.98      1.00      0.99       270
          40       1.00      0.40      0.57        10
          41       1.00      0.98      0.99       229
          42       0.98      0.98      0.98       405

    accuracy                           0.96    117605
   macro avg       0.91      0.87      0.88    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9556792970708975
train_acc 0.9558397478377597

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9683887878816877
valid_acc: 0.9685472556438927
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.69      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.94      0.93      9782
          13       0.90      0.94      0.92       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.96      0.95      0.95     19633
          19       0.88      0.66      0.76       266
          20       0.97      0.99      0.98      8344
          21       1.00      0.07      0.12        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.91      0.64      0.76       115
          27       0.93      0.68      0.79        38
          28       0.86      0.97      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.90      0.91    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9652395085283026
train_acc 0.9653298159759393

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9716863026346994
valid_acc: 0.9717784107818546
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.76      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.90      0.95      0.93       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.87      0.71      0.78       266
          20       0.98      0.99      0.98      8344
          21       0.82      0.60      0.69        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.90      0.65      0.76       115
          27       0.93      0.68      0.79        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9706249204824925
train_acc 0.9706897503865695

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.46it/s]
valid_weighted_f1: 0.9740701005419242
valid_acc: 0.974133752816632
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.75      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.89      0.74      0.81       266
          20       0.98      0.99      0.98      8344
          21       0.83      1.00      0.91        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.91      0.70      0.79       115
          27       0.91      0.79      0.85        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-02-22 18:53:35,549] Trial 5 finished with value: 0.974133752816632 and parameters: {'lrmain': 3e-05, 'drop_out': 0.3}. Best is trial 3 with value: 0.9759363972620212.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.8767214307948485
train_acc 0.8766471682724167

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.51it/s]
valid_weighted_f1: 0.9630085802743722
valid_acc: 0.9631563283873985
              precision    recall  f1-score   support

           1       1.00      0.96      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.66      0.56      0.61       101
           5       1.00      0.86      0.92        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      0.98      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.93      0.91      9782
          13       0.90      0.87      0.89       306
          14       0.95      0.92      0.94       331
          15       0.97      1.00      0.99        66
          16       1.00      0.99      1.00       678
          17       0.93      0.93      0.93     15211
          18       0.96      0.93      0.94     19633
          19       0.84      0.64      0.72       266
          20       0.97      0.98      0.97      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.85      0.68      0.75       115
          27       0.90      0.74      0.81        38
          28       0.86      0.95      0.90       248
          29       0.97      0.98      0.98        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.94      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.98      1.00      0.99       270
          40       1.00      0.90      0.95        10
          41       1.00      0.99      1.00       229
          42       0.99      0.98      0.98       405

    accuracy                           0.96    117605
   macro avg       0.91      0.89      0.90    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9589171118414098
train_acc 0.9590342560024468

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.969944912813961
valid_acc: 0.970052293694996
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.71      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.95      0.93      9782
          13       0.90      0.95      0.92       306
          14       0.95      0.94      0.95       331
          15       0.99      1.00      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.90      0.67      0.77       266
          20       0.97      0.99      0.98      8344
          21       0.75      0.40      0.52        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.95      0.66      0.78       115
          27       0.93      0.68      0.79        38
          28       0.86      0.98      0.91       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.99      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.91      0.92    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9678791885460404
train_acc 0.9679529659648944

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9730484544570434
valid_acc: 0.9731048849963863
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.74      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.85      0.73      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.79      1.00      0.88        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.93      0.70      0.80       115
          27       0.91      0.76      0.83        38
          28       0.88      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.94      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.972804372875036
train_acc 0.9728519906203803

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.60it/s]
valid_weighted_f1: 0.9747980240420376
valid_acc: 0.9748480081629183
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.76      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.95      0.94      9782
          13       0.89      0.97      0.93       306
          14       0.95      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.97      0.96      0.96     19633
          19       0.83      0.78      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.88      0.93      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.95      0.67      0.79       115
          27       0.94      0.76      0.84        38
          28       0.90      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.99      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.97      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.99      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-02-22 19:03:44,451] Trial 6 finished with value: 0.9748480081629183 and parameters: {'lrmain': 3e-05, 'drop_out': 0.1}. Best is trial 3 with value: 0.9759363972620212.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.35it/s]
train_weighted_f1 0.8677076555586741
train_acc 0.867420477137177

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9616308241702172
valid_acc: 0.9618723693720506
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.54      0.64       101
           5       1.00      0.86      0.92        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.89      0.93      0.91      9782
          13       0.86      0.87      0.86       306
          14       0.94      0.89      0.92       331
          15       1.00      0.98      0.99        66
          16       1.00      0.99      0.99       678
          17       0.93      0.93      0.93     15211
          18       0.95      0.93      0.94     19633
          19       0.85      0.58      0.68       266
          20       0.97      0.98      0.97      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       0.99      1.00      0.99       925
          25       0.96      0.93      0.94      2155
          26       0.82      0.56      0.66       115
          27       1.00      0.66      0.79        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.95      0.97      0.96      4030
          34       0.96      0.94      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.98      1.00      0.99       270
          40       1.00      0.30      0.46        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.98       405

    accuracy                           0.96    117605
   macro avg       0.91      0.87      0.88    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.34it/s]
train_weighted_f1 0.9575127425369386
train_acc 0.957643030704661

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.60it/s]
valid_weighted_f1: 0.9687094955876269
valid_acc: 0.9688533650780153
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.59      0.69       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.95      0.93      9782
          13       0.87      0.95      0.91       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.94      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.85      0.65      0.74       266
          20       0.98      0.98      0.98      8344
          21       0.75      0.20      0.32        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.87      0.59      0.70       115
          27       1.00      0.71      0.83        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.90      0.92    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.33it/s]
train_weighted_f1 0.9662137795438526
train_acc 0.9662930536439482

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9721529017110516
valid_acc: 0.972254581012712
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.68      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.91      0.94      0.92       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.85      0.69      0.76       266
          20       0.98      0.99      0.98      8344
          21       0.83      0.67      0.74        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.90      0.69      0.78       115
          27       0.94      0.76      0.84        38
          28       0.90      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9711587997059353
train_acc 0.9712133183803164

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9740668074897024
valid_acc: 0.9741252497767952
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.73      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      1.00      1.00     12278
          12       0.93      0.95      0.94      9782
          13       0.90      0.95      0.93       306
          14       0.95      0.96      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.74      0.78       266
          20       0.98      0.98      0.98      8344
          21       0.80      0.80      0.80        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.91      0.67      0.77       115
          27       1.00      0.74      0.85        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.97      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-02-22 19:13:54,534] Trial 7 finished with value: 0.9741252497767952 and parameters: {'lrmain': 3e-05, 'drop_out': 0.2}. Best is trial 3 with value: 0.9759363972620212.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9107285738066644
train_acc 0.910682273878099

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.50it/s]
valid_weighted_f1: 0.9674368613532554
valid_acc: 0.9676119212618511
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.64      0.71       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.92      9782
          13       0.87      0.94      0.90       306
          14       0.93      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.95      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.85      0.68      0.76       266
          20       0.97      0.98      0.98      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.91      0.62      0.74       115
          27       1.00      0.61      0.75        38
          28       0.86      0.95      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.92      0.90      0.91    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9675156081376414
train_acc 0.9675908225858524

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9729464333819915
valid_acc: 0.9730368606776922
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.71      0.77       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.89      0.96      0.92       306
          14       0.94      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.85      0.76      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.75      0.80      0.77        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.86      0.66      0.75       115
          27       0.96      0.68      0.80        38
          28       0.88      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9746617596679414
train_acc 0.9747062496813987

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.974654786872657
valid_acc: 0.9747459716848773
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.72      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.93      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.94      0.99      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.97      0.96     19633
          19       0.83      0.77      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.74      0.93      0.82        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.68      0.77       115
          27       1.00      0.66      0.79        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9791143549910585
train_acc 0.979141178569608

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.62it/s]
valid_weighted_f1: 0.9763787441186296
valid_acc: 0.9764295735725522
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.77      0.80       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.92      0.97      0.94       306
          14       0.95      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.79      0.81       266
          20       0.98      0.99      0.99      8344
          21       0.93      0.93      0.93        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.88      0.73      0.80       115
          27       1.00      0.71      0.83        38
          28       0.90      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.97      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.97    117605
weighted avg       0.98      0.98      0.98    117605

[I 2021-02-22 19:24:03,222] Trial 8 finished with value: 0.9764295735725522 and parameters: {'lrmain': 5e-05, 'drop_out': 0.0}. Best is trial 8 with value: 0.9764295735725522.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.8817341166013678
train_acc 0.8816587653565785

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9640645191206524
valid_acc: 0.9642872326856852
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.55      0.63       101
           5       1.00      0.81      0.89        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.93      0.92      9782
          13       0.85      0.87      0.86       306
          14       0.96      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.93      0.94      0.93     15211
          18       0.96      0.94      0.95     19633
          19       0.86      0.58      0.69       266
          20       0.97      0.98      0.97      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.83      0.51      0.63       115
          27       0.97      0.79      0.87        38
          28       0.84      0.97      0.90       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.95      0.98      0.97      4030
          34       0.97      0.94      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       0.98      0.98      0.98       405

    accuracy                           0.96    117605
   macro avg       0.91      0.89      0.90    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.34it/s]
train_weighted_f1 0.9598742864055939
train_acc 0.9600049276987647

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9708383520705814
valid_acc: 0.9709621189575273
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.61      0.72       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.88      0.94      0.91       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.88      0.68      0.77       266
          20       0.98      0.99      0.98      8344
          21       0.90      0.60      0.72        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.90      0.62      0.73       115
          27       0.94      0.79      0.86        38
          28       0.86      0.97      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.99      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.98       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9685408680574097
train_acc 0.96861565648842

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9735790759534501
valid_acc: 0.9736745886654479
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.68      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.88      0.96      0.92       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.84      0.74      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.85      0.73      0.79        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.90      0.63      0.74       115
          27       0.91      0.82      0.86        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9736192781924161
train_acc 0.9736729197464784

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.9750227672650322
valid_acc: 0.9751030993580205
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.89      0.70      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.95      0.94      0.94      9782
          13       0.91      0.96      0.93       306
          14       0.95      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.96      0.97      0.96     19633
          19       0.83      0.76      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.85      0.73      0.79        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.86      0.72      0.79       115
          27       0.91      0.76      0.83        38
          28       0.89      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.99      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.98      0.98      0.98    117605

[I 2021-02-22 19:34:12,205] Trial 9 finished with value: 0.9751030993580205 and parameters: {'lrmain': 4e-05, 'drop_out': 0.3}. Best is trial 8 with value: 0.9764295735725522.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.8934882540798993
train_acc 0.8933291277973187

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.47it/s]
valid_weighted_f1: 0.96538595432003
valid_acc: 0.9655626886611963
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.64      0.70       101
           5       0.95      0.95      0.95        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.93      0.92      9782
          13       0.89      0.91      0.90       306
          14       0.93      0.93      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.94      0.94     15211
          18       0.95      0.94      0.95     19633
          19       0.84      0.63      0.72       266
          20       0.97      0.98      0.98      8344
          21       1.00      0.07      0.12        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.84      0.64      0.73       115
          27       1.00      0.58      0.73        38
          28       0.86      0.98      0.92       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.98      0.97       370
          39       0.98      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.98       405

    accuracy                           0.97    117605
   macro avg       0.94      0.90      0.91    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9633566016348293
train_acc 0.9634543168340385

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.63it/s]
valid_weighted_f1: 0.971607506532436
valid_acc: 0.9717188895029973
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.76      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.90      0.94      0.92       306
          14       0.94      0.94      0.94       331
          15       0.99      1.00      0.99        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.84      0.72      0.77       266
          20       0.98      0.99      0.98      8344
          21       0.82      0.60      0.69        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.88      0.66      0.76       115
          27       0.89      0.63      0.74        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.34it/s]
train_weighted_f1 0.9709443161250599
train_acc 0.9710030415795823

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.48it/s]
valid_weighted_f1: 0.9740087352787383
valid_acc: 0.974099740657285
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.78      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.94      0.94      9782
          13       0.91      0.96      0.93       306
          14       0.94      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.84      0.73      0.78       266
          20       0.98      0.99      0.98      8344
          21       0.83      0.67      0.74        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.88      0.70      0.78       115
          27       1.00      0.61      0.75        38
          28       0.90      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.95      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9757388811452267
train_acc 0.9757809977740395

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.975341762178403
valid_acc: 0.9754007057523064
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.74      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.95      0.94      9782
          13       0.91      0.96      0.94       306
          14       0.94      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.96      0.96      0.96     19633
          19       0.82      0.77      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.88      1.00      0.94        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.85      0.70      0.77       115
          27       1.00      0.68      0.81        38
          28       0.90      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.99      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.95      0.95    117605
weighted avg       0.98      0.98      0.98    117605

[I 2021-02-22 19:44:21,654] Trial 10 finished with value: 0.9754007057523064 and parameters: {'lrmain': 4e-05, 'drop_out': 0.1}. Best is trial 8 with value: 0.9764295735725522.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.8315521940802367
train_acc 0.831280479516066

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.56it/s]
valid_weighted_f1: 0.9561896565933683
valid_acc: 0.9565494664342502
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.62      0.49      0.54       101
           5       1.00      0.24      0.38        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.93      0.98      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.92      0.90      9782
          13       0.84      0.83      0.83       306
          14       0.92      0.88      0.90       331
          15       0.98      0.98      0.98        66
          16       0.99      0.99      0.99       678
          17       0.92      0.93      0.92     15211
          18       0.95      0.93      0.94     19633
          19       0.82      0.57      0.67       266
          20       0.96      0.97      0.97      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      1.00      1.00      1397
          24       0.98      1.00      0.99       925
          25       0.94      0.92      0.93      2155
          26       0.91      0.50      0.65       115
          27       0.94      0.42      0.58        38
          28       0.81      0.92      0.86       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.98      0.97      2601
          33       0.94      0.97      0.96      4030
          34       0.94      0.93      0.94      2051
          35       0.95      0.93      0.94      3387
          36       0.96      0.97      0.96      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.98      1.00      0.99       270
          40       0.00      0.00      0.00        10
          41       1.00      0.97      0.98       229
          42       0.96      0.98      0.97       405

    accuracy                           0.96    117605
   macro avg       0.88      0.83      0.84    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.33it/s]
train_weighted_f1 0.949804538736196
train_acc 0.9500082836315441

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9655346398291365
valid_acc: 0.9657157433782577
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.69      0.71       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.93      0.92      9782
          13       0.89      0.90      0.89       306
          14       0.95      0.92      0.94       331
          15       0.99      1.00      0.99        66
          16       1.00      0.99      0.99       678
          17       0.94      0.94      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.84      0.61      0.70       266
          20       0.97      0.98      0.98      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.89      0.63      0.73       115
          27       0.90      0.68      0.78        38
          28       0.87      0.96      0.91       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.95      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.97      0.97      0.97       370
          39       0.98      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       0.99      0.98      0.98       405

    accuracy                           0.97    117605
   macro avg       0.91      0.90      0.90    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9605572789938591
train_acc 0.960666556218246

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9693889658143144
valid_acc: 0.9694825900259343
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.77      0.76      0.77       101
           5       0.95      1.00      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.94      0.93      9782
          13       0.88      0.94      0.91       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.95      0.94      0.94     15211
          18       0.96      0.95      0.95     19633
          19       0.85      0.67      0.75       266
          20       0.97      0.99      0.98      8344
          21       0.89      0.53      0.67        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.92      0.62      0.74       115
          27       0.90      0.74      0.81        38
          28       0.89      0.96      0.92       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.98       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9664915634095842
train_acc 0.9665681126913731

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.61it/s]
valid_weighted_f1: 0.97151909330097
valid_acc: 0.9715998469452829
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.75      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.90      0.95      0.93       306
          14       0.95      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.85      0.69      0.76       266
          20       0.98      0.99      0.98      8344
          21       0.80      0.80      0.80        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.94      0.96      2155
          26       0.93      0.71      0.81       115
          27       0.91      0.76      0.83        38
          28       0.87      0.98      0.92       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-02-22 19:54:31,404] Trial 11 finished with value: 0.9715998469452829 and parameters: {'lrmain': 2e-05, 'drop_out': 0.2}. Best is trial 8 with value: 0.9764295735725522.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.8866834221936744
train_acc 0.886564162036329

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.52it/s]
valid_weighted_f1: 0.9653046665163467
valid_acc: 0.9654861613026657
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.60      0.69       101
           5       1.00      0.86      0.92        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.93      0.92      9782
          13       0.88      0.91      0.89       306
          14       0.94      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.94      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.88      0.62      0.72       266
          20       0.97      0.98      0.98      8344
          21       0.50      0.07      0.12        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.88      0.59      0.71       115
          27       0.93      0.68      0.79        38
          28       0.87      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.98      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.97      0.98      0.98       405

    accuracy                           0.97    117605
   macro avg       0.93      0.89      0.90    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9618136901514686
train_acc 0.9619218449983857

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9711164489641734
valid_acc: 0.971200204072956
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.73      0.79       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.92      0.95      0.94       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.88      0.69      0.77       266
          20       0.98      0.99      0.98      8344
          21       0.71      0.67      0.69        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.89      0.73      0.80       115
          27       0.94      0.79      0.86        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.97      0.96      0.97      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.35it/s]
train_weighted_f1 0.9699142334673753
train_acc 0.9699835176972353

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9744768601567453
valid_acc: 0.9745418987287956
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.92      0.75      0.83       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.94      0.94      0.94      9782
          13       0.93      0.96      0.94       306
          14       0.94      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.84      0.76      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.79      1.00      0.88        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.75      0.81       115
          27       1.00      0.66      0.79        38
          28       0.89      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.95      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9746219036707566
train_acc 0.9746690795398549

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9751330316272007
valid_acc: 0.9751796267165511
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.78      0.80       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.95      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.95      0.97      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.80      0.82       266
          20       0.98      0.99      0.99      8344
          21       0.82      0.93      0.87        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.92      0.71      0.80       115
          27       0.97      0.74      0.84        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.95      0.95      0.95    117605
weighted avg       0.98      0.98      0.98    117605

[I 2021-02-22 20:04:41,198] Trial 12 finished with value: 0.9751796267165511 and parameters: {'lrmain': 4e-05, 'drop_out': 0.2}. Best is trial 8 with value: 0.9764295735725522.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.840334469504537
train_acc 0.8399687346009413

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.53it/s]
valid_weighted_f1: 0.9571718338725508
valid_acc: 0.9573997704179245
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.62      0.55      0.59       101
           5       1.00      0.57      0.73        21
           6       1.00      0.99      0.99      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.93      0.98      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.93      0.90      9782
          13       0.87      0.87      0.87       306
          14       0.91      0.86      0.88       331
          15       0.96      1.00      0.98        66
          16       0.99      0.99      0.99       678
          17       0.93      0.92      0.92     15211
          18       0.95      0.93      0.94     19633
          19       0.86      0.56      0.68       266
          20       0.96      0.97      0.97      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       1.00      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.95      0.92      0.93      2155
          26       0.83      0.55      0.66       115
          27       0.88      0.37      0.52        38
          28       0.78      0.95      0.86       248
          29       0.97      0.98      0.98        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.93      0.94      2051
          35       0.94      0.93      0.94      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.98      1.00      0.99       270
          40       1.00      0.80      0.89        10
          41       1.00      0.99      0.99       229
          42       0.98      0.98      0.98       405

    accuracy                           0.96    117605
   macro avg       0.90      0.86      0.87    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:21<00:00,  4.25it/s]
train_weighted_f1 0.952724156912535
train_acc 0.9529245467366739

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9660943804894174
valid_acc: 0.9662514348879725
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.65      0.68       101
           5       1.00      0.90      0.95        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.94      0.92      9782
          13       0.89      0.93      0.91       306
          14       0.95      0.92      0.94       331
          15       0.99      1.00      0.99        66
          16       1.00      0.99      0.99       678
          17       0.94      0.94      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.89      0.64      0.74       266
          20       0.97      0.98      0.98      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.87      0.63      0.73       115
          27       0.91      0.79      0.85        38
          28       0.86      0.97      0.91       248
          29       0.99      1.00      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.98       405

    accuracy                           0.97    117605
   macro avg       0.91      0.90      0.91    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9625732885842689
train_acc 0.962697107950587

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9697676266737328
valid_acc: 0.9698482207389142
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.71      0.75       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.91      0.95      0.93       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.95      0.94      0.94     15211
          18       0.96      0.95      0.95     19633
          19       0.86      0.71      0.78       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.47      0.64        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.91      0.69      0.78       115
          27       0.91      0.82      0.86        38
          28       0.87      0.97      0.91       248
          29       0.99      1.00      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9679012168046822
train_acc 0.9679816400740854

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.58it/s]
valid_weighted_f1: 0.9720776402244108
valid_acc: 0.9721270354151609
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.75      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.97      0.95      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.83      0.74      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.91      0.67      0.77        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.92      0.73      0.82       115
          27       0.92      0.87      0.89        38
          28       0.88      0.96      0.92       248
          29       0.99      1.00      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-02-22 20:14:53,685] Trial 13 finished with value: 0.9721270354151609 and parameters: {'lrmain': 2e-05, 'drop_out': 0.1}. Best is trial 8 with value: 0.9764295735725522.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.8942795127275738
train_acc 0.8941893510730489

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.45it/s]
valid_weighted_f1: 0.9659444503491642
valid_acc: 0.9660983801709111
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.67      0.69       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.93      0.92      9782
          13       0.89      0.93      0.91       306
          14       0.94      0.92      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.93      0.95      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.85      0.64      0.73       266
          20       0.97      0.98      0.97      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.94      0.63      0.75       115
          27       1.00      0.68      0.81        38
          28       0.85      0.96      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.95      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.98       405

    accuracy                           0.97    117605
   macro avg       0.92      0.90      0.91    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.37it/s]
train_weighted_f1 0.9631209171810121
train_acc 0.9632185519362457

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.54it/s]
valid_weighted_f1: 0.9720891374842466
valid_acc: 0.9721695506143446
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.74      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.95      0.93       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.88      0.71      0.78       266
          20       0.98      0.99      0.98      8344
          21       1.00      0.80      0.89        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.91      0.72      0.81       115
          27       0.93      0.71      0.81        38
          28       0.86      0.97      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:23<00:00,  4.18it/s]
train_weighted_f1 0.9706401785911162
train_acc 0.9706982464189223

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9746658910426129
valid_acc: 0.9747119595255304
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.79      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.95      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.85      0.80      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.79      1.00      0.88        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.88      0.71      0.79       115
          27       1.00      0.74      0.85        38
          28       0.87      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9759002858911637
train_acc 0.9759402983806562

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.57it/s]
valid_weighted_f1: 0.9757542243004064
valid_acc: 0.9757918455847966
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.84      0.81       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.95      0.94      0.95      9782
          13       0.91      0.97      0.94       306
          14       0.94      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.96      0.97      0.96     19633
          19       0.83      0.81      0.82       266
          20       0.98      0.99      0.99      8344
          21       0.83      1.00      0.91        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.72      0.80       115
          27       1.00      0.74      0.85        38
          28       0.89      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.95      0.95    117605
weighted avg       0.98      0.98      0.98    117605

[I 2021-02-22 20:25:08,060] Trial 14 finished with value: 0.9757918455847966 and parameters: {'lrmain': 5e-05, 'drop_out': 0.3}. Best is trial 8 with value: 0.9764295735725522.
selecting for trial

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.8226455925993296
train_acc 0.822281057246266

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.43it/s]
valid_weighted_f1: 0.9550167307995903
valid_acc: 0.9553845499766166
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.66      0.54      0.60       101
           5       1.00      0.05      0.09        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      0.98      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.87      0.92      0.90      9782
          13       0.83      0.76      0.80       306
          14       0.90      0.85      0.88       331
          15       0.92      0.98      0.95        66
          16       0.99      0.99      0.99       678
          17       0.92      0.93      0.92     15211
          18       0.95      0.92      0.93     19633
          19       0.86      0.55      0.67       266
          20       0.96      0.97      0.97      8344
          21       0.00      0.00      0.00        15
          22       0.98      1.00      0.99      2100
          23       1.00      1.00      1.00      1397
          24       0.99      1.00      0.99       925
          25       0.95      0.91      0.93      2155
          26       0.84      0.47      0.60       115
          27       0.87      0.34      0.49        38
          28       0.79      0.94      0.86       248
          29       0.96      0.97      0.96        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.95      0.92      0.93      2051
          35       0.95      0.93      0.94      3387
          36       0.96      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.96      0.95       370
          39       0.98      0.98      0.98       270
          40       0.00      0.00      0.00        10
          41       1.00      0.99      0.99       229
          42       0.97      0.98      0.97       405

    accuracy                           0.96    117605
   macro avg       0.87      0.82      0.83    117605
weighted avg       0.96      0.96      0.96    117605


Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9477841897523954
train_acc 0.9480191500569234

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9650733052467517
valid_acc: 0.9652565792270736
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.76      0.63      0.69       101
           5       1.00      0.90      0.95        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.94      0.92      9782
          13       0.88      0.90      0.89       306
          14       0.96      0.92      0.94       331
          15       0.99      1.00      0.99        66
          16       1.00      0.99      0.99       678
          17       0.93      0.94      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.87      0.61      0.71       266
          20       0.97      0.98      0.97      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.83      0.62      0.71       115
          27       0.87      0.71      0.78        38
          28       0.86      0.98      0.92       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      0.99      1.00       229
          42       0.99      0.98      0.98       405

    accuracy                           0.97    117605
   macro avg       0.91      0.89      0.90    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [02:18<00:00,  4.34it/s]
train_weighted_f1 0.9594824909765887
train_acc 0.9596151722145758

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9693013183513196
valid_acc: 0.9694060626674036
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.71      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.94      0.93      9782
          13       0.89      0.94      0.91       306
          14       0.96      0.92      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.96      0.95      0.95     19633
          19       0.87      0.67      0.76       266
          20       0.97      0.98      0.98      8344
          21       0.80      0.27      0.40        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.89      0.63      0.74       115
          27       0.88      0.76      0.82        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.96      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.98       405

    accuracy                           0.97    117605
   macro avg       0.94      0.91      0.92    117605
weighted avg       0.97      0.97      0.97    117605


Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.36it/s]
train_weighted_f1 0.9650622269882636
train_acc 0.9651545853086608

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.55it/s]
valid_weighted_f1: 0.9717106895921881
valid_acc: 0.9717784107818546
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.71      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.92      0.95      0.93      9782
          13       0.90      0.95      0.92       306
          14       0.96      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.87      0.72      0.79       266
          20       0.98      0.99      0.98      8344
          21       0.86      0.80      0.83        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.91      0.69      0.78       115
          27       0.90      0.74      0.81        38
          28       0.90      0.98      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605

[I 2021-02-22 20:35:17,548] Trial 15 finished with value: 0.9717784107818546 and parameters: {'lrmain': 2e-05, 'drop_out': 0.3}. Best is trial 8 with value: 0.9764295735725522.

Process finished with exit code 0
