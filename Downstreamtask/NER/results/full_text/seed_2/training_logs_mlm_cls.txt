ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 5e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [02:20<00:00,  4.28it/s]
train_weighted_f1 0.9015633654226258
train_acc 0.9012081358005811

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.41it/s]
valid_weighted_f1: 0.9652963197580009
valid_acc: 0.9654521491433188
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.64      0.73      0.68       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.92      0.92      9782
          13       0.85      0.95      0.90       306
          14       0.91      0.95      0.93       331
          15       1.00      1.00      1.00        66
          16       0.99      1.00      0.99       678
          17       0.93      0.94      0.94     15211
          18       0.96      0.94      0.95     19633
          19       0.83      0.68      0.75       266
          20       0.97      0.98      0.98      8344
          21       0.17      0.07      0.10        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.89      0.56      0.68       115
          27       1.00      0.50      0.67        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.95      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.92      0.90      0.90    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9635202254177004
train_acc 0.963582819323376

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.9717774292173845
valid_acc: 0.9718464351005485
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.80      0.79       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.89      0.96      0.93       306
          14       0.94      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.82      0.79      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.69      0.73      0.71        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.90      0.68      0.77       115
          27       1.00      0.74      0.85        38
          28       0.87      0.98      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.96      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9720082629545571
train_acc 0.9720533635792085

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.41it/s]
valid_weighted_f1: 0.9743859128116508
valid_acc: 0.974431359210918
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.85      0.83       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.94      0.94      9782
          13       0.90      0.97      0.93       306
          14       0.94      0.98      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.83      0.77      0.80       266
          20       0.98      0.99      0.98      8344
          21       0.86      0.80      0.83        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.85      0.70      0.77       115
          27       1.00      0.79      0.88        38
          28       0.89      0.98      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.95      0.98      0.96      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [02:43<00:00,  3.66it/s]
train_weighted_f1 0.9769809582067867
train_acc 0.9770129224652088

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.40it/s]
valid_weighted_f1: 0.9758231264933637
valid_acc: 0.975842863823817
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.88      0.84       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.95      0.94      0.95      9782
          13       0.91      0.97      0.94       306
          14       0.95      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.96      0.96      0.96     19633
          19       0.81      0.82      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.87      0.87      0.87        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.89      0.75      0.81       115
          27       1.00      0.74      0.85        38
          28       0.89      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.98      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.98    117605
   macro avg       0.95      0.95      0.95    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [02:17<00:00,  4.35it/s]
train_weighted_f1 0.9809966586217798
train_acc 0.9810177397155528

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.43it/s]
valid_weighted_f1: 0.9760505704864862
valid_acc: 0.9760809489392458
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.83      0.84       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.89      0.98      0.93       306
          14       0.95      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.97      0.96      0.96     19633
          19       0.82      0.80      0.81       266
          20       0.98      0.99      0.98      8344
          21       0.86      0.80      0.83        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.89      0.69      0.77       115
          27       1.00      0.74      0.85        38
          28       0.89      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.50      0.33      0.40         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.95      0.94      0.95    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.983932437144496
train_acc 0.9839467468692121

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.39it/s]
valid_weighted_f1: 0.9766572288676828
valid_acc: 0.9766846647676545
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.86      0.84       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.90      0.97      0.93       306
          14       0.96      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.80      0.80      0.80       266
          20       0.98      0.99      0.99      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.88      0.71      0.79       115
          27       1.00      0.79      0.88        38
          28       0.89      0.97      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [02:32<00:00,  3.92it/s]
train_weighted_f1 0.9866154891370241
train_acc 0.986624059064417

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.44it/s]
valid_weighted_f1: 0.9768437619131144
valid_acc: 0.9768717316440627
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.85      0.86       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.94      0.95      9782
          13       0.89      0.97      0.93       306
          14       0.95      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.96      0.97      0.97     19633
          19       0.77      0.82      0.80       266
          20       0.99      0.99      0.99      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.90      0.68      0.77       115
          27       1.00      0.74      0.85        38
          28       0.92      0.96      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.98      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.99      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [02:32<00:00,  3.93it/s]
train_weighted_f1 0.9884154259604031
train_acc 0.9884220319110976

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.47it/s]
valid_weighted_f1: 0.9771115862470419
valid_acc: 0.977126822839165
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.83      0.84       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.89      0.96      0.93       306
          14       0.96      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.95      0.96     15211
          18       0.97      0.97      0.97     19633
          19       0.80      0.83      0.81       266
          20       0.98      0.99      0.99      8344
          21       1.00      0.67      0.80        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.84      0.70      0.76       115
          27       0.94      0.82      0.87        38
          28       0.92      0.96      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.97      0.95      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [03:06<00:00,  3.22it/s]
train_weighted_f1 0.9901765907951637
train_acc 0.9901807106081459

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.37it/s]
valid_weighted_f1: 0.9771593509061804
valid_acc: 0.9771778410781855
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.84      0.85       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      0.99      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.90      0.97      0.93       306
          14       0.97      0.98      0.98       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.85      0.81      0.83       266
          20       0.98      0.99      0.99      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.85      0.74      0.79       115
          27       0.91      0.84      0.88        38
          28       0.90      0.99      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.96      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [03:09<00:00,  3.16it/s]
train_weighted_f1 0.9914611249578253
train_acc 0.9914657355015208

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.37it/s]
valid_weighted_f1: 0.9771025354721979
valid_acc: 0.9771098167594915
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.83      0.84       101
           5       1.00      0.95      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      1.00      1.00     12278
          12       0.94      0.96      0.95      9782
          13       0.91      0.97      0.94       306
          14       0.96      1.00      0.98       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.82      0.83      0.83       266
          20       0.98      0.99      0.99      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.85      0.77      0.81       115
          27       1.00      0.76      0.87        38
          28       0.92      0.95      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.97      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [02:55<00:00,  3.41it/s]
train_weighted_f1 0.9927451093360891
train_acc 0.9927465123787191

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.9775018192850462
valid_acc: 0.9775094596318183
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.82      0.84       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.92      0.97      0.94       306
          14       0.96      0.99      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.82      0.82      0.82       266
          20       0.99      0.99      0.99      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.83      0.78      0.81       115
          27       0.91      0.76      0.83        38
          28       0.89      0.99      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.99      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [02:34<00:00,  3.89it/s]
train_weighted_f1 0.9935650153300307
train_acc 0.9935663795007731

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.42it/s]
valid_weighted_f1: 0.976894968228876
valid_acc: 0.9769227498830833
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.81      0.82       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.92      0.96      0.94       306
          14       0.93      0.99      0.96       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.97      0.97     19633
          19       0.81      0.82      0.82       266
          20       0.99      0.98      0.98      8344
          21       0.91      0.67      0.77        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.84      0.78      0.81       115
          27       1.00      0.55      0.71        38
          28       0.91      0.96      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.97      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.98    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 12
100%|█████████████████████████████████████████| 600/600 [02:55<00:00,  3.41it/s]
train_weighted_f1 0.9944283173681955
train_acc 0.9944297887886357

Valid_Epoch: 12
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.41it/s]
valid_weighted_f1: 0.9773366591326004
valid_acc: 0.9773564049147571
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.84      0.83       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.92      0.97      0.94       306
          14       0.95      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.84      0.81      0.82       266
          20       0.98      0.99      0.98      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.97      2155
          26       0.87      0.77      0.81       115
          27       1.00      0.74      0.85        38
          28       0.93      0.94      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.97      0.95      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.96      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 13
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.16it/s]
train_weighted_f1 0.9949909109095371
train_acc 0.9949915889279707

Valid_Epoch: 13
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.41it/s]
valid_weighted_f1: 0.9773620729660462
valid_acc: 0.9773734109944305
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.78      0.80       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      1.00      1.00     12278
          12       0.94      0.95      0.95      9782
          13       0.92      0.96      0.94       306
          14       0.96      0.98      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.81      0.82      0.82       266
          20       0.98      0.99      0.99      8344
          21       0.91      0.67      0.77        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.83      0.77      0.80       115
          27       0.94      0.79      0.86        38
          28       0.93      0.93      0.93       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.98      0.98      0.98      2601
          33       0.97      0.98      0.97      4030
          34       0.97      0.97      0.97      2051
          35       0.96      0.96      0.96      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.99      2611
          38       0.97      0.98      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Train_Epoch: 14
100%|█████████████████████████████████████████| 600/600 [03:10<00:00,  3.15it/s]
train_weighted_f1 0.9955272253217076
train_acc 0.9955279009702469

Valid_Epoch: 14
100%|███████████████████████████████████████████| 75/75 [00:11<00:00,  6.41it/s]
valid_weighted_f1: 0.9774492170298269
valid_acc: 0.9774499383529612
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.82      0.83       101
           5       0.95      0.95      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      1.00      1.00      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      1.00      1.00     12278
          12       0.95      0.95      0.95      9782
          13       0.92      0.96      0.94       306
          14       0.96      0.97      0.97       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.96      0.96     15211
          18       0.97      0.96      0.97     19633
          19       0.80      0.83      0.81       266
          20       0.99      0.99      0.99      8344
          21       0.85      0.73      0.79        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.96      0.96      2155
          26       0.84      0.77      0.80       115
          27       0.94      0.84      0.89        38
          28       0.93      0.95      0.94       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.98      0.98      2601
          33       0.98      0.97      0.97      4030
          34       0.98      0.96      0.97      2051
          35       0.95      0.96      0.96      3387
          36       0.98      0.98      0.98      1654
          37       0.99      0.99      0.99      2611
          38       0.97      0.95      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.98    117605
   macro avg       0.96      0.96      0.96    117605
weighted avg       0.98      0.98      0.98    117605

-saving model-

Process finished with exit code 0
