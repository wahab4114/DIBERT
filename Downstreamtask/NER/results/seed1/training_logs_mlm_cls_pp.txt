ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 2e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.92it/s]
train_weighted_f1 0.8856297342057294
train_acc 0.8863124670778746

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9499566010888274
valid_acc: 0.9504017686322861
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.43      0.53       101
           5       1.00      0.62      0.76        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.92      1.00      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.88      0.91      0.90      9782
          13       0.83      0.86      0.84       306
          14       0.90      0.84      0.87       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.92      0.91      0.91     15211
          18       0.92      0.93      0.93     19633
          19       0.89      0.56      0.69       266
          20       0.94      0.96      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       0.99      0.99      0.99      1397
          24       0.99      1.00      0.99       925
          25       0.95      0.89      0.92      2155
          26       0.86      0.44      0.59       115
          27       0.88      0.18      0.30        38
          28       0.85      0.86      0.85       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.94      0.95      2601
          33       0.94      0.97      0.96      4030
          34       0.91      0.89      0.90      2051
          35       0.96      0.91      0.94      3387
          36       0.94      0.96      0.95      1654
          37       0.97      0.94      0.96      2611
          38       0.93      0.97      0.95       370
          39       0.98      1.00      0.99       270
          40       0.00      0.00      0.00        10
          41       0.99      1.00      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.88      0.83      0.84    117605
weighted avg       0.95      0.95      0.95    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9527860911260776
train_acc 0.95300101102785

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9615552478048485
valid_acc: 0.9617618298541729
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.55      0.65       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.96      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.93      0.92      9782
          13       0.84      0.92      0.88       306
          14       0.95      0.92      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.93      0.93     15211
          18       0.94      0.95      0.94     19633
          19       0.87      0.62      0.73       266
          20       0.97      0.97      0.97      8344
          21       1.00      0.07      0.12        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.91      0.94      2155
          26       0.88      0.50      0.63       115
          27       0.93      0.68      0.79        38
          28       0.86      0.92      0.88       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.93      0.95      0.94      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.97      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.93      0.97      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      0.90      0.95        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.94      0.89      0.90    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9646119155951192
train_acc 0.9647287216869722

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.56it/s]
valid_weighted_f1: 0.9661753909521608
valid_acc: 0.9663024531269929
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.68      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.94      0.93      9782
          13       0.86      0.94      0.90       306
          14       0.93      0.93      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.94      0.95     19633
          19       0.86      0.67      0.76       266
          20       0.98      0.97      0.98      8344
          21       0.71      0.33      0.45        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.93      0.95      2155
          26       0.91      0.54      0.68       115
          27       0.92      0.58      0.71        38
          28       0.87      0.94      0.90       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.94      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.93      0.90      0.91    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.90it/s]
train_weighted_f1 0.9713402198898041
train_acc 0.9714161611527417

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9679983206126076
valid_acc: 0.9681221036520556
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.67      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.92      0.93      9782
          13       0.88      0.95      0.91       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.94      0.96      0.95     19633
          19       0.81      0.70      0.75       266
          20       0.98      0.98      0.98      8344
          21       0.80      0.80      0.80        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.91      0.60      0.72       115
          27       0.93      0.68      0.79        38
          28       0.90      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.97598074452346
train_acc 0.9760348167405821

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9689143568886129
valid_acc: 0.96899791675524
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.70      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.93      0.93      9782
          13       0.88      0.97      0.92       306
          14       0.94      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.93      0.96      0.94     15211
          18       0.96      0.95      0.95     19633
          19       0.87      0.73      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.73      0.73      0.73        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.90      0.63      0.74       115
          27       0.90      0.68      0.78        38
          28       0.89      0.94      0.92       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.95      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9794213674430502
train_acc 0.9794597797828414

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.970389541641119
valid_acc: 0.9704944517665065
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.63      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.90      0.96      0.93       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.84      0.74      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.87      0.87      0.87        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.86      0.63      0.73       115
          27       0.88      0.74      0.80        38
          28       0.89      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9826140005245094
train_acc 0.982639419890911

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9701380017917111
valid_acc: 0.9702308575315676
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.73      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.88      0.97      0.92       306
          14       0.94      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.82      0.80      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.88      0.57      0.69       115
          27       0.90      0.68      0.78        38
          28       0.90      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.95      0.95      2051
          35       0.98      0.92      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.93      0.97      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9847631248561076
train_acc 0.9847836060559718

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9715363077096251
valid_acc: 0.9716168530249564
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.67      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.88      0.96      0.92       306
          14       0.94      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.84      0.78      0.81       266
          20       0.98      0.98      0.98      8344
          21       1.00      0.73      0.85        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.88      0.63      0.74       115
          27       0.90      0.68      0.78        38
          28       0.90      0.94      0.92       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9864952276314142
train_acc 0.9865093626276529

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9700415996047667
valid_acc: 0.970086305854343
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.76      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.91      0.96      0.93       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.94      0.97      0.95     19633
          19       0.83      0.74      0.79       266
          20       0.98      0.97      0.98      8344
          21       0.92      0.73      0.81        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.89      0.68      0.77       115
          27       0.85      0.76      0.81        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.97      0.95      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9883649551626769
train_acc 0.9883753037331566

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9704962333244042
valid_acc: 0.9705709791250372
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.72      0.78       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.88      0.97      0.92       306
          14       0.94      0.96      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.95     15211
          18       0.94      0.97      0.95     19633
          19       0.81      0.76      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.71      0.80      0.75        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.85      0.62      0.71       115
          27       0.97      0.74      0.84        38
          28       0.91      0.93      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.97      0.96      2051
          35       0.98      0.92      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.94      0.98      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9896061926224846
train_acc 0.9896146624526346

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9712021698929422
valid_acc: 0.9712597253518133
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.73      0.77       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.90      0.98      0.93       306
          14       0.95      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.84      0.81      0.83       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.80      0.86        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.85      0.63      0.73       115
          27       0.83      0.76      0.79        38
          28       0.90      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.98      0.96      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.94      0.97      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [05:13<00:00,  1.91it/s]
train_weighted_f1 0.9910138513653328
train_acc 0.9910186317989499

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.971632025662655
valid_acc: 0.9716423621444666
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.74      0.76       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.95      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.81      0.81      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.83      0.70      0.76       115
          27       0.85      0.76      0.81        38
          28       0.89      0.96      0.92       248
          29       1.00      0.98      0.99        66
          30       1.00      1.00      1.00      2302
          31       1.00      1.00      1.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
