ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 5e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9090720852376529
train_acc 0.9093632648553126

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9580310676101123
valid_acc: 0.9581820500829047
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.57      0.64      0.60       101
           5       1.00      0.95      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.92      0.91      9782
          13       0.85      0.93      0.89       306
          14       0.90      0.92      0.91       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.92      0.93      0.93     15211
          18       0.94      0.95      0.94     19633
          19       0.84      0.65      0.73       266
          20       0.96      0.96      0.96      8344
          21       0.83      0.33      0.48        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.91      0.93      2155
          26       0.92      0.49      0.64       115
          27       1.00      0.29      0.45        38
          28       0.87      0.88      0.88       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.96      0.96      2601
          33       0.96      0.96      0.96      4030
          34       0.95      0.89      0.92      2051
          35       0.96      0.93      0.94      3387
          36       0.95      0.97      0.96      1654
          37       0.98      0.96      0.97      2611
          38       0.94      0.96      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      0.90      0.95        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.93      0.88      0.90    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9619797992167598
train_acc 0.9620588435200761

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.52it/s]
valid_weighted_f1: 0.9654635200711996
valid_acc: 0.9655626886611963
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.69      0.75      0.72       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.93      0.92      9782
          13       0.89      0.96      0.92       306
          14       0.92      0.94      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.92      0.94     15211
          18       0.94      0.96      0.95     19633
          19       0.85      0.72      0.78       266
          20       0.97      0.97      0.97      8344
          21       0.88      0.93      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.92      0.61      0.73       115
          27       0.95      0.50      0.66        38
          28       0.90      0.88      0.89       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.98      0.95      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.94      0.94      2051
          35       0.96      0.93      0.95      3387
          36       0.95      0.99      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.95      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.92    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9728589584011978
train_acc 0.9729072148306741

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.968207250213799
valid_acc: 0.9682496492496068
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.71      0.71      0.71       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.94      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.95      0.93      9782
          13       0.91      0.96      0.94       306
          14       0.91      0.94      0.92       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.73      0.82      0.77       266
          20       0.98      0.97      0.98      8344
          21       0.87      0.87      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.94      0.94      2155
          26       0.93      0.66      0.77       115
          27       1.00      0.34      0.51        38
          28       0.91      0.90      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.97      0.97      2601
          33       0.95      0.97      0.96      4030
          34       0.94      0.95      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.98      2611
          38       0.97      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.979039432617452
train_acc 0.9790700242986525

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9696325608462595
valid_acc: 0.9697121721015263
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.76      0.75       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      1.00      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.91      0.95      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.84      0.74      0.78       266
          20       0.98      0.98      0.98      8344
          21       0.88      0.93      0.90        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      0.99      1.00       925
          25       0.95      0.94      0.95      2155
          26       0.86      0.69      0.76       115
          27       0.89      0.45      0.60        38
          28       0.93      0.88      0.90       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.96      0.97      2601
          33       0.97      0.97      0.97      4030
          34       0.93      0.97      0.95      2051
          35       0.94      0.96      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9832110848125272
train_acc 0.9832298941394368

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9700483235285171
valid_acc: 0.9701118149738531
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.79      0.68      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.94      0.97        65
          11       0.99      0.99      0.99     12278
          12       0.95      0.92      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.80      0.78      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.88      0.93      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.93      0.96      0.95      2155
          26       0.93      0.70      0.80       115
          27       0.92      0.63      0.75        38
          28       0.91      0.92      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.94      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.98      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.986314082990553
train_acc 0.9863277599361099

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9703249894910647
valid_acc: 0.9703754092087922
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.83      0.82       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.95      0.93      0.94      9782
          13       0.92      0.97      0.94       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.80      0.79      0.80       266
          20       0.98      0.97      0.98      8344
          21       0.83      1.00      0.91        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.95      2155
          26       0.93      0.70      0.80       115
          27       0.87      0.68      0.76        38
          28       0.93      0.91      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.97      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      0.90      0.95        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9887426277599805
train_acc 0.9887501911607279

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9709327888908968
valid_acc: 0.9710131371965478
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.68      0.76       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       1.00      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.91      0.96      0.94       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.88      0.75      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.81      0.87      0.84        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.96      0.95      2155
          26       0.94      0.67      0.78       115
          27       0.89      0.63      0.74        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.94      0.98      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.98      0.92      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.93      0.97      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9908576042951199
train_acc 0.9908625172044655

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.52it/s]
valid_weighted_f1: 0.9702728482686165
valid_acc: 0.970281875770588
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.65      0.74       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       1.00      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.92      0.95      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.80      0.78      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.87      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.88      0.73      0.80       115
          27       0.92      0.63      0.75        38
          28       0.88      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.96      0.98      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.95      0.95      2051
          35       0.97      0.94      0.95      3387
          36       0.96      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.91      0.98      0.94       370
          39       1.00      1.00      1.00       270
          40       1.00      0.90      0.95        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [05:16<00:00,  1.90it/s]
train_weighted_f1 0.9921130554062625
train_acc 0.9921146199724729

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9705408894628237
valid_acc: 0.970579482164874
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.78      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.98      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.92      0.95      0.94      9782
          13       0.90      0.95      0.93       306
          14       0.91      0.94      0.92       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.83      0.77      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.81      0.87      0.84        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.89      0.68      0.77       115
          27       0.93      0.37      0.53        38
          28       0.86      0.98      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.75      1.00      0.86         3
          32       0.97      0.97      0.97      2601
          33       0.97      0.96      0.97      4030
          34       0.94      0.96      0.95      2051
          35       0.96      0.95      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.93      0.98      0.95       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.97    117605
   macro avg       0.95      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [05:16<00:00,  1.90it/s]
train_weighted_f1 0.9935723038893801
train_acc 0.9935727515250378

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9706570824269884
valid_acc: 0.9707410399217721
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.65      0.73       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.92      0.95      0.94      9782
          13       0.90      0.97      0.93       306
          14       0.92      0.95      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.86      0.76      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.87      0.87      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.96      2155
          26       0.92      0.66      0.77       115
          27       0.94      0.45      0.61        38
          28       0.91      0.96      0.94       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.96      0.95      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 10
100%|█████████████████████████████████████████| 600/600 [05:16<00:00,  1.90it/s]
train_weighted_f1 0.9945661648726798
train_acc 0.9945678493143701

Valid_Epoch: 10
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.52it/s]
valid_weighted_f1: 0.9701397123340929
valid_acc: 0.9701713362527103
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.86      0.70      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.94      0.97        65
          11       1.00      0.99      0.99     12278
          12       0.91      0.96      0.94      9782
          13       0.91      0.96      0.94       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.89      0.74      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.85      0.73      0.79        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.88      0.73      0.80       115
          27       0.90      0.74      0.81        38
          28       0.87      0.98      0.92       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.97      0.96      2051
          35       0.96      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.98      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 11
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9952797719686934
train_acc 0.9952804540279689

Valid_Epoch: 11
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9713356611804498
valid_acc: 0.9714042770290379
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.87      0.70      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.95      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.92      0.97      0.94       306
          14       0.95      0.94      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.96      0.96     19633
          19       0.92      0.73      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.92      0.70      0.79       115
          27       0.87      0.68      0.76        38
          28       0.90      0.95      0.92       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.97      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.93      0.98      0.95       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
