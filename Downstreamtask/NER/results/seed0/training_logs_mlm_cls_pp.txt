ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 2e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:11<00:00,  1.93it/s]
train_weighted_f1 0.8851082185981842
train_acc 0.8857336748738339

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.94925695754343
valid_acc: 0.9497300284851835
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.70      0.40      0.51       101
           5       1.00      0.71      0.83        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.92      1.00      0.96        65
          11       0.99      0.99      0.99     12278
          12       0.87      0.92      0.89      9782
          13       0.83      0.86      0.84       306
          14       0.88      0.84      0.86       331
          15       1.00      1.00      1.00        66
          16       0.99      0.99      0.99       678
          17       0.93      0.89      0.91     15211
          18       0.92      0.94      0.93     19633
          19       0.87      0.56      0.68       266
          20       0.95      0.96      0.95      8344
          21       0.00      0.00      0.00        15
          22       0.99      1.00      0.99      2100
          23       1.00      0.99      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.89      0.92      2155
          26       0.81      0.45      0.58       115
          27       0.75      0.08      0.14        38
          28       0.82      0.84      0.83       248
          29       1.00      0.97      0.98        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.96      0.94      0.95      2601
          33       0.95      0.96      0.96      4030
          34       0.91      0.91      0.91      2051
          35       0.96      0.92      0.94      3387
          36       0.94      0.96      0.95      1654
          37       0.97      0.95      0.96      2611
          38       0.94      0.96      0.95       370
          39       0.98      1.00      0.99       270
          40       0.00      0.00      0.00        10
          41       0.99      1.00      0.99       229
          42       1.00      0.98      0.99       405

    accuracy                           0.95    117605
   macro avg       0.87      0.82      0.84    117605
weighted avg       0.95      0.95      0.95    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9526325670537992
train_acc 0.952839586413145

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.51it/s]
valid_weighted_f1: 0.9613872526261278
valid_acc: 0.9615662599379278
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.74      0.54      0.63       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.97      1.00      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.90      0.94      0.92      9782
          13       0.84      0.92      0.88       306
          14       0.94      0.92      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.94      0.92      0.93     15211
          18       0.94      0.95      0.94     19633
          19       0.84      0.63      0.72       266
          20       0.97      0.97      0.97      8344
          21       1.00      0.33      0.50        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.93      0.94      2155
          26       0.88      0.49      0.63       115
          27       0.91      0.55      0.69        38
          28       0.87      0.88      0.87       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.96      0.97      2601
          33       0.96      0.97      0.96      4030
          34       0.94      0.94      0.94      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.97      0.96      1654
          37       0.98      0.97      0.98      2611
          38       0.93      0.96      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.94      0.89      0.91    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9644639918966523
train_acc 0.9645683590763113

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9662089373313445
valid_acc: 0.9663279622465031
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.78      0.60      0.68       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.95      0.93      9782
          13       0.85      0.95      0.90       306
          14       0.94      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.94      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.67      0.75       266
          20       0.98      0.97      0.97      8344
          21       1.00      0.67      0.80        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.94      0.95      2155
          26       0.89      0.51      0.65       115
          27       0.92      0.63      0.75        38
          28       0.90      0.90      0.90       248
          29       1.00      0.98      0.99        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.94      0.96      0.95      2051
          35       0.96      0.94      0.95      3387
          36       0.97      0.97      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.96      0.95       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.91      0.92    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9711001158516825
train_acc 0.9711772102428166

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9685598595131324
valid_acc: 0.9686918073211173
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.66      0.74       101
           5       0.95      1.00      0.98        21
           6       1.00      0.99      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.93      9782
          13       0.88      0.95      0.91       306
          14       0.93      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.94      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.85      0.73      0.78       266
          20       0.97      0.98      0.98      8344
          21       0.79      0.73      0.76        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.94      0.95      2155
          26       0.88      0.57      0.69       115
          27       0.92      0.63      0.75        38
          28       0.89      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.94      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.92    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9759179261055239
train_acc 0.9759774685222001

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9699114337117468
valid_acc: 0.9699927724161388
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.68      0.75       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.88      0.96      0.92       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.85      0.75      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.86      0.80      0.83        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.91      0.59      0.72       115
          27       0.90      0.71      0.79        38
          28       0.89      0.94      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       0.99      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.979613481476709
train_acc 0.9796456304905609

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9702506925341284
valid_acc: 0.9703499000892819
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.85      0.61      0.71       101
           5       0.95      1.00      0.98        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.93      0.94      0.94      9782
          13       0.87      0.98      0.92       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.82      0.80      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.82      0.93      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.88      0.57      0.69       115
          27       0.85      0.76      0.81        38
          28       0.91      0.92      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.95      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.98      0.98      2611
          38       0.96      0.96      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9821556809094072
train_acc 0.982181696147899

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9707326101010829
valid_acc: 0.9708005612006292
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.67      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      1.00      1.00        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.94      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.95      0.95     19633
          19       0.84      0.80      0.82       266
          20       0.98      0.98      0.98      8344
          21       0.75      0.80      0.77        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.96      0.96      2155
          26       0.88      0.65      0.75       115
          27       0.90      0.71      0.79        38
          28       0.92      0.92      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.96      0.95      0.95      2051
          35       0.97      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.95       370
          39       1.00      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.94      0.93      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9846783053433845
train_acc 0.9846975837283989

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.53it/s]
valid_weighted_f1: 0.9708167401238657
valid_acc: 0.9709025976786702
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.64      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.88      0.97      0.92       306
          14       0.97      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.85      0.77      0.81       266
          20       0.98      0.98      0.98      8344
          21       0.79      0.73      0.76        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.84      0.63      0.72       115
          27       0.86      0.82      0.84        38
          28       0.89      0.96      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.98      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.986500983158483
train_acc 0.9865146726478734

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9708393432500975
valid_acc: 0.9709111007185068
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.88      0.68      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.84      0.75      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.92      0.73      0.81        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.86      0.67      0.75       115
          27       0.91      0.76      0.83        38
          28       0.89      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.93      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9885610768327846
train_acc 0.9885717744813173

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9709222015616605
valid_acc: 0.9709876280770375
              precision    recall  f1-score   support

           1       1.00      0.99      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.82      0.69      0.75       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.90      0.97      0.93       306
          14       0.96      0.95      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.84      0.77      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.81      0.87      0.84        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.97      0.95      0.96      2155
          26       0.86      0.68      0.76       115
          27       0.94      0.76      0.84        38
          28       0.90      0.93      0.91       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.67      0.67      0.67         3
          32       0.98      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.94      0.97      0.95      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
