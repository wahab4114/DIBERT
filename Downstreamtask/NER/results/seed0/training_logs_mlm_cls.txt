ssh://root@mp-weizenbaum.iais.fraunhofer.de:22022/opt/conda/envs/dibert/bin/python -u /cluster/pytorchic-bert/Downstreamtask/NER/train_ner.py
38367
4796
{'lrmain': 5e-05, 'drop_out': 0.1}
selecting best_params

Train_Epoch: 0
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.908983764406145
train_acc 0.9093462727906068

Valid_Epoch: 0
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9574656221739443
valid_acc: 0.9577058798520471
/opt/conda/envs/dibert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.61      0.61      0.61       101
           5       1.00      1.00      1.00        21
           6       1.00      0.99      1.00      2353
           7       0.98      0.98      0.98      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.91      0.91      9782
          13       0.84      0.93      0.89       306
          14       0.91      0.91      0.91       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      0.99       678
          17       0.92      0.92      0.92     15211
          18       0.93      0.95      0.94     19633
          19       0.88      0.63      0.74       266
          20       0.97      0.96      0.96      8344
          21       0.67      0.13      0.22        15
          22       0.99      1.00      1.00      2100
          23       1.00      0.99      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.93      0.91      0.92      2155
          26       0.88      0.44      0.59       115
          27       0.93      0.37      0.53        38
          28       0.86      0.86      0.86       248
          29       1.00      1.00      1.00        66
          30       0.99      1.00      1.00      2302
          31       0.00      0.00      0.00         3
          32       0.97      0.94      0.96      2601
          33       0.95      0.96      0.96      4030
          34       0.94      0.90      0.92      2051
          35       0.95      0.93      0.94      3387
          36       0.94      0.98      0.96      1654
          37       0.98      0.96      0.97      2611
          38       0.95      0.97      0.96       370
          39       0.99      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.96    117605
   macro avg       0.92      0.88      0.89    117605
weighted avg       0.96      0.96      0.96    117605

-saving model-

Train_Epoch: 1
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9615662792563913
train_acc 0.9616457239469168

Valid_Epoch: 1
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9652937283716478
valid_acc: 0.9654351430636453
              precision    recall  f1-score   support

           1       1.00      0.97      0.98       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.72      0.75      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.94      0.93      9782
          13       0.86      0.96      0.91       306
          14       0.91      0.94      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      0.99      1.00       678
          17       0.95      0.93      0.94     15211
          18       0.94      0.96      0.95     19633
          19       0.89      0.68      0.77       266
          20       0.97      0.98      0.97      8344
          21       0.81      0.87      0.84        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.92      0.94      2155
          26       0.85      0.53      0.65       115
          27       0.89      0.42      0.57        38
          28       0.90      0.84      0.87       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.96      0.96      2601
          33       0.96      0.97      0.96      4030
          34       0.95      0.94      0.94      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.97      0.97      2611
          38       0.96      0.96      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.98      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.92      0.93    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 2
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.9730411695257988
train_acc 0.9730877555181731

Valid_Epoch: 2
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9676026130086814
valid_acc: 0.967679945580545
              precision    recall  f1-score   support

           1       1.00      0.98      0.99       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.72      0.73       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      1.00      0.99        65
          11       0.99      0.99      0.99     12278
          12       0.91      0.95      0.93      9782
          13       0.89      0.98      0.93       306
          14       0.93      0.94      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.93      0.94     15211
          18       0.95      0.95      0.95     19633
          19       0.84      0.72      0.78       266
          20       0.97      0.98      0.98      8344
          21       0.83      0.67      0.74        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.93      0.94      2155
          26       0.86      0.63      0.73       115
          27       0.96      0.58      0.72        38
          28       0.91      0.89      0.90       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.97      0.96      0.97      2601
          33       0.96      0.96      0.96      4030
          34       0.94      0.96      0.95      2051
          35       0.95      0.95      0.95      3387
          36       0.95      0.98      0.96      1654
          37       0.98      0.97      0.97      2611
          38       0.95      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.92      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 3
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.90it/s]
train_weighted_f1 0.9789243379478824
train_acc 0.9789532038538002

Valid_Epoch: 3
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9698996397878882
valid_acc: 0.969950257216955
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.73      0.75      0.74       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       0.99      1.00      0.99     12278
          12       0.93      0.94      0.93      9782
          13       0.90      0.97      0.93       306
          14       0.93      0.94      0.93       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.82      0.77      0.80       266
          20       0.98      0.98      0.98      8344
          21       0.86      0.80      0.83        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      0.99      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.88      0.64      0.74       115
          27       0.88      0.58      0.70        38
          28       0.92      0.87      0.90       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.33      0.50         3
          32       0.98      0.97      0.97      2601
          33       0.96      0.97      0.97      4030
          34       0.93      0.96      0.95      2051
          35       0.96      0.95      0.95      3387
          36       0.97      0.98      0.98      1654
          37       0.99      0.97      0.98      2611
          38       0.98      0.96      0.97       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.96      0.93      0.94    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 4
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.983011522103243
train_acc 0.9830291753750998

Valid_Epoch: 4
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.969619076199178
valid_acc: 0.9696781599421793
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.71      0.77       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.97      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.95      0.93      0.94      9782
          13       0.89      0.97      0.93       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.78      0.80      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.82      0.93      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.95      0.95      2155
          26       0.89      0.63      0.74       115
          27       0.85      0.74      0.79        38
          28       0.91      0.92      0.91       248
          29       1.00      0.98      0.99        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.96      0.98      0.97      4030
          34       0.94      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 5
100%|█████████████████████████████████████████| 600/600 [05:14<00:00,  1.91it/s]
train_weighted_f1 0.986451041241256
train_acc 0.9864626344497119

Valid_Epoch: 5
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.55it/s]
valid_weighted_f1: 0.9694077757420816
valid_acc: 0.9695080991454444
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.89      0.66      0.76       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       1.00      0.95      0.98        65
          11       0.99      0.99      0.99     12278
          12       0.94      0.93      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.95      0.93      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.94     15211
          18       0.95      0.96      0.95     19633
          19       0.87      0.73      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.81      0.87      0.84        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.95      0.95      0.95      2155
          26       0.91      0.65      0.76       115
          27       0.90      0.74      0.81        38
          28       0.92      0.93      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.94      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.94      0.98      0.96       370
          39       1.00      0.99      0.99       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 6
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9893091060126783
train_acc 0.9893151773121952

Valid_Epoch: 6
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9699768142582776
valid_acc: 0.9700778028145062
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.84      0.73      0.78       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.98      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.95      0.92      0.94      9782
          13       0.90      0.98      0.94       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.94      0.95      0.95     15211
          18       0.95      0.96      0.95     19633
          19       0.90      0.71      0.79       266
          20       0.98      0.98      0.98      8344
          21       0.93      0.93      0.93        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.87      0.66      0.75       115
          27       0.89      0.63      0.74        38
          28       0.92      0.91      0.91       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.98      0.96      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.96      0.95      2051
          35       0.97      0.93      0.95      3387
          36       0.97      0.98      0.97      1654
          37       0.99      0.98      0.98      2611
          38       0.91      0.98      0.94       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      0.99       405

    accuracy                           0.97    117605
   macro avg       0.97      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 7
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9906765779609937
train_acc 0.9906819765169665

Valid_Epoch: 7
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9710394897601307
valid_acc: 0.9710726584754049
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.80      0.78      0.79       101
           5       1.00      1.00      1.00        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.96      0.93      0.95       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.86      0.77      0.81       266
          20       0.97      0.98      0.98      8344
          21       0.88      0.93      0.90        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.95      0.95      2155
          26       0.93      0.68      0.78       115
          27       0.91      0.82      0.86        38
          28       0.90      0.95      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.97      4030
          34       0.96      0.95      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.98      0.98      0.98      2611
          38       0.94      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      1.00      1.00       405

    accuracy                           0.97    117605
   macro avg       0.97      0.95      0.96    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 8
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9923048729191206
train_acc 0.9923089667125452

Valid_Epoch: 8
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.54it/s]
valid_weighted_f1: 0.9706901227406374
valid_acc: 0.9707665490412822
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.83      0.75      0.79       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.94      0.94      0.94      9782
          13       0.91      0.97      0.94       306
          14       0.94      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.95      0.95      0.95     15211
          18       0.95      0.96      0.96     19633
          19       0.86      0.72      0.79       266
          20       0.97      0.98      0.98      8344
          21       0.81      0.87      0.84        15
          22       1.00      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.96      0.94      0.95      2155
          26       0.91      0.67      0.77       115
          27       0.92      0.61      0.73        38
          28       0.87      0.97      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.96      0.95      0.96      2051
          35       0.97      0.94      0.95      3387
          36       0.96      0.98      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.95      0.98      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.97    117605
   macro avg       0.96      0.94      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Train_Epoch: 9
100%|█████████████████████████████████████████| 600/600 [05:15<00:00,  1.90it/s]
train_weighted_f1 0.9932732534811146
train_acc 0.9932764523967307

Valid_Epoch: 9
100%|███████████████████████████████████████████| 75/75 [00:16<00:00,  4.52it/s]
valid_weighted_f1: 0.9708436453033782
valid_acc: 0.9708855915989967
              precision    recall  f1-score   support

           1       1.00      1.00      1.00       121
           2       1.00      1.00      1.00      3312
           3       1.00      1.00      1.00      4790
           4       0.81      0.78      0.80       101
           5       0.91      1.00      0.95        21
           6       1.00      1.00      1.00      2353
           7       0.99      0.99      0.99      3217
           8       1.00      1.00      1.00      9748
           9       0.97      0.98      0.98        65
          11       1.00      0.99      0.99     12278
          12       0.93      0.95      0.94      9782
          13       0.92      0.96      0.94       306
          14       0.95      0.94      0.94       331
          15       1.00      1.00      1.00        66
          16       1.00      1.00      1.00       678
          17       0.96      0.94      0.95     15211
          18       0.96      0.95      0.96     19633
          19       0.89      0.74      0.80       266
          20       0.97      0.98      0.98      8344
          21       0.82      0.93      0.87        15
          22       0.99      1.00      1.00      2100
          23       1.00      1.00      1.00      1397
          24       1.00      1.00      1.00       925
          25       0.94      0.95      0.95      2155
          26       0.88      0.73      0.80       115
          27       0.86      0.82      0.84        38
          28       0.90      0.94      0.92       248
          29       1.00      1.00      1.00        66
          30       1.00      1.00      1.00      2302
          31       1.00      0.67      0.80         3
          32       0.97      0.97      0.97      2601
          33       0.95      0.98      0.96      4030
          34       0.95      0.96      0.96      2051
          35       0.97      0.93      0.95      3387
          36       0.95      0.99      0.97      1654
          37       0.99      0.97      0.98      2611
          38       0.96      0.97      0.96       370
          39       1.00      1.00      1.00       270
          40       1.00      1.00      1.00        10
          41       1.00      1.00      1.00       229
          42       1.00      0.99      1.00       405

    accuracy                           0.97    117605
   macro avg       0.96      0.95      0.95    117605
weighted avg       0.97      0.97      0.97    117605

-saving model-

Process finished with exit code 0
